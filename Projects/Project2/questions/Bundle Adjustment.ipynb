{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bundle Adjustment\n",
    "\n",
    "Part of this assignment is based on scipy-cookbook. It will take around 2 hours to finish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the paper 'Building Rome in a Day' and briefly write about the fundamental idea behind the problem and solution. No need to be verbose, just write about the challenge with the task and how the pipeline is implemented (do not include details about performance/parallelization).\n",
    "\n",
    "2. How is this task different from a SLAM problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 1: Building Rome in a Day\n",
    "\n",
    "> **Paper**: S Agarwal (2009) - Building Rome in a day; available at [10.1109/ICCV.2009.5459148](https://doi.org/10.1109/ICCV.2009.5459148)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "The paper aims to address the problem of large scale depth reconstruction from images of a city. Precisely, instead of using custom setups to capture images (like how Google Maps data is collected), it uses images from publicly accessible image databases (like [flickr](https://www.flickr.com/)). A key problem addressed by this paper is scaling the image correspondence, bundle adjustment optimization, and the map creation process; thereby effectively distributing it across multiple compute cores (a compute cluster).\n",
    "\n",
    "This is particularly challenging when it comes to data distribution and lifecycle management of detected features. The code system design is divided into various parts (that are implemented on different nodes on the cluster, using an efficient job distribution and scheduling manager). Two of the most important parts are described below (in the following two cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Matching** and **Correspondence Validation**\n",
    "\n",
    "The image features are detected using SIFT features. These matches are pruned and verified using a RANSAC algorithm that uses the fundamental or the essential matrix (in some cases, the [EXIF](https://en.wikipedia.org/wiki/Exif) / metadata of the images contains the focal length of the camera using which the image was taken; if no focal length information is available, fundamental matrix is used instead).\n",
    "\n",
    "Pair-wise matching cannot be scaled to large databases (imagine $^n\\textup{C}_2$ value for $n=100,000$), and pair-wise comparisons don't even make sense (many pairs will not match as they won't be capturing the same scene). A multi-stage image matching scheme is therefore proposed. Each stage has a proposal and verification. Proposals (of potential image pairs) are generated using vocabulary tree and based on query expansion.\n",
    "\n",
    "In a vocabulary tree, feature descriptors of images are stored in a k-Means tree. Basically, images are quantized into vector spaces that can be addressed quickly and, likely images of the same scenes (having similar descriptors) are stored closer together. This is like finding a huge embedding space for images.\n",
    "\n",
    "In query expansion, a query is expanded (dynamically) when new data pertaining to this query is found. This yields a hugely connected graphs linking potential pairs together. The graph needs to be maintained, so geometric verification of image pairs are used before adding them to the graph.\n",
    "\n",
    "After this, the correspondence has to be _validated_ (so that it is ensured that it is indeed correct). This is a two step process. The first step is photometric matching between feature descriptors and the second is the estimation of fundamental or essential matrix (depending on the availability of focal length data). In case an essential matrix is recovered and there is good angle between the viewing directions (this can be found by decomposition of the essential matrix), a full two-view Euclidean reconstruction is done and stored. This helps to reduce the size of the reconstruction problem (and to also estimate the initial parameters of the optimization).\n",
    "\n",
    "Ultimately, a _track_ is generated that helps us to find and label all of the connected components in the graph of individual feature matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geometric Estimation**\n",
    "\n",
    "The SfM problem is solved using **Bindle Adjustment**: a large scale optimization procedure where the projection error for every scene is aimed to be minimized, and the camera projection matrices and the world point coordinates are aimed to be found. For such a large scale optimization, the sparse nature of the problem is exploited (not every image is related to the other, not every camera parameter is related to the other). This gives huge computational savings, and also allows the problem to be solved in a parallel fashion (unrelated parts can be solved on separate cores and then gradients can be concatenated and applied). The authors developed methods over Sparse Bundle Adjustment algorithm (the then state-of-the-art algorithm) to handle the problem complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 2: Difference from SLAM\n",
    "\n",
    "In the first overview, SLAM (Simultaneous Localization and Mapping) and Bundle Adjustment (an SfM - Structure from Motion - problem) appear similar. However, key differences are described below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a typical SLAM problem, the poses (localization) and the environment (mapping) are found through filtering or smoothing. This is not very different from the expected results of a bundle adjustment problem (camera poses / parameters and the scene reconstruction as a 3D point cloud). However, the mapping in SLAM involves a more complex process. SFM / Bundle Adjustment do not usually incorporate building maps through landmark locations (they work on entire scene reconstruction). SLAM is more complete, as it also incorporates the entire mapping process as well. However, for this, the front end needs to incorporate landmark identification and lifecycle management algorithms.\n",
    "\n",
    "SLAM could use Bundle Adjustment as a mean to refine updates (smoothing), but filtering techniques like Kalman Filtering are more widely used(alone or in conjunction with bundle adjustment).\n",
    "\n",
    "Finally, SLAM implementations (usually) can leverage data from other types of sensors (like GPS, IMU, etc.) better than Bundle Adjustment can: which, in its raw form, will use that data only as initial estimates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "We have a set of points in real world defined by their coordinates $(X, Y, Z)$ in some apriori chosen \"world coordinate frame\". We photograph these points by different cameras, which are characterized by their orientation and translation relative to the world coordinate frame and also by focal length and two radial distortion parameters (9 parameters in total). Then we precicely measure 2-D coordinates $(x, y)$ of the points projected by the cameras on images. Our task is to refine 3-D coordinates of original points as well as camera parameters, by minimizing the sum of squares of reprojecting errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a dataset from [Bundle Adjustment in Large](https://grail.cs.washington.edu/projects/bal/) for this task. Feel free to choose any of the ones mentioned on the page. Take the smallest file from each dataset (you can choose any but it will take longer to run, consume more memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import copy\n",
    "import bz2\n",
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"http://grail.cs.washington.edu/projects/bal/data/\"\n",
    "\n",
    "DATASET_NAME = \"final/\"\n",
    "# FILE_NAME = \"problem-13682-4456117-pre.txt.bz2\" # Too Huge!\n",
    "# FILE_NAME = \"problem-93-61203-pre.txt.bz2\"  # Testing a small file\n",
    "FILE_NAME = \"problem-394-100368-pre.txt.bz2\"  # Testing a small file\n",
    "\n",
    "URL = BASE_URL + DATASET_NAME + FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(FILE_NAME):\n",
    "    urllib.request.urlretrieve(URL, FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read the data from the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bal_data(file_name):\n",
    "    with bz2.open(file_name, \"rt\") as file:\n",
    "        n_cameras, n_points, n_observations = map(\n",
    "            int, file.readline().split())\n",
    "\n",
    "        camera_indices = np.empty(n_observations, dtype=int)\n",
    "        point_indices = np.empty(n_observations, dtype=int)\n",
    "        points_2d = np.empty((n_observations, 2))\n",
    "\n",
    "        for i in range(n_observations):\n",
    "            camera_index, point_index, x, y = file.readline().split()\n",
    "            camera_indices[i] = int(camera_index)\n",
    "            point_indices[i] = int(point_index)\n",
    "            points_2d[i] = [float(x), float(y)]\n",
    "\n",
    "        camera_params = np.empty(n_cameras * 9)\n",
    "        for i in range(n_cameras * 9):\n",
    "            camera_params[i] = float(file.readline())\n",
    "        camera_params = camera_params.reshape((n_cameras, -1))\n",
    "\n",
    "        points_3d = np.empty(n_points * 3)\n",
    "        for i in range(n_points * 3):\n",
    "            points_3d[i] = float(file.readline())\n",
    "        points_3d = points_3d.reshape((n_points, -1))\n",
    "\n",
    "    return camera_params, points_3d, camera_indices, point_indices, points_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_params, points_3d, camera_indices, point_indices, points_2d = read_bal_data(FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera_params: (394, 9);\n",
      "points_3d: (100368, 3);\n",
      "camera_indices: (534408,); \n",
      "point_indices: (534408,); \n",
      "points_2d: (534408, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"camera_params: {camera_params.shape};\\npoints_3d: {points_3d.shape};\\n\"\n",
    "        f\"camera_indices: {camera_indices.shape}; \\npoint_indices: {point_indices.shape}; \\n\"\n",
    "        f\"points_2d: {points_2d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have numpy arrays:\n",
    "\n",
    "1. `camera_params` with shape `(n_cameras, 9)` contains initial estimates of parameters for all cameras. First 3 components in each row form a **rotation vector**, next 3 components form a translation vector, then a focal distance and two distortion parameters.\n",
    "2. `points_3d` with shape `(n_points, 3)` contains initial estimates of point coordinates in the world frame.\n",
    "3. `points_2d` with shape `(n_observations, 2)` contains measured 2-D coordinates of points projected on images in all the observations.\n",
    "4. `camera_ind` with shape `(n_observations,)` gives the index of the camera (from 0 to `n_cameras - 1`) associated with a particular observation.   \n",
    "5. `point_ind` with shape `(n_observations,)` contains indices of 3D points (from 0 to `n_points - 1`) involved in each observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Point Cloud\n",
    "\n",
    "Visualize `points_3d`. It may not look like 'Venice' or any building as we are working with a small subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Geometries\n",
    "cf = o3d.geometry.TriangleMesh.create_coordinate_frame(0.5)\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points_3d)\n",
    "o3d.visualization.draw_geometries([pcd, cf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Parameters\n",
    "\n",
    "How many cameras and 3D points do we have? Calculate the number of parameters to estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cameras: 394\n",
      "n_points: 100368\n",
      "Total number of parameters to estimate: 304650\n",
      "Total number of residuals: 1068816\n"
     ]
    }
   ],
   "source": [
    "n_cameras = camera_params.shape[0]  # Number of cameras\n",
    "n_points = points_3d.shape[0]   # Number of 3D points\n",
    "m = 2*points_2d.shape[0]    # 2 (x, y) eqs per point / observation\n",
    "n = 9*n_cameras+3*n_points  # Number of parameters to estimate\n",
    "\n",
    "print(\"n_cameras: {}\".format(n_cameras))\n",
    "print(\"n_points: {}\".format(n_points))\n",
    "print(\"Total number of parameters to estimate: {}\".format(n))\n",
    "print(\"Total number of residuals: {}\".format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose a relatively small problem to reduce computation time, but scipy's algorithm is capable of solving much larger problems, although required time will grow proportionally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the function which returns a vector of residuals. We use numpy vectorized computations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check function `fun` !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short review on Transformations\n",
    "\n",
    "Rodrigues Formula: $$\\mathbf{R}=\\cos \\theta \\mathbf{I}+(1-\\cos \\theta) \\mathbf{n n}^{\\mathrm{T}}+\\sin \\theta \\mathbf{n}^{\\wedge}$$\n",
    "If described by a rotation vector, assuming that the rotation axis is a unit length vector $\\mathbf{n}$ and the angle is $\\theta$, then the vector $\\theta \\mathbf{n}$ can also describe this rotation. Here, rot_vecs = $\\theta \\mathbf{n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(points, rot_vecs):\n",
    "    \"\"\"Rotate points by given rotation vectors.\n",
    "    \n",
    "    Rodrigues' rotation formula is used.\n",
    "    \"\"\"\n",
    "    theta = np.linalg.norm(rot_vecs, axis=1)[:, np.newaxis] #np.newaxis converts this into a column vector.\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        v = rot_vecs / theta\n",
    "        v = np.nan_to_num(v)\n",
    "    dot = np.sum(points * v, axis=1)[:, np.newaxis]\n",
    "    cos_theta = np.cos(theta)\n",
    "    sin_theta = np.sin(theta)\n",
    "    \n",
    "    return (cos_theta * points) + ((1 - cos_theta) * v * dot) + (sin_theta * np.cross(v, points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short review on camera modelling & radial distortion\n",
    "\n",
    "\n",
    "\n",
    "- Each pixel moves radially away from (barrel) or towards (pincushion) the image center (c).\n",
    "- As a function of distance from $c: r_{c}^{2}=x_{c}^{2}+y_{c}^{2}$.\n",
    "- The shift $\\gamma$ can be modelled as: $\\gamma=1+k_{1} r_{c}^{2}+k_{2} r_{c}^{4}$ where ${k}_{1}$ and ${k}_{2}$ are radial distortion parameters.\n",
    "- The modified co-ordinates are:\n",
    "\n",
    "$$\\begin{array}{l}\n",
    "\\hat{x}_{c}=\\gamma x_{c} \\\\\n",
    "\\hat{y}_{c}=\\gamma y_{c}\n",
    "\\end{array} \n",
    "$$\n",
    "\n",
    "- **This is applied before the focal-length multiplier and center shift are applied**: Meaning before $K$ matrix is even applied. But how do we exactly do that?\n",
    "\n",
    "    $$\\mathbf{K}=\\left[\\begin{array}{ccc}\\alpha_{x} & 0 & x_{0} \\\\0 & \\alpha_{y} & y_{0} \\\\0 & 0 & 1\\end{array}\\right] ; \\qquad      \\lambda {p} = \\mathrm{x} =K[R \\quad t] \\mathrm{X}$$\n",
    "\n",
    "    $$x_{final} = \\gamma \\left(\\frac{f_0X}{Z}+c_x \\right)\n",
    "     \\qquad \\color{red} \\bigotimes \\textbf{wrong}$$\n",
    "\n",
    "    $$x_{final} =  \\left(f_0 \\left(\\gamma\\frac{X}{Z} \\right)+c_x \\right)\n",
    "     \\qquad \\color{surd} \\checkmark \\textbf{correct}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing it up\n",
    "\n",
    "Let $\\pmb{P} = (X, Y, Z)^T$ - a radius-vector of a point, $\\pmb{R}$ - a rotation matrix of a camera, $\\pmb{t}$ - a translation vector of a camera, $f$ - its focal distance, $k_1, k_2$ - its distortion parameters. Then the reprojecting is done as follows:\n",
    "\n",
    "\\begin{align}\n",
    "\\pmb{Q} = \\pmb{R} \\pmb{P} + \\pmb{t} \\\\\n",
    "\\pmb{q} = -\\begin{pmatrix} Q_x / Q_z \\\\ Q_y / Q_z \\end{pmatrix} \\\\\n",
    "\\pmb{p} = f (1 + k_1 \\lVert \\pmb{q} \\rVert^2 + k_2 \\lVert \\pmb{q} \\rVert^4) \\pmb{q}\n",
    "\\end{align}\n",
    "The resulting vector $\\pmb{p}=(x, y)^T$ contains image coordinates of the original point.\n",
    "\n",
    "![radial_distortion_1.png](./../misc/radial_distortion_1.png) \n",
    "![radial_distortion_2.png](./../misc/radial_distortion_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(points, camera_params):\n",
    "    \"\"\"Convert 3-D points to 2-D by projecting onto images.\"\"\"\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    #\n",
    "    # TO DO : Implement this function based on the information mentioned above.\n",
    "    #\n",
    "    #############################\n",
    "    # print(\"=== Project function entrance ===\")\n",
    "    # print(f\"Points: {points.shape}\")    # n_obs, 3\n",
    "    # print(f\"Camera Parameters: {camera_params.shape}\")  # n_obs, 9\n",
    "    # Transform point in camera frame\n",
    "    pts_cam = rotate(points, camera_params[:,:3])   # Rotate\n",
    "    pts_cam = pts_cam + camera_params[:,3:6]    # Points in {camera}\n",
    "    # print(f\"Points in (cam): {pts_cam.shape}\")\n",
    "    # Points in homogeneous pixel coordinates (no dist. and focus)\n",
    "    qx = pts_cam[:, [0]]/pts_cam[:, [2]]\n",
    "    qy = pts_cam[:, [1]]/pts_cam[:, [2]]\n",
    "    q = -np.hstack((qx, qy)) # No focus and distortion yet\n",
    "    # print(f\"q (homogeneous unscaled): {q.shape}\")\n",
    "    # Apply distortion\n",
    "    norm_q = np.linalg.norm(q, axis=1).reshape(-1, 1)   # row-wise\n",
    "    # print(f\"q norm: {norm_q.shape}\")\n",
    "    k1 = camera_params[:, [7]]  # norm^2 - k1 parameter\n",
    "    k2 = camera_params[:, [8]]  # norm^4 - k2 parameter\n",
    "    # print(f\"K1: {k1.shape}, K2: {k2.shape}\")\n",
    "    d_vect = 1 + k1 * (norm_q**2) + k2 * (norm_q**4)    # Dist. vect.\n",
    "    # print(f\"Dist. vect: {d_vect.shape}\")\n",
    "    distq = d_vect * q  # Distortion applied\n",
    "    # print(f\"Distorted q: {distq.shape}\")\n",
    "    # Apply focus\n",
    "    f = camera_params[:,[6]]    # Focal length values\n",
    "    # print(f\"F: {f.shape}\")\n",
    "    points_proj = f * distq     # Projected points\n",
    "    # print(f\"Projected points: {points_proj.shape}\")\n",
    "    # print(\"=== Project function exit ===\")\n",
    "    # raise NotImplementedError(\"TODO - Hold on\")\n",
    "    return points_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(params, n_cameras, n_points, camera_indices, point_indices, points_2d):\n",
    "    \"\"\"Compute residuals.\n",
    "    \n",
    "    `params` contains camera parameters and 3-D coordinates.\n",
    "    \"\"\"\n",
    "    params = copy.deepcopy(params)\n",
    "    camera_params = params[:n_cameras * 9].reshape((n_cameras, 9))\n",
    "    \n",
    "    points_3d = params[n_cameras * 9:].reshape((n_points, 3))\n",
    "    points_proj = project(points_3d[point_indices], camera_params[camera_indices])\n",
    "    return (points_proj - points_2d).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short review on Structure from Motion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual\n",
    "\n",
    "In our lecture, in the residual vector, we  wrote the elements in order: 11, 12, 13.., 1N, then 21, 22.. and so on till MN. However, notice that it is not the case here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M -> camera, N -> 3D point (in our lectures, NOT in this code)\n",
    "\n",
    "![sfm_residual_1.png](./../misc/sfm_residual_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that computing Jacobian of `fun` is cumbersome, thus we will rely on the finite difference approximation. To make this process time feasible we provide Jacobian sparsity structure (i. e. mark elements which are known to be non-zero):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sfm_jac_2.png](./../misc/sfm_jac_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the matrix is sparse, we can make use of data structures that are meant for such a use case - https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.lil_matrix.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the matrix computation has been given to you, you will have to explain this function later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bundle_adjustment_sparsity(n_cameras, n_points, camera_indices, point_indices):\n",
    "\n",
    "    # print(f\"Num. Cameras: {n_cameras}\")\n",
    "    # print(f\"Num. Points: {n_points}\")\n",
    "    # print(f\"Cam. Indices: {camera_indices.shape}\")\n",
    "    # print(f\"Point Indices: {point_indices.shape}\")\n",
    "    # raise NotImplementedError(\"TODO: Work in progress\")\n",
    "    m = 2 * point_indices.shape[0]  # 2*num_obs: Num. rows in residual\n",
    "    n = 9*n_cameras + 3*n_points    # Number of paramters\n",
    "            \n",
    "    A = lil_matrix((m, n), dtype=int)\n",
    "\n",
    "    camera_indices = np.sort(camera_indices)\n",
    "    point_indices = np.sort(point_indices)\n",
    "    \n",
    "    i = np.arange(camera_indices.size)\n",
    "    for s in range(9):\n",
    "        A[2 * i, camera_indices * 9 + s] = 1\n",
    "        A[2 * i + 1, camera_indices * 9 + s] = 1\n",
    "\n",
    "    for s in range(3):\n",
    "        A[2 * i, n_cameras * 9 + point_indices * 3 + s] = 1\n",
    "        A[2 * i + 1, n_cameras * 9 + point_indices * 3 + s] = 1\n",
    "            \n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THAT'S IT! Now we are ready to use inbuilt library functions!\n",
    "\n",
    "Now we are ready to run optimization. Let's visualize residuals evaluated with the initial parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.hstack((camera_params.ravel(), points_3d.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = fun(x0, n_cameras, n_points, camera_indices, point_indices, points_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22d5c4c2ca0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1068816, 304650) 394 100368\n"
     ]
    }
   ],
   "source": [
    "A = bundle_adjustment_sparsity(n_cameras, n_points, camera_indices, point_indices)\n",
    "print(A.shape, n_cameras, n_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "\n",
    "Scipy has existing functions for optimization that we can make use of. Write a sentence about the method that is used for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1         4.5457e+06                                    4.04e+07    \n",
      "       1              7         4.5418e+06      3.91e+03       6.94e-02       4.05e+07    \n",
      "       2              8         4.5316e+06      1.02e+04       6.93e-02       4.06e+07    \n",
      "       3              9         4.5276e+06      4.06e+03       1.39e-01       4.08e+07    \n",
      "       4             10         4.5166e+06      1.09e+04       3.46e-02       4.09e+07    \n",
      "       5             11         4.5020e+06      1.46e+04       6.92e-02       4.10e+07    \n",
      "       6             13         4.4985e+06      3.52e+03       3.55e-02       4.10e+07    \n",
      "       7             14         4.4940e+06      4.52e+03       3.38e-02       4.11e+07    \n",
      "       8             15         4.4905e+06      3.46e+03       3.55e-02       4.11e+07    \n",
      "       9             16         4.4861e+06      4.46e+03       3.38e-02       4.12e+07    \n",
      "      10             17         4.4826e+06      3.42e+03       3.55e-02       4.12e+07    \n",
      "      11             18         4.4783e+06      4.38e+03       3.36e-02       4.13e+07    \n",
      "      12             19         4.4749e+06      3.35e+03       3.57e-02       4.13e+07    \n",
      "      13             20         4.4706e+06      4.33e+03       3.35e-02       4.14e+07    \n",
      "      14             21         4.4673e+06      3.33e+03       3.47e-02       4.14e+07    \n",
      "      15             22         4.4630e+06      4.22e+03       3.48e-02       4.14e+07    \n",
      "      16             23         4.4598e+06      3.25e+03       3.57e-02       4.15e+07    \n",
      "      17             24         4.4556e+06      4.19e+03       3.35e-02       4.15e+07    \n",
      "      18             25         4.4524e+06      3.22e+03       3.45e-02       4.16e+07    \n",
      "      19             26         4.4483e+06      4.09e+03       3.50e-02       4.16e+07    \n",
      "      20             27         4.4452e+06      3.14e+03       3.55e-02       4.17e+07    \n",
      "      21             28         4.4411e+06      4.05e+03       3.38e-02       4.17e+07    \n",
      "      22             29         4.4380e+06      3.09e+03       3.45e-02       4.18e+07    \n",
      "      23             30         4.4340e+06      3.97e+03       3.50e-02       4.18e+07    \n",
      "      24             31         4.4310e+06      3.05e+03       3.55e-02       4.18e+07    \n",
      "      25             32         4.4271e+06      3.89e+03       3.35e-02       4.19e+07    \n",
      "      26             33         4.4241e+06      2.98e+03       3.58e-02       4.19e+07    \n",
      "      27             34         4.4203e+06      3.83e+03       3.35e-02       4.20e+07    \n",
      "      28             35         4.4173e+06      2.95e+03       3.40e-02       4.20e+07    \n",
      "      29             36         4.4136e+06      3.75e+03       3.55e-02       4.21e+07    \n",
      "      30             37         4.4107e+06      2.87e+03       3.57e-02       4.21e+07    \n",
      "      31             38         4.4070e+06      3.69e+03       3.35e-02       4.21e+07    \n",
      "      32             43         4.4070e+06      0.00e+00       0.00e+00       4.21e+07    \n",
      "`xtol` termination condition is satisfied.\n",
      "Function evaluations 43, initial cost 4.5457e+06, final cost 4.4070e+06, first-order optimality 4.21e+07.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "# So far: method='lm'\n",
    "res = least_squares(fun, x0, jac_sparsity=A, verbose=2, x_scale='jac', ftol=1e-4, method='trf',\n",
    "                    args=(n_cameras, n_points, camera_indices, point_indices, points_2d))\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = res.x\n",
    "\n",
    "new_camera_params = params[:n_cameras * 9].reshape((n_cameras, 9))\n",
    "new_points_3d = params[n_cameras * 9:].reshape((n_points, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Optimised Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(new_points_3d)\n",
    "cf = o3d.geometry.TriangleMesh.create_coordinate_frame(2)\n",
    "o3d.visualization.draw_geometries([pcd, cf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Older point cloud, just for reference\n",
    "# Geometries\n",
    "cf = o3d.geometry.TriangleMesh.create_coordinate_frame(2)\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points_3d)\n",
    "o3d.visualization.draw_geometries([pcd, cf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting `scaling='jac'` was done to automatically scale the variables and equalize their influence on the cost function (clearly the camera parameters and coordinates of the points are very different entities). This option turned out to be crucial for successfull bundle adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization took 251 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimization took {0:.0f} seconds\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot residuals at the found solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22d5dcf5be0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**This might not have worked as expected**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see much better picture of residuals now, with the mean being very close to zero. There are some spikes left. It can be explained by outliers in the data, or, possibly, the algorithm found a local minimum (very good one though) or didn't converged enough. Note that the algorithm worked with Jacobian finite difference aproximate, which can potentially block the progress near the minimum because of insufficient accuracy (but again, computing exact Jacobian for this problem is quite difficult).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2- Part B: Submission details\n",
    "\n",
    "You are supposed to gain understanding by playing around with the code above and submit your answers to questions asked below. You shouldn't submit this whole notebook, just copy the following cells (starting next cell up until the end of this notebook) and paste it at the end of your Project 2 notebook (already shared on GitHub classrooms, [link](https://github.com/AryanSakaria/Project_2/blob/main/Project_2.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SfM pipeline (`6 mark`)\n",
    "\n",
    "To get the context of below questions, take a look at the code above: The same questions have been asked at different places above as comments in the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "1. `0.5 mark` **Basics** - How do we know this (`camera_ind`) information in practical setting? In other words, how do we know observations in `points_2d` belong to which camera. Explain. \n",
    "    - Ans-1 - Basics:\n",
    "    \n",
    "    \n",
    "2. `0.5 mark` **Basics** - How do we know this (`point_ind`) information in practical setting?  In other words, how do we know observations in `points_2d` belong to which 3D point. Explain.\n",
    "    - Ans-2 - Basics: \n",
    "    \n",
    "3. `0.5 mark` **Transformations** - `rotate()` function: Why do we use the rodriquez formula? How is this representation different from the standard 3x3 Rotation matrix, why do we use this instead?\n",
    "    - Ans-3 - Transformations: \n",
    "\n",
    "    \n",
    "4. `0.5 mark` **Transformations** - `project()` function: In the `project()` function, would it make any difference if I do translate first, then rotate? Why/why not?\n",
    "    - Ans-4 - Transformations: \n",
    "        \n",
    "        \n",
    "5. `0.5 mark` **Jacobian** - `bundle_adjustment_sparsity()` function: m above is not \"M*N\" (*2) unlike our lecture notes. Why is that so?\n",
    "    - Ans-5 - Jacobian:\n",
    "    \n",
    "6. `2 mark` **Jacobian & Parameters** - `bundle_adjustment_sparsity()` function: \n",
    "    1.  Why are we doing `n_cameras * 9` here instead of `n_cameras * 12`? Recollect: Every individual motion Jacobian was (1*)12 in our lecture notes. \n",
    "        - Ans 6.1 - Jacobian & Parameters: \n",
    "        \n",
    "    2. Ignoring the scale parameters, what was the number of unknown parameters in our lecture notes in terms of `n_cameras` and `n_points`? What is it here in the code? Is it different? If so, what is and why? [Link of notes](https://www.notion.so/Stereo-Structure-from-Motion-9fdd81e4194f4803ac9ba7552df56470).\n",
    "        - Ans 6.2 - Jacobian & Parameters:        \n",
    "            \n",
    "            \n",
    "7. `6 mark` **Sparsity, Residual Vector & Jacobian** - `bundle_adjustment_sparsity()` function: Explain what you understand from above 6 lines of code by coding a simple toy example yourself to illustrate how it is different from what you've learnt in class. ([Coding toy example + elaborating in words]- both are compulsory.) For the toy example, you can take something like 3 points all seen from 3 cameras. (You don't actually have to code much, just need to call the existing function) Write that toy example after this cell\n",
    "    - Ans 6 - Sparsity, Residual Vector & Jacobian: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 1\n",
    "\n",
    "In a practical setting, we will be given the cameras with images, or some identifier associated with images (which could help us find which camera they were taken with). If we're directly given cameras (with say images in the memory) or likewise, the our job is simply a dictionary storage and search (we know the camera each image belongs to).\n",
    "\n",
    "If we're not given that data, just a set of images from a source like flickr, then we might want to inspect image properties like the user who uploaded it (they likely used the same camera), metadata information, etc. to find the camera a particular image was taken with.\n",
    "\n",
    "Note that we could also associate images with common camera models (in the worst case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 2\n",
    "\n",
    "This could be obtained if we have a depth sensor in our setup (which could give us something like a point cloud). Then, if our cameras are calibrated, we can find the projected ray (of a pixel) in 3D space, and run a linear search along that ray to see which point in the point cloud it approximately hits. This will give us the correspondence for 2D (point in image) to 3D (point in real world).\n",
    "\n",
    "If we do not have a depth sensor, then we may need at least two images of the scene for which we know the focal lengths, and these have a good baseline and rotation. We can then find the corresponding 3D point through triangulation: project the rays of the pixels in the images and see where they meet in 3D space. Note that since we _already_ have a set of 3D points (through our initial estimates), we'll have to associate on something like a nearest neighbor basis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 3\n",
    "\n",
    "The [Rodrigues' rotation formula](https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula) is basically a conversion through a [matrix exponential](https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation#Exponential_map_from_%F0%9D%94%B0%F0%9D%94%AC(3)_to_SO(3)) (we get the result directly through taylor expansion). It converts a vector of three numbers (denoted by $\\theta\\mathbf{\\hat{n}}$) into a rotation matrix. We use this property here to transform / rotate the points.\n",
    "\n",
    "A standard rotation matrix, represented by group $\\textup{SO}(3)$ is a 3-by-3 orthogonal matrix. It has 9 elements with 6 constraints (rotations in 3D space have 3 degrees of freedom). This creates a complex manifold, on which we cannot run optimization processes easily. Rotation matrices cannot be simply added, they have to be multiplied (they follow a separate lie algebra).\n",
    "\n",
    "On the other hand, the exponential representation allows us to have fewer numbers (just 3, which is the minimal). It can also be added to a better degree (unless the addition leads to a singularity). It's manifold is more easier to optimize on, therefore it is used instead.\n",
    "\n",
    "Another option is to use quaternions, which are 4 number representations and have no singularity issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 4\n",
    "\n",
    "Yes. It would make a difference. The correct point is obtained by doing the rotation first, and then translation. Basically, the order of rotation and translation matter. This is because if we translate first, we've basically shifted our origin (we've reached some other place in the world, defined by our _original_ axis, not _rotated_ axis). Now, no rotation can get us to the desired origin (origin defined in the _rotated_ axis, which is the translation vector).\n",
    "\n",
    "Basically, the homogeneous transform is $\\mathbf{p}_{final} = \\mathbf{R} \\times \\mathbf{p} + \\mathbf{t}$ and not $\\mathbf{p}_{final} = \\mathbf{R} \\times (\\mathbf{p} + \\mathbf{t})$. Both these results are two completely different points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 5\n",
    "\n",
    "In the lecture notes, the number of points is $n$ and the number of cameras is $m$. It is assumed that _every_ point is captured by _every_ camera, yielding us $mn$ pixels (observations). Since each pixel has 2 values (the $x$ and $y$), we got $2mn$ rows for the jacobian (residual will also have the same number of rows).\n",
    "\n",
    "However, in practice, such an assumption does not hold very well. We might not observe all of the $n$ points in each of the $m$ images. We will only observe a few points of interest in each image (every image will not have some points of interest and may contain some new points of interest). Due to this, the number of rows of the jacobian (or the length of the residual) is actually $2n_{obs}$ (where $n_{obs}$ is the number of observations). The value of $2mn$ is sort of an upper bound.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 6\n",
    "\n",
    "**6.1**: **Individual Motion Jacobian** size is `n_cameras * 9`\n",
    "\n",
    "It all depends on the way we parameterize the camera projection matrix. In the notes, each camera is assumed to have 5 parameters for the intrinsics (two focal lengths, two center offsets, and one pixel shear), 6 parameters for extrinsics (3 for rotation and 3 for translation). Here, these are reduced to only the focal length and two distortion parameters for intrinsics, while the 6 parameters for the extrinsics remain (3 each for rotation and translation).\n",
    "\n",
    "Hence, the camera here is parameterized by only 9 numbers, instead of 12. This reduces the size of every individual motion jacobian.\n",
    "\n",
    "**6.2**: **Number of parameters** for the jacobian\n",
    "\n",
    "The number of parameters in the notes is $12m+3n$ where $m$ is number of cameras (value of `n_cameras` here) and $n$ is the number of 3D points being estimated (value of `n_points` here). This was because there were 12 parameters for every camera and 3 parameters for every point (that was to be found). Here, the number of parameters for every camera is just 9. Hence, the number of parameters here is $9m+3n$.\n",
    "\n",
    "The number of variables / parameters by each camera has reduced from 12 to 9. The number of parameters by each 3D point still remains 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 7\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initializing R,t and 3D points for SfM given 2 images (`4 mark`)\n",
    "\n",
    "Using OpenCV functions, mention how you would initialize R,t (poses) and 3D points for SfM given 2 images and K matrix. You don't need to implement it, just mention function names with input/output arguments clearly and briefly explain what they do (You don't need to give detailed answers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
