{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is project-2 which will get you familiar with Structure from Motion and a rudimentary stereo SLAM pipeline. This notebook is not meant for coding, refer to the notebooks in `questions/` for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team Name**: `MR21_3241`\n",
    "\n",
    "**Members**: `2021701032` (Avneesh Mishra), `2019111041` (Prateek Sancheti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Instructions:\n",
    "1. Zip the entire folder, not just this notebook, and submit on Moodle. \n",
    "2. Be sure to solve all questions that are in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment will take around 10-12 hours, so be sure to split the work equally. A recommendation to split the work would be to have one person start with stereo, the other with bundle adjustment, and then both switch to completing the PnP and ICP parts. This is because question-1 and 2 are separate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Stereo, PnP, and ICP\n",
    "\n",
    "Time: ~6-7 Hours\n",
    "\n",
    "This question has been designed to test your understanding of the concepts that create a SLAM system, from creating a front-end using Stereo Matching to a backend where you optimise to get your odometry to stitch the pointclouds obtained from the front end to build a map of the environment.\n",
    "\n",
    "The dataset has been provided in `data/`, where `img2` and `img3` correspond to the left and right camera images respectively. File `poses.txt` has the pose information for all frames. File `calib.txt` has camera calibration information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Bundle Adjustment\n",
    "\n",
    "Time: ~2-3 Hours\n",
    "\n",
    "This question will walk you through a simple implementation of Bundle Adjustment and run it on a a small dataset. Most of the weightage for this is in the theory part, where you have to explain the method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: Part-B Submission\n",
    "\n",
    "As instructed in the notebook `Bundle Adjustment.ipynb`, the answers to the questions are attached below. The sections contain questions (as they are provided) followed by sections for answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SfM pipeline (`6 mark`)\n",
    "\n",
    "To get the context of below questions, take a look at the code above: The same questions have been asked at different places above as comments in the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "1. `0.5 mark` **Basics** - How do we know this (`camera_ind`) information in practical setting? In other words, how do we know observations in `points_2d` belong to which camera. Explain. \n",
    "    - Ans-1 - Basics:\n",
    "    \n",
    "    \n",
    "2. `0.5 mark` **Basics** - How do we know this (`point_ind`) information in practical setting?  In other words, how do we know observations in `points_2d` belong to which 3D point. Explain.\n",
    "    - Ans-2 - Basics: \n",
    "    \n",
    "3. `0.5 mark` **Transformations** - `rotate()` function: Why do we use the rodriquez formula? How is this representation different from the standard 3x3 Rotation matrix, why do we use this instead?\n",
    "    - Ans-3 - Transformations: \n",
    "\n",
    "    \n",
    "4. `0.5 mark` **Transformations** - `project()` function: In the `project()` function, would it make any difference if I do translate first, then rotate? Why/why not?\n",
    "    - Ans-4 - Transformations: \n",
    "        \n",
    "        \n",
    "5. `0.5 mark` **Jacobian** - `bundle_adjustment_sparsity()` function: m above is not \"M*N\" (*2) unlike our lecture notes. Why is that so?\n",
    "    - Ans-5 - Jacobian:\n",
    "    \n",
    "6. `2 mark` **Jacobian & Parameters** - `bundle_adjustment_sparsity()` function: \n",
    "    1.  Why are we doing `n_cameras * 9` here instead of `n_cameras * 12`? Recollect: Every individual motion Jacobian was (1*)12 in our lecture notes. \n",
    "        - Ans 6.1 - Jacobian & Parameters: \n",
    "        \n",
    "    2. Ignoring the scale parameters, what was the number of unknown parameters in our lecture notes in terms of `n_cameras` and `n_points`? What is it here in the code? Is it different? If so, what is and why? [Link of notes](https://www.notion.so/Stereo-Structure-from-Motion-9fdd81e4194f4803ac9ba7552df56470).\n",
    "        - Ans 6.2 - Jacobian & Parameters:        \n",
    "            \n",
    "            \n",
    "7. `6 mark` **Sparsity, Residual Vector & Jacobian** - `bundle_adjustment_sparsity()` function: Explain what you understand from above 6 lines of code by coding a simple toy example yourself to illustrate how it is different from what you've learnt in class. ([Coding toy example + elaborating in words]- both are compulsory.) For the toy example, you can take something like 3 points all seen from 3 cameras. (You don't actually have to code much, just need to call the existing function) Write that toy example after this cell\n",
    "    - Ans 6 - Sparsity, Residual Vector & Jacobian: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers: SfM Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 1\n",
    "\n",
    "In a practical setting, we will be given the cameras with images, or some identifier associated with images (which could help us find which camera they were taken with). If we're directly given cameras (with say images in the memory) or likewise, the our job is simply a dictionary storage and search (we know the camera each image belongs to).\n",
    "\n",
    "If we're not given that data, just a set of images from a source like flickr, then we might want to inspect image properties like the user who uploaded it (they likely used the same camera), metadata information, etc. to find the camera a particular image was taken with.\n",
    "\n",
    "Note that we could also associate images with common camera models (in the worst case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 2\n",
    "\n",
    "This could be obtained if we have a depth sensor in our setup (which could give us something like a point cloud). Then, if our cameras are calibrated, we can find the projected ray (of a pixel) in 3D space, and run a linear search along that ray to see which point in the point cloud it approximately hits. This will give us the correspondence for 2D (point in image) to 3D (point in real world).\n",
    "\n",
    "If we do not have a depth sensor, then we may need at least two images of the scene for which we know the focal lengths, and these have a good baseline and rotation. We can then find the corresponding 3D point through triangulation: project the rays of the pixels in the images and see where they meet in 3D space. Note that since we _already_ have a set of 3D points (through our initial estimates), we'll have to associate on something like a nearest neighbor basis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 3\n",
    "\n",
    "The [Rodrigues' rotation formula](https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula) is basically a conversion through a [matrix exponential](https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation#Exponential_map_from_%F0%9D%94%B0%F0%9D%94%AC(3)_to_SO(3)) (we get the result directly through taylor expansion). It converts a vector of three numbers (denoted by $\\theta\\mathbf{\\hat{n}}$) into a rotation matrix. We use this property here to transform / rotate the points.\n",
    "\n",
    "A standard rotation matrix, represented by group $\\textup{SO}(3)$ is a 3-by-3 orthogonal matrix. It has 9 elements with 6 constraints (rotations in 3D space have 3 degrees of freedom). This creates a complex manifold, on which we cannot run optimization processes easily. Rotation matrices cannot be simply added, they have to be multiplied (they follow a separate lie algebra).\n",
    "\n",
    "On the other hand, the exponential representation allows us to have fewer numbers (just 3, which is the minimal). It can also be added to a better degree (unless the addition leads to a singularity). It's manifold is more easier to optimize on, therefore it is used instead.\n",
    "\n",
    "Another option is to use quaternions, which are 4 number representations and have no singularity issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 4\n",
    "\n",
    "Yes. It would make a difference. The correct point is obtained by doing the rotation first, and then translation. Basically, the order of rotation and translation matter. This is because if we translate first, we've basically shifted our origin (we've reached some other place in the world, defined by our _original_ axis, not _rotated_ axis). Now, no rotation can get us to the desired origin (origin defined in the _rotated_ axis, which is the translation vector).\n",
    "\n",
    "Basically, the homogeneous transform is $\\mathbf{p}_{final} = \\mathbf{R} \\times \\mathbf{p} + \\mathbf{t}$ and not $\\mathbf{p}_{final} = \\mathbf{R} \\times (\\mathbf{p} + \\mathbf{t})$. Both these results are two completely different points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 5\n",
    "\n",
    "In the lecture notes, the number of points is $n$ and the number of cameras is $m$. It is assumed that _every_ point is captured by _every_ camera, yielding us $mn$ pixels (observations). Since each pixel has 2 values (the $x$ and $y$), we got $2mn$ rows for the jacobian (residual will also have the same number of rows).\n",
    "\n",
    "However, in practice, such an assumption does not hold very well. We might not observe all of the $n$ points in each of the $m$ images. We will only observe a few points of interest in each image (every image will not have some points of interest and may contain some new points of interest). Due to this, the number of rows of the jacobian (or the length of the residual) is actually $2n_{obs}$ (where $n_{obs}$ is the number of observations). The value of $2mn$ is sort of an upper bound.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 6\n",
    "\n",
    "**6.1**: **Individual Motion Jacobian** size is `n_cameras * 9`\n",
    "\n",
    "It all depends on the way we parameterize the camera projection matrix. In the notes, each camera is assumed to have 5 parameters for the intrinsics (two focal lengths, two center offsets, and one pixel shear), 6 parameters for extrinsics (3 for rotation and 3 for translation). Here, these are reduced to only the focal length and two distortion parameters for intrinsics, while the 6 parameters for the extrinsics remain (3 each for rotation and translation).\n",
    "\n",
    "Hence, the camera here is parameterized by only 9 numbers, instead of 12. This reduces the size of every individual motion jacobian.\n",
    "\n",
    "**6.2**: **Number of parameters** for the jacobian\n",
    "\n",
    "The number of parameters in the notes is $12m+3n$ where $m$ is number of cameras (value of `n_cameras` here) and $n$ is the number of 3D points being estimated (value of `n_points` here). This was because there were 12 parameters for every camera and 3 parameters for every point (that was to be found). Here, the number of parameters for every camera is just 9. Hence, the number of parameters here is $9m+3n$.\n",
    "\n",
    "The number of variables / parameters by each camera has reduced from 12 to 9. The number of parameters by each 3D point still remains 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 7\n",
    "\n",
    "> **Note**: Please do not run the code cells here, run them in the `Bundle Adjustment.ipynb` notebook (in the end). The functions are declared there.\n",
    "\n",
    "For this example code, the given sample scenario is considered. There are 3 points in the environment (each having its own X, Y, Z). Each of these three points is captured by each of the three cameras in the environment.\n",
    "\n",
    "The images taken by these cameras will have many pixels (ideally), but for this problem, let's say that we already have an algorithm that detects these points in images (maybe these points could have different colors), and returns those pixel coordinates. So from each image / camera, we get three pixel coordinates (x, y values of pixel in image, could be from the center of image, not the top left corner frame; as is here). So, we have 9 pixels in total (3 pixels from each of 3 cameras). These nine pixels have a pixel to world point correspondence (`point_indices` in the code above) and they also have pixel to camera correspondence (`camera_indices` in the code above). Note that the correspondence here, just says _which_ point or camera (depending on the array) does the particular pixel represent or belong to.\n",
    "\n",
    "For the code below, the following variable definitions can be noted\n",
    "- `m_cams`: Number of cameras in the scene. 3 in our case.\n",
    "- `n_pts`: Number of 3D points in the scene. 3 in our case.\n",
    "- `pt_is`: The correspondence of the 9 pixels (from the camera images) to the points in the world. Let's assume that our detection and stacking algorithm gave this (in a practical setting).\n",
    "- `cam_is`: The correspondence of the 9 pixels to the cameras in the world. Since we know which camera took which image, this can be readily obtained.\n",
    "- `c`: This is the _sparse jacobian matrix_ returned by `bundle_adjustment_sparsity`. The code above described this as `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cams = 3\n",
    "n_pts = 3\n",
    "# Points seen (concatenated in image vector, like points_2d)\n",
    "pt_is = np.array([0, 1, 2, 0, 1, 2, 0, 1, 2])   # World points (corr)\n",
    "# Points taken from camera (correspondence for vector like points_2d)\n",
    "cam_is = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])  # Camera (corr)\n",
    "c = bundle_adjustment_sparsity(m_cams, n_pts, cam_is, pt_is)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the Jacobian as an image. Note that only the grid intersection values matter here (kind of how the image can be visualized as a matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian shape is: (18, 36)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "plt.title(\"Jacobian\")\n",
    "plt.imshow(c.toarray())\n",
    "plt.grid(True)\n",
    "plt.yticks(np.arange(2*m_cams*n_pts))\n",
    "plt.xticks(np.arange(9*m_cams+3*n_pts))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(f\"Jacobian shape is: {c.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the residuals (using the function `fun` above), we'll first need our parameter estimates, as well as pixel locations of the points in the image. Let's start with parameter estimates first. We have 9 parameters per camera (3 cameras) and 3 parameters per 3D point (3 points). This parameter vector is stored in `ev`. This is same as `x0` in the code above (initial estimates). However, we'll just use random data here (in a realistic setting, this should be initial estimates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 camera parameters of m_cams: camera_params (initial estimate)\n",
    "cx_params = np.random.rand(9 * m_cams)\n",
    "# 3 initial estimates of n_pts: points_3d\n",
    "px_params = np.random.rand(3 * n_pts)\n",
    "# Parameter vector\n",
    "ev = np.hstack((cx_params, px_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image too has to be created. We'll simply assume that we have the image pixels and we'll store them in `pix_2d_vect` here. This is similar to the `points_2d` (pixels in 2D) described in code above. Note that we have 3 cameras and each camera gives three pixels (each pixel has 2 values: x, y arranged as columns). Therefore, the first three rows is from camera 1, then from camera 2, then from camera 3. Check the `cam_is` above (camera correspondence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixels of the images\n",
    "pix_2d_vect = np.random.rand(3 * m_cams, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can compute the residuals (the error in the projection and actual pixels) using the `fun` function. The residuals here is described as `rvect`. In the code above, we passed this (callable function for residuals) to the function [least_squares](https://scipy.github.io/devdocs/reference/generated/scipy.optimize.least_squares.html#scipy.optimize.least_squares) for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual shape: (18,)\n"
     ]
    }
   ],
   "source": [
    "# Compute the residuals\n",
    "rvect = fun(ev, m_cams, n_pts, cam_is, pt_is, pix_2d_vect)\n",
    "print(f\"Residual shape: {rvect.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old parameter vector shape: (36,)\n",
      "New parameter vector shape: (36,)\n"
     ]
    }
   ],
   "source": [
    "# Single stage of Gradient Descent like step\n",
    "Jc = c.toarray()\n",
    "d_ev = Jc.T @ rvect  # Change in paraemters\n",
    "ev_new = ev - (0.01) * d_ev\n",
    "print(f\"Old parameter vector shape: {ev.shape}\")\n",
    "print(f\"New parameter vector shape: {ev_new.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes a brief step of the optimization process. The non-linear least squares solver used in the code above is _much_ more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initializing R,t and 3D points for SfM given 2 images (`4 mark`)\n",
    "\n",
    "Using OpenCV functions, mention how you would initialize R,t (poses) and 3D points for SfM given 2 images and K matrix. You don't need to implement it, just mention function names with input/output arguments clearly and briefly explain what they do (You don't need to give detailed answers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: Initial estimates for SfM\n",
    "\n",
    "The SfM algorithm (or Bundle Adjustment) requires 'good enough' estimates to converse fast and to a good optima. The process is described in the next two cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R and t estimates for camera\n",
    "\n",
    "To estimate R, t and the 3D points (as initial estimates), we'll need some way to triangulate them (if we're only given images and the camera intrinsics). Here's briefly how we can go about getting the initial estimates\n",
    "\n",
    "1. It is assumed that there is an algorithm that has given us the pixel correspondences ([SIFT](https://docs.opencv.org/4.x/d7/d60/classcv_1_1SIFT.html) or some [keypoint detection and matching](https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html) can be used along with some neighborhood estimates or embedding formation).\n",
    "2. Knowing the corresponding pixels, and given the camera intrinsic parameters we can use 5 point algorithm solvers to estimate the essential matrix. This can be done through the function [findEssentialMat](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gad245d60e64d0c1270dbfd0520847bb87). This essential matrix includes the baseline information (vector as skew symmetric cross product matrix) and the rotation matrix.\n",
    "3. Decompose the essential matrix to obtain the possible translation vector (baseline) and rotation matrices. This uses an SVD technique and is implemented in [decomposeEssentialMat](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga54a2f5b3f8aeaf6c76d4a31dece85d5d). These two steps (2 and 3) can also be done directly, through one function call, using [recoverPose](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga1b2f149ee4b033c4dfe539f87338e243). \n",
    "\n",
    "This solves our problem of finding the initial estimates of camera poses. That is, we have the initial estimates of the camera parameters given by R, t and we already have the K matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimates for the 3D points\n",
    "\n",
    "To find the initial estimates of the 3D points, either of the two methods can be used\n",
    "\n",
    "1. **Triangulate points** directly: This can be done if we have the camera projection matrices (we already have calibrated cameras / we know the intrinsics). A set of feature points / corresponding pixels can be triangulated (project rays outwards and see where they meet) using the function [triangulatePoints](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gad3fc9a0c82b08df034234979960b778c). It takes in the projection matrices of the cameras (given by $P$) and the corresponding points, and returns the 3D points (in homogeneous coordinates). This can then be used to get the euclidean 3D points. This is just a function call, but requires very good correspondence estimates.\n",
    "\n",
    "2. Find points through **stereo to depth**: Here, we first create the two images into a stereo pair (hopefully there is a good enough baseline). We already know the rotation and translation between the cameras (through the previous steps). \n",
    "    1. We can now undistort the images. This can be done by first using [stereoRectify](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga617b1685d4059c6040827800e72ad2b6) to get the homographies. The results of this can actually also be used to verify the estimates of R and t for the camera. This function returns the rectification / rotation transform that must be applied to the images. We could directly do $KRK^{-1}$ to the homogeneous coordinates of the pixels. However, using OpenCV would entail two function calls. We can undistort the images (and convert them into _stereo rectified image pairs_) by using [initUndistortRectifyMap](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a) (which will give the two output maps) and [remap](https://docs.opencv.org/4.x/da/d54/group__imgproc__transform.html#gab75ef31ce5cdfb5c44b6da5f3b908ea4) (which will apply the mapping) in succession for both the images, (as shown in [this](https://python.plainenglish.io/the-depth-i-stereo-calibration-and-rectification-24da7b0fb1e0) tutorial).\n",
    "        \n",
    "        On a side-note: In case we do not have calibrated cameras (we don't know the intrinsics), we can use [stereoRectifyUncalibrated](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gaadc5b14471ddc004939471339294f052) and the resulting output rectification homography matrix can be used to rectify the images into a stereo pair. However, we will need the focal length for reprojection to 3D.\n",
    "    \n",
    "    2. After stereo rectification, we can find the disparity map using any of the [stereo matchers](https://docs.opencv.org/4.x/d2/d6e/classcv_1_1StereoMatcher.html). Let's say we pick [StereoBM](https://docs.opencv.org/4.x/d9/dba/classcv_1_1StereoBM.html#a04fdf00525f82fe708d556e2cd359004). We then use [compute](https://docs.opencv.org/4.x/d2/d6e/classcv_1_1StereoMatcher.html#a03f7087df1b2c618462eb98898841345) to obtain the disparity map from the left and right images (that are rectified).\n",
    "    3. After the disparity map is obtained, we can use [reprojectImageTo3D](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga1bc1152bd57d63bc524204f21fde6e02) to get the 3D point cloud. The function will use an output of stereo rectify that contains information on how to project the points in the undistorted images to 3D (using the disparity). This is shown as $Q$ in the argument list.\n",
    "    4. Now, we can find the points of interest in this point cloud using search techniques, or scanning along the projected rays of the corresponding pixels.\n",
    "\n",
    "Using either of the above two methods would give us good enough initial estimates of the 3D points. The latter is actually implemented (steps after stereo rectification) in the `StereoSLAM` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
