{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-confirmation",
   "metadata": {},
   "source": [
    "# Question 4: General Theory/Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-cleaners",
   "metadata": {},
   "source": [
    "_No need to be verbose, it's not fun for anyone_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-hindu",
   "metadata": {},
   "source": [
    "1. What part of S**L**A**M** did this project deal with? Why? What does the other part deal with and how would it generally work, given that you only have LIDAR scans, RGB video stream, and noisy pose data for a moving robot?\n",
    "\n",
    "\n",
    "2. Loop closures play an important role in reducing drift, how would you go about detecting these?\n",
    "\n",
    "\n",
    "3. Explain the structure of your Jacobian. Is the pose-graph fully connected? Why/Why not?\n",
    "\n",
    "\n",
    "4. With what you know now, how would you describe and differentiate the SLAM frontend and backend? Why do we need to optimise our poses/map in the first place - where does the noise come from/why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 1: Parts of SLAM\n",
    "\n",
    "The project deals with the **Localization** aspect of SLAM, using an optimization problem (_pose graph optimization_). Here, the vertices (states) were given, and they had to be optimized using odometry and loop closure constraints.\n",
    "\n",
    "The other part is **Mapping** and it deals with tracking the pose of landmarks in a map (usually a global coordinate system). This entails adding state vectors of each landmark and successively updating their estimated position using a filter (like Bayes filter or a Kalman Filter). Usually, these new states (landmarks) have no motion model (they're assumed to be fixed in the global frame). SLAM entails simultaneous optimization (or finding) of both the position(s) of the robot in global frame (**localization**) and the pose of landmarks in the global frame (**mapping**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a robot with noisy motion data and sensors, one might run some feature detection or object detection algorithm to find landmarks (a pose estimation algorithm may also be needed to find the poses / positions of landmarks in the local environment). One approach could be to keep a track of a certain number of features that have very less noise in detection. These could also be cross-checked with some loop-closure algorithms (if there is a loop closure, you would also expect similar landmarks to be around). \n",
    "\n",
    "Note that local detections can be transformed to the global frame using homogeneous transformations and the current estimate of states. As the state estimates get better, so does the map.\n",
    "\n",
    "When using a filter, a model of the measurements given the map and pose may be needed (along with the motion model). Beliefs could be updated using a method similar to Bayes' Rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 2: Loop Closure\n",
    "\n",
    "Odometry can deviate and accumulate errors over time. Loop closures allow us to reduce localization error upon detection. There could be methods based on\n",
    "\n",
    "- Clustering features and running neighborhood based pattern matching: where a graph of features and neighborhood information can be stored (in a quickly searchable manner), and new features sensed can be queried to find earlier occurrences.\n",
    "- Backtracking state-space trees can also be used for detecting loop closures. A method employing branch-and-bound approach is explored in [Wolfgang Hess, et al. 2016](https://doi.org/10.1109/ICRA.2016.7487258)\n",
    "- Local shape and color information can be used, while extending the bag-of-words method. A such visual bag of words method is demonstrated in [A. Angeli, et al. 2008](https://doi.org/10.1109/TRO.2008.2004514). Another reference can be [Nishant Kejriwal, et al.](https://doi.org/10.1016/J.ROBOT.2015.12.003)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 3: Jacobian and Pose Graph connectivity\n",
    "\n",
    "The Jacobian was visualized as an image in `Question 2` (2D SLAM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jacobian as an image is shown below\n",
    "\n",
    "![Jacobian Matrix as an image](./results/q4/jac_1.jpg)\n",
    "\n",
    "It is observable that it is very sparse (many values are 0), indicating that there are very few states involved in each constraint (two in our case). This is because the jacobian is simply the derivative of the constraint equations w.r.t. the states.\n",
    "\n",
    "The jacobian matrix is a 420 by 360 matrix (there are 420 constraints and 360 states). Out of the 420 constraints, 357 are odometry (= 119 * 3), 60 are loop closure (= 20 * 3), 3 are zero constraint (= 3 * 1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8425e5333de65a039bbcffbbf070e00567276e57b2a8c30426dd1ecf8bc06755"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('mr-cs7-503': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
