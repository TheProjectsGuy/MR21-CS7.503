{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-confirmation",
   "metadata": {},
   "source": [
    "# Question 4: General Theory/Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-cleaners",
   "metadata": {},
   "source": [
    "_No need to be verbose, it's not fun for anyone_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-hindu",
   "metadata": {},
   "source": [
    "1. What part of S**L**A**M** did this project deal with? Why? What does the other part deal with and how would it generally work, given that you only have LIDAR scans, RGB video stream, and noisy pose data for a moving robot?\n",
    "\n",
    "\n",
    "2. Loop closures play an important role in reducing drift, how would you go about detecting these?\n",
    "\n",
    "\n",
    "3. Explain the structure of your Jacobian. Is the pose-graph fully connected? Why/Why not?\n",
    "\n",
    "\n",
    "4. With what you know now, how would you describe and differentiate the SLAM frontend and backend? Why do we need to optimise our poses/map in the first place - where does the noise come from/why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 1: Parts of SLAM\n",
    "\n",
    "The project deals with the **Localization** aspect of SLAM, using an optimization problem (_pose graph optimization_). Here, the vertices (states) were given, and they had to be optimized using odometry and loop closure constraints.\n",
    "\n",
    "The other part is **Mapping** and it deals with tracking the pose of landmarks in a map (usually a global coordinate system). This entails adding state vectors of each landmark and successively updating their estimated position using a filter (like Bayes filter or a Kalman Filter). Usually, these new states (landmarks) have no motion model (they're assumed to be fixed in the global frame). SLAM entails simultaneous optimization (or finding) of both the position(s) of the robot in global frame (**localization**) and the pose of landmarks in the global frame (**mapping**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a robot with noisy motion data and sensors, one might run some feature detection or object detection algorithm to find landmarks (a pose estimation algorithm may also be needed to find the poses / positions of landmarks in the local environment). One approach could be to keep a track of a certain number of features that have very less noise in detection. These could also be cross-checked with some loop-closure algorithms (if there is a loop closure, you would also expect similar landmarks to be around). \n",
    "\n",
    "Note that local detections can be transformed to the global frame using homogeneous transformations and the current estimate of states. As the state estimates get better, so does the map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
