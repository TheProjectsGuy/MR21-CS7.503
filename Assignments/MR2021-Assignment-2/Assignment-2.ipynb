{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment - 2: Data Representation and Point Cloud Operations\n",
    "\n",
    "Team Name: \\<team name here\\> \n",
    "\n",
    "Roll number: \\<Roll number here (in sorted order)\\>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Instructions\n",
    "\n",
    "- Code must be written in Python in Jupyter Notebooks. We highly recommend using anaconda distribution or at the minimum, virtual environments for this assignment.\n",
    "- Save all your results in ```results/<question_number>/<sub_topic_number>/```\n",
    "- The **References** section provides you with important resources to solve the assignment.\n",
    "- Make sure your code is modular since you may need to reuse parts for future assignments.\n",
    "- Answer the descriptive questions in your own words with context & clarity. Do not copy answers from online resources or lecture notes.\n",
    "- The **deadline** for this assignment is on 26/09/2021 at 11:55pm. Please note that there will be no extensions.\n",
    "- Plagiarism is **strictly prohibited**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Submission Instructions\n",
    "\n",
    "1. Make sure your code runs without any errors after reinitializing the kernel and removing all saved variables.\n",
    "2. After completing your code and saving your results, zip the folder with name as ``Team_<team_name>_MR2021_Assignment_<assignment_number>.zip``"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "import sympy as sp\r\n",
    "import open3d as o3d\r\n",
    "import cv2\r\n",
    "import pandas as pd\r\n",
    "# Utilities\r\n",
    "import copy\r\n",
    "import time"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to types of Transformations and Homogeneous coordinates\r\n",
    "\r\n",
    "In robotics applications, it is inevitable to keep track of the frames of multiple objects/worlds. These frames can be transformations from one coordinate frame to the other. **Homogeneous coordinates** help in keeping track of various coordinate frames and allow performing composition of various transforms. We will first try to understand between types of transformations and their invariant properties.\r\n",
    "\r\n",
    "1. What is the difference between Affine, Similarity, and Euclidean transform? What are the invariant properities of each type of transform?\r\n",
    "2. Watch this [video](https://www.youtube.com/watch?v=PvEl63t-opM) to briefly understand homogeneous coordinates. What are points at infinity? What type of transformation can you apply to transform a point from infinity to a point that is not at infinity? \r\n",
    "3. Using homogeneous coordinates we can represent different types of transformation as point transforms vs. frame transforms. Concatenation of transforms (whether you post multiply transformation matrices or pre-multiply transformation matrices) depends on the problem and how you are viewing it. Try to understand the difference between frame vs. point transformations from this [video](https://youtu.be/Za7Sdegf8m8?t=1834). Let's assume that our camera and world frames are coinciding with each other. We need to estimate the camera to world **frame** transformation matrix after applying the transformations defined below in terms of $T_i$.We apply **frame** transform to move the camera in the world in the following order:\r\n",
    "    1. $T_1$ from the camera coordinate frame.\r\n",
    "    2. $T_2$ from the world coordinate frame.\r\n",
    "    3. $T_3$ from the world coordinate frame.\r\n",
    "    4. $T_4$ from the camera coordinate frame.\r\n",
    "    5. $T_5$ from the camera coordinate frame.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer 1: Affine, Similarity and Euclidean Transform\r\n",
    "\r\n",
    "Description as well as the properties preserved by different transforms are summarized below. Their homogeneous transformation matrices are also described.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Affine Transform\r\n",
    "\r\n",
    "It is a transformation that is any sequence of **rotation** (rotate points about an axis by a given angle), directional **scaling** (scaling the points differently in different direction) and **translation** (offsetting or moving the points)\r\n",
    "\r\n",
    "It can be described by a transformation\r\n",
    "\r\n",
    "$$ \r\n",
    "\\begin{bmatrix}\r\n",
    "\\mathbf{y} \\\\\r\n",
    "1\r\n",
    "\\end{bmatrix} = \r\n",
    "\\left[\r\n",
    "\\begin{array}{ccc|c}\r\n",
    "& \\mathbf{A} & & \\mathbf{b} \\\\\r\n",
    "0 & \\cdots & 0 & 1\r\n",
    "\\end{array}\r\n",
    "\\right]\r\n",
    "\\begin{bmatrix}\r\n",
    "\\mathbf{x} \\\\\r\n",
    "1\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "Where $\\mathbf{x}$ is the input vector, $\\mathbf{y}$ is the output vector (result of transformation). The matrix $\\mathbf{A}$ contains information about rotation and scaling (SVD of $\\mathbf{A}$ might reveal more about it) of $\\mathbf{x}$ and the vector $\\mathbf{b}$ is the translation vector. The above matrix equation can be more simply written as\r\n",
    "\r\n",
    "$$ \\mathbf{y} = \\mathbf{A} \\mathbf{x} + \\mathbf{b} $$\r\n",
    "\r\n",
    "This type of transformation maintains the following invariant properties (assume transformation happening on 2D vectors for visualizing, but the same concepts can be extended to higher dimensions)\r\n",
    "\r\n",
    "- **Parallelism**: If two lines are parallel before the transform, they'll remain parallel after the transform as well.\r\n",
    "\r\n",
    "However, the following properties are not maintained\r\n",
    "\r\n",
    "- **Angles**: If two lines make a certain angle before the transformation, there is no guarantee that they'll maintain the same angle after transformation.\r\n",
    "- **Lengths**: SInce scaling is involved, the lengths of vectors need not be preserved. They'll not remain of the same length after the transformation.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Similarity Transform\r\n",
    "\r\n",
    "> **Note**: Assuming that the _similarity transform_ described here is not representing a transformation in one frame, in another frame.\r\n",
    "\r\n",
    "A similarity transform is a mix of **scaled rotation** and a **translation**. The main difference from affine transform is that the scaling happens to the entire vector space (uniform in all directions).\r\n",
    "\r\n",
    "It can be described by a transformation\r\n",
    "\r\n",
    "$$\r\n",
    "\\begin{bmatrix}\r\n",
    "\\mathbf{y} \\\\\r\n",
    "1\r\n",
    "\\end{bmatrix}\r\n",
    "=\r\n",
    "\\left [\r\n",
    "\\begin{array}{ccc|c}\r\n",
    "& m\\mathbf{R} & & \\mathbf{b} \\\\\r\n",
    "0 & \\cdots & 0 & 1\r\n",
    "\\end{array}\r\n",
    "\\right ]\r\n",
    "\\begin{bmatrix}\r\n",
    "\\mathbf{x} \\\\\r\n",
    "1\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "Where $\\mathbf{x}$ is the input vector, $\\mathbf{y}$ is the output vector (result of transformation). The matrix $\\mathbf{R}$ is formed by orthonormal basis vectors (in the respective dimensional space) such that $\\left | \\mathbf{R} \\right | = +1$. Such a group of matrices are called _special orthogonal_ matrices. It can be scaled by $m$ (a scalar). The vector $\\mathbf{b}$ is a translation vector. The above matrix equation can more simply be written as\r\n",
    "\r\n",
    "$$ \\mathbf{y} = m \\mathbf{R\\,x} + \\mathbf{b} $$\r\n",
    "\r\n",
    "This type of transformation maintains the following invariant properties (assume transformation happening on 2D vectors for visualizing, but the same concepts can be extended to higher dimensions)\r\n",
    "\r\n",
    "- **Angles**: If two lines make a particular angle before transformation, they will maintain the same angle after transformation. This is because the matrix $\\mathbf{R}$ inherently preserves angles. Note that scaling is uniform for all axis here, unlike the affine transform case.\r\n",
    "- **Parallelism**: If two lines are parallel before the transform, they will remain parallel after the transform. This follows from the fact that angles are preserved.\r\n",
    "\r\n",
    "However, the following properties are not maintained\r\n",
    "\r\n",
    "- **Length**: Since uniform scaling is observed, the resultant vectors need not be of the same length. But, they'll be a scalar multiple of their original lengths (for untranslated free vectors).\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Euclidean Transform\r\n",
    "\r\n",
    "Euclidean transforms, or _Rigid Body Transforms_ are transformation that preserve the length of vectors as well. They only rotate or translate (offset) vectors, they do not involve scaling.\r\n",
    "\r\n",
    "It can be described by a transformation\r\n",
    "\r\n",
    "$$\r\n",
    "\\begin{bmatrix}\r\n",
    "\\mathbf{y} \\\\\r\n",
    "1\r\n",
    "\\end{bmatrix}\r\n",
    "=\r\n",
    "\\left [\r\n",
    "\\begin{array}{ccc|c}\r\n",
    "& \\mathbf{R} & & \\mathbf{b} \\\\\r\n",
    "0 & \\cdots & 0 & 1\r\n",
    "\\end{array}\r\n",
    "\\right ]\r\n",
    "\\begin{bmatrix}\r\n",
    "\\mathbf{x} \\\\\r\n",
    "1\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "Where $\\mathbf{x}$ is the input vector, $\\mathbf{y}$ is the output vector (result of transformation). The matrix $\\mathbf{R}$ is formed by orthonormal basis vectors (in the respective dimensional space) such that $\\left | \\mathbf{R} \\right | = +1$. Such a group of matrices are called _special orthogonal_ matrices. The vector $\\mathbf{b}$ is a translation vector. The above matrix equation can more simply be written as\r\n",
    "\r\n",
    "$$ \\mathbf{y} = \\mathbf{R\\,x} + \\mathbf{b} $$\r\n",
    "\r\n",
    "This type of transformation maintains the following invariant properties\r\n",
    "\r\n",
    "- **Length**: The length of free vectors (their origin doesn't matter, only direction does) remains the same before and after transformation. This is because, to them, only rotation can be interpreted. And rotations have unity determinant\r\n",
    "- **Angle**: If two lines make a particular angle before transformation, they maintain that angle even after the transformation.\r\n",
    "- **Parallelism**: If two lines are parallel before the transform, they will remain parallel even after transform. This follows the fact that angles are preserved\r\n",
    "\r\n",
    "However, the following properties may not be preserved\r\n",
    "\r\n",
    "- **Direction**: The direction of vector may not remain constant after the transformation. This is because a rotation has taken place\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer 2: Points at infinity\r\n",
    "\r\n",
    "Points at infinity and projective transform described below"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Points at infinity\r\n",
    "\r\n",
    "As the [given video](https://youtu.be/PvEl63t-opM) shows, a point can be converted **from spatial coordinates to homogeneous coordinates** as follows\r\n",
    "\r\n",
    "$$\r\n",
    "\\begin{bmatrix}\r\n",
    "x \\\\\r\n",
    "y \\\\\r\n",
    "z \\\\\r\n",
    "\\end{bmatrix}\r\n",
    "\\rightarrow\r\n",
    "\\begin{bmatrix}\r\n",
    "x \\\\\r\n",
    "y \\\\\r\n",
    "z \\\\\r\n",
    "1\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "A point can be converted from **homogeneous coordinates to spatial coordinates** as follows\r\n",
    "\r\n",
    "$$\r\n",
    "\\begin{bmatrix}\r\n",
    "x \\\\\r\n",
    "y \\\\\r\n",
    "z \\\\\r\n",
    "s\r\n",
    "\\end{bmatrix}\r\n",
    "\\rightarrow\r\n",
    "\\begin{bmatrix}\r\n",
    "x/s \\\\\r\n",
    "y/s \\\\\r\n",
    "z/s\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "As observed above, if $s=0$ for homogeneous coordinate, then the point cannot be converted to the spatial coordinates. The resultant conversion will give $\\infty$. Such points in homogeneous coordinates are **points at infinity**.\r\n",
    "\r\n",
    "If the first three elements are normalized in homogeneous coordinates, then the point can then be considered a **direction**. The direction cannot be brought to a specific point in spatial coordinates, but can still be inferred as being on a line at infinity. Axis, for example, are directional points at infinity (that's why the rotation matrix has $s=0$ in the homogeneous transformation matrix, because they're axis and not points).\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Projective transform\r\n",
    "\r\n",
    "The only way how points at infinity can be represented in _finite_ spatial coordinates is through projection. We essentially project the points on a dimension just lower than the spacial dimension. That is, project the 3D point at infinity on to a plane.\r\n",
    "\r\n",
    "> Case when this projection fails: Assume that the proposed plane passes through origin. There is a case of the point at infinity already being on the proposed plane (at infinity), in which case, the particular plane will not project it to a finite point in spatial coordinates.\r\n",
    "\r\n",
    "Consider a general case of Homogeneous Transformation\r\n",
    "\r\n",
    "$$\r\n",
    "\\begin{bmatrix}\r\n",
    "\\mathbf{y} \\\\\r\n",
    "s_y\r\n",
    "\\end{bmatrix}\r\n",
    "=\r\n",
    "\\begin{bmatrix}\r\n",
    "\\mathbf{A} & \\mathbf{t} \\\\\r\n",
    "\\mathbf{p}^T & 1\r\n",
    "\\end{bmatrix}\r\n",
    "\\begin{bmatrix}\r\n",
    "\\mathbf{x} \\\\\r\n",
    "s_x\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "If $s_x = 0$, then for $s_y$ to not be $0$, $\\mathbf{p}$ has to be a non-zero vector. It can be seen that the dot product of $\\mathbf{p}$ and $\\mathbf{x}$ give value to $s_y$ (if $s_x$ is 0). This brings a point at infinity to a point that is not at infinity (specifically, the point comes to $\\mathbf{y}/s_y$ in spatial coordinates). A thing to note here is that if $\\mathbf{p}$ and $\\mathbf{x}$ are perpendicular, then $\\mathbf{x}$ will not be projected into spatial coordinates ($\\mathbf{y}$ will remain a point at infinity).\r\n",
    "\r\n",
    "An example of such transforms are cameras (which project points at infinity onto a fixed screen).\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer 3: Camera and World transforms\r\n",
    "\r\n",
    "We post-multiply homogeneous transformation matrices when the transforms are described in the current frame. We pre-multiply homogeneous transformation matrices when the transforms are described in the world frame.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Camera to World transformation steps\r\n",
    "\r\n",
    "The answer should be $\\mathbf{T}_{eq} = \\mathbf{T}_3 \\mathbf{T}_2 \\mathbf{T}_1 \\mathbf{T}_4 \\mathbf{T}_5 $\r\n",
    "\r\n",
    "Beginning with the identity transformation (4x4 identity matrix)\r\n",
    "\r\n",
    "$$ \\mathbf{T}_{eq_s} = \\mathbf{I}_{(4,4)} $$\r\n",
    "\r\n",
    "We apply the following steps\r\n",
    "\r\n",
    "1. $T_1$ from the camera coordinate frame (post multiply)\r\n",
    "\r\n",
    "    $$ \\mathbf{T}_{eq_1} = \\mathbf{T}_{eq_s} \\mathbf{T}_1 = \\mathbf{I}_{(4, 4)} \\mathbf{T}_1 \\Rightarrow \\mathbf{T}_{eq_1} = \\mathbf{T}_1 $$\r\n",
    "\r\n",
    "2. $T_2$ from the world coordinate frame (pre multiply)\r\n",
    "\r\n",
    "    $$ \\mathbf{T}_{eq_2} = \\mathbf{T}_2 \\mathbf{T}_{eq_1} = \\mathbf{T}_2 \\left ( \\mathbf{T}_1 \\right ) \\Rightarrow \\mathbf{T}_{eq_2} = \\mathbf{T}_2 \\mathbf{T}_1 $$\r\n",
    "\r\n",
    "3. $T_3$ from the world coordinate frame (pre multiply)\r\n",
    "\r\n",
    "    $$ \\mathbf{T}_{eq_3} = \\mathbf{T}_3 \\mathbf{T}_{eq_2} = \\mathbf{T}_3 \\left ( \\mathbf{T}_2 \\mathbf{T}_1 \\right ) \\Rightarrow \\mathbf{T}_{eq_3} = \\mathbf{T}_3 \\mathbf{T}_2 \\mathbf{T}_1 $$\r\n",
    "\r\n",
    "4. $T_4$ from the camera coordinate frame (post multiply)\r\n",
    "\r\n",
    "    $$ \\mathbf{T}_{eq_4} = \\mathbf{T}_{eq_3} \\mathbf{T}_4 = \\left ( \\mathbf{T}_3 \\mathbf{T}_2 \\mathbf{T}_1 \\right ) \\mathbf{T}_4 \\Rightarrow \\mathbf{T}_{eq_4} = \\mathbf{T}_3 \\mathbf{T}_2 \\mathbf{T}_1 \\mathbf{T}_4 $$\r\n",
    "\r\n",
    "5. $T_5$ from the camera coordinate frame (post multiply)\r\n",
    "\r\n",
    "    $$ \\mathbf{T}_{eq_5} = \\mathbf{T}_{eq_4} \\mathbf{T}_5 = \\left ( \\mathbf{T}_3 \\mathbf{T}_2 \\mathbf{T}_1 \\mathbf{T}_4 \\right ) \\mathbf{T}_5 \\Rightarrow \\mathbf{T}_{eq_5} = \\mathbf{T}_3 \\mathbf{T}_2 \\mathbf{T}_1 \\mathbf{T}_4 \\mathbf{T}_5 $$\r\n",
    "\r\n",
    "The final transform is given by\r\n",
    "\r\n",
    "$$ \\mathbf{T}_{eq} = \\mathbf{T}_{eq_5} = \\mathbf{T}_3 \\mathbf{T}_2 \\mathbf{T}_1 \\mathbf{T}_4 \\mathbf{T}_5 $$\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualise the Data\n",
    "\n",
    "Point clouds are a collection of points that represent a 3D shape or feature. Each point has its own set of X, Y and Z coordinates and in some cases additional attributes. A popular way to obtain this is by photogrammetry, though here we will use LiDAR data.\n",
    "\n",
    "LiDAR is a remote sensing process which collects measurements used to create 3D models and maps of objects and environments. Using ultraviolet, visible, or near-infrared light, LiDAR gauges spatial relationships and shapes by measuring the time it takes for signals to bounce off objects and return to the scanner.\n",
    "\n",
    "1. Download the data from [here](https://iiitaphyd-my.sharepoint.com/:f:/g/personal/venkata_surya_students_iiit_ac_in/EnYAMaTVIhJItzKYqtahE30BRKB6p6UfHN3TyJzvo6Mw0g?e=PegWds). It contains the LIDAR sensor output and odometry information per frame.\n",
    "\n",
    "    The .bin files contain the 3D point cloud captured by the LIDAR in this format - x, y, z, and reflectance. \n",
    "\n",
    "    The odometry information is given in the `odometry.txt` file, which is a 12 element vector. Reshape each of the first 77 rows to a 3x4 matrix to obtain the pose.\n",
    "    \n",
    "\n",
    "2. Obtain the point cloud from this and visualise for 1-2 frames."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading and Visualizing Point Clouds\r\n",
    "\r\n",
    "Let's start by reading from the file. Note that the folder name will have to contain the LiDAR points.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "All configurations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Folder name\r\n",
    "lidar_folder_name = \"./data/data_pc_odom/LiDAR\" # Should contain .bin files\r\n",
    "num_frames = 77 # Number of frames to load for data\r\n",
    "start_num = 10  # Starting number (for file name). File names must be 6 character long\r\n",
    "pc_frames = []  # Will be a list of numpy arrays (one each frame)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load all data\r\n",
    "for i in range(start_num, start_num+num_frames):\r\n",
    "    # Read from file\r\n",
    "    pc_raw = np.fromfile(f\"{lidar_folder_name}/{i:06d}.bin\", dtype=np.float32)\r\n",
    "    pc_frame = pc_raw.astype(float).reshape(-1, 4)\r\n",
    "    # Append to readings\r\n",
    "    pc_frames.append(pc_frame)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Convert each of them to Open3D point clouds\r\n",
    "o3d_pcds = [o3d.geometry.PointCloud(o3d.utility.Vector3dVector(points[:,:3]))\\\r\n",
    "    for points in pc_frames]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Visualize all point clouds in a slideshow\r\n",
    "def viz_pcds_local_ss(o3d_pcds):\r\n",
    "    \"\"\"\r\n",
    "    Visualizes the point clouds in the local frame with an axis (for reference).\r\n",
    "    The visualization is in local frame (origin is fixed). It is as if observing\r\n",
    "    from the sensor.\r\n",
    "    \r\n",
    "    Parameters:\r\n",
    "    - o3d_pcds: list[o3d.geometry.PointCloud]\r\n",
    "        A list of point clouds to visualize\r\n",
    "    \"\"\"\r\n",
    "    # Some parameters for the visualization\r\n",
    "    viz_title = \"Point Cloud visualization\"\r\n",
    "    viz_width = 1080\r\n",
    "    viz_height = 720\r\n",
    "    step_time = 0.1\r\n",
    "    end_wait_time = 1\r\n",
    "    look_at = [0, 0, 0]\r\n",
    "    cam_front = [1, -2, 1]\r\n",
    "    cam_up = [0, 0, 1]\r\n",
    "    cam_zoom = 0.45\r\n",
    "    # Environment variables\r\n",
    "    pc_viz: o3d.geometry.PointCloud = copy.deepcopy(o3d_pcds[0])    # PC to viz.\r\n",
    "    cf = o3d.geometry.TriangleMesh.create_coordinate_frame(size=5.0,\\\r\n",
    "        origin=[0, 0, 0])   # Coordinate frame\r\n",
    "    # -- Start non-blocking visualization --\r\n",
    "    vis = o3d.visualization.Visualizer()\r\n",
    "    vis.create_window(viz_title, viz_width, viz_height)\r\n",
    "    vis.add_geometry(cf)\r\n",
    "    vis.add_geometry(pc_viz)\r\n",
    "    # Set view\r\n",
    "    ctr = vis.get_view_control()\r\n",
    "    ctr.set_lookat(look_at)\r\n",
    "    ctr.set_front(cam_front)\r\n",
    "    ctr.set_up(cam_up)\r\n",
    "    ctr.set_zoom(cam_zoom)\r\n",
    "    vis.poll_events()\r\n",
    "    vis.update_renderer()\r\n",
    "    st_time = time.time()\r\n",
    "    for i in range(len(o3d_pcds)):\r\n",
    "        # Copy points\r\n",
    "        pc: o3d.geometry.PointCloud = copy.deepcopy(o3d_pcds[i])\r\n",
    "        pc_viz.points = pc.points\r\n",
    "        # Update visualization\r\n",
    "        vis.update_geometry(pc_viz)\r\n",
    "        st_time = time.time()\r\n",
    "        while (time.time() - st_time) < step_time:\r\n",
    "            vis.poll_events()\r\n",
    "            vis.update_renderer()\r\n",
    "    # Destroy everything\r\n",
    "    st_time = time.time()\r\n",
    "    while(time.time() - st_time) < end_wait_time:\r\n",
    "        vis.poll_events()\r\n",
    "        vis.update_renderer()\r\n",
    "    vis.destroy_window()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "viz_pcds_local_ss(o3d_pcds)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following GIF was obtained by the following configurations in the function `viz_pcds_local_ss`\r\n",
    "\r\n",
    "```py\r\n",
    "    look_at = [0, 0, 0]\r\n",
    "    cam_front = [1, -2, 1]\r\n",
    "    cam_up = [0, 0, 1]\r\n",
    "    cam_zoom = 0.5\r\n",
    "```\r\n",
    "\r\n",
    "![LiDAR data GIF](./results/2/LiDAR_data_sequence.gif)\r\n",
    "\r\n",
    "Thanks to [GalaxyApps on Microsoft Store](https://www.microsoft.com/en-us/p/gif-maker-gif-editor/9pkc9pxzxg9r) for the app"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading and Visualizing Odometry\r\n",
    "\r\n",
    "Let's start by reading from the `odometry.txt` file. Assuming that they're with respect to a fixed frame\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "All configurations\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# File name (relative path)\r\n",
    "odom_file = \"./data/data_pc_odom/odometry.txt\"\r\n",
    "num_rows = num_frames   # Same number of rows as frames in LiDAR\r\n",
    "sep_odomf = ' '     # Separator for the file (pandas)\r\n",
    "# Store all homogeneous transforms\r\n",
    "pose_matrices = None    # A numpy.ndarray of shape (num_rows, 4, 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Read all data\r\n",
    "odom_f_all = pd.read_csv(odom_file, sep=sep_odomf)\r\n",
    "nptable_odom = odom_f_all.to_numpy().astype(float)\r\n",
    "pose_matrices = []\r\n",
    "for i in range(num_rows):\r\n",
    "    ht = np.vstack((nptable_odom[i].reshape(3, 4), [0, 0, 0, 1]))\r\n",
    "    pose_matrices.append(ht)\r\n",
    "pose_matrices = np.array(pose_matrices, dtype=float)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Visualize the odometry\r\n",
    "def viz_odom_global_single(ht_poses):\r\n",
    "    \"\"\"\r\n",
    "    Visualize the odometry after the homogeneous transformation frames\r\n",
    "    are passed to the function. All transformations are assumed to be\r\n",
    "    in the global frame. The function shows a single window, not an\r\n",
    "    updating slideshow.\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - ht_poses: np.ndarray  shape: (N, 4, 4)\r\n",
    "        A list of 4x4 homogeneous transformation matrices\r\n",
    "    \"\"\"\r\n",
    "    # Some parameters for the visualization\r\n",
    "    viz_title = \"Odometry visualization\"\r\n",
    "    viz_width = 1080\r\n",
    "    viz_height = 720\r\n",
    "    look_at = [25, 0, 25]\r\n",
    "    cam_front = [1, 1, -2]\r\n",
    "    cam_up = [0, 1, 0]\r\n",
    "    # Environment variables\r\n",
    "    cf = o3d.geometry.TriangleMesh.create_coordinate_frame(size=10.0,\\\r\n",
    "        origin=[0, 0, 0])   # Global coordinate frame\r\n",
    "    cf_track = o3d.geometry.TriangleMesh.create_coordinate_frame(size=5.0,\\\r\n",
    "        origin=[0, 0, 0])   # Global coordinate frame\r\n",
    "    # -- Display window --\r\n",
    "    vis = o3d.visualization.Visualizer()\r\n",
    "    vis.create_window(viz_title, viz_width, viz_height)\r\n",
    "    vis.add_geometry(cf)    # Starting frame\r\n",
    "    # Add all frames\r\n",
    "    for i in range(len(ht_poses)):\r\n",
    "        ht = ht_poses[i]\r\n",
    "        cf_viz = copy.deepcopy(cf_track)\r\n",
    "        cf_viz.transform(ht)\r\n",
    "        vis.add_geometry(cf_viz)\r\n",
    "        vis.poll_events()\r\n",
    "        vis.update_renderer()\r\n",
    "    # Set view\r\n",
    "    ctr = vis.get_view_control()\r\n",
    "    ctr.set_lookat(look_at)\r\n",
    "    ctr.set_front(cam_front)\r\n",
    "    ctr.set_up(cam_up)\r\n",
    "    # Show window\r\n",
    "    vis.run()\r\n",
    "    vis.destroy_window()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "viz_odom_global_single(pose_matrices)\r\n",
    "odom_pose_matrices = pose_matrices # Save for next question"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The image below is obtained using the following configurations for the function `viz_odom_global_single`\r\n",
    "\r\n",
    "```py\r\n",
    "    look_at = [25, 0, 25]\r\n",
    "    cam_front = [1, 1, -2]\r\n",
    "    cam_up = [0, 1, 0]\r\n",
    "```\r\n",
    "\r\n",
    "You might have to wait a few moments for the visualization to load\r\n",
    "\r\n",
    "![Odometry frames](./results/2/odom_frames.jpg)\r\n",
    "\r\n",
    "The pattern of LiDAR data is clear, but there is definitely a transform between this odometry data and the LiDAR data. Note that the LiDAR visualization showed motion along `+X` axis, but this shows motion along `+Z` axis. Even the up direction of the two frames are different.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transform \r\n",
    "\r\n",
    "The point cloud obtained is with respect to the LiDAR frame. The poses however, are in the camera frame. If we want to combine the point clouds from various frames, we need to bring them to the camera frame. \r\n",
    "\r\n",
    "1. Refer to the image below and apply the required transformation to the point cloud. \r\n",
    "\r\n",
    "2. Then, register all point clouds into a common reference frame and visualise it (Open3D). It is helpful to use homogeneous coordinates to keep track of the different frames.\r\n",
    "\r\n",
    "3. Write a function to transform the registered point cloud from the world to the $i^{th}$ camera frame, wherein $i$ is the input to the function.\r\n",
    "\r\n",
    "4. \\[Bonus\\] Move around in the registered point cloud using arrow keys like you would do in a game. For this you will have to regularly transform the entire registered world to your current camera frame and visualize repeatedly. You may choose to avoid visualizing points that are behind the camera in this case as they are not visible from the scene. You may also visualize points at a max depth to make the process easier.\r\n",
    "\r\n",
    "![](./img/transform.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer 1: Apply Transformations to the point cloud\r\n",
    "\r\n",
    "Before applying transformations, it is better to define all the transformations.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is assumed that the vehicle is rigid and the transform between any two frames on the vehicle remains constant for the entire run. Below is a table that contains the _code name_ (name of frame in code) of frames. The transform values are in code, and are rough estimates from the image.\r\n",
    "\r\n",
    "| **Frame Name** | **Code Name** | Notes |\r\n",
    "| :--- | :---- | :---- |\r\n",
    "| OXTS RT 3003 GPS/IMU | `bref` | The body reference frame. It is assumed to be behind all frames in the vehicle (maybe in plane of rear axels) |\r\n",
    "| Velodyne HDL-64E Laserscanner | `bld` | Frame for LiDAR on the body. Assumed to be aligned with `bref`, origin offset only in `+Z` and `+X`. |\r\n",
    "| Point Gray Flea 2 Video Camera | `bcam` | Frame for camera on the body. Assumed that we obtain the orientation by rotation `bld` first by `90` deg along `+Y`, then rotate the resultant frame by `-90` deg along `+Z`. The origin offset from the `bld` is assumed to be in `+X` and `-Z` direction. |\r\n",
    "| Ground Reference with Body Camera Pose | `grbcp` or `osta` | Frame 0 (starting frame) of the `bcam` (odometry series). The orientation is as in `bcam` (so is the initial placement). Also called the odometry start frame. |\r\n",
    "| Ground Reference (**World**) | `gref` | The world frame. The pose is what the pose of `bref` is at starting of the experiment. The pose is that of `bref`. Maintains the same starting transformation with `grbcp` as the transformation between `bref` and `bcam` |\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the rotation functions and declare inverse transformation function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Borrowing basic functions from earlier submissions\r\n",
    "\r\n",
    "# Rotate about X axis\r\n",
    "def RotX(angle, degrees = False):\r\n",
    "    \"\"\"\r\n",
    "    Generates a Rotation matrice when the rotation is about X axis\r\n",
    "    A general rotation about X (Roll) is given by\r\n",
    "\r\n",
    "                | 1    0    0 |\r\n",
    "    RotX(T) =   | 0   cT  -sT |\r\n",
    "                | 0   sT   cT |\r\n",
    "\r\n",
    "    Where T is rotation angle in radians\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - angle: Symbol or float\r\n",
    "        The angle of rotation\r\n",
    "    - degrees: bool     default: False\r\n",
    "        If 'True', then angle parameter is assumed to be in degrees\r\n",
    "        else it is by default assumed to be in radians\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - rot_mat: sp.Matrix        shape: (3, 3)\r\n",
    "        The 3x3 rotation matrix for Roll by angle_rad\r\n",
    "    \"\"\"\r\n",
    "    angle_rad = angle if not degrees else sp.rad(angle)\r\n",
    "    rot_mat = sp.Matrix([\r\n",
    "        [1, 0, 0],\r\n",
    "        [0, sp.cos(angle_rad), -sp.sin(angle_rad)],\r\n",
    "        [0, sp.sin(angle_rad), sp.cos(angle_rad)],\r\n",
    "    ])\r\n",
    "    return rot_mat\r\n",
    "\r\n",
    "# Rotate about Y Axis\r\n",
    "def RotY(angle, degrees = False):\r\n",
    "    \"\"\"\r\n",
    "    Generates a Rotation matrice when the rotation is about Y axis\r\n",
    "    A general rotation about Y (Pitch) is given by\r\n",
    "\r\n",
    "                |  cT   0   sT |\r\n",
    "    RotY(T) =   |   0   1    0 |\r\n",
    "                | -sT   0   cT |\r\n",
    "\r\n",
    "    Where T is rotation angle in radians\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - angle: Symbol or float\r\n",
    "        The angle of rotation\r\n",
    "    - degrees: bool     default: False\r\n",
    "        If 'True', then angle parameter is assumed to be in degrees\r\n",
    "        else it is by default assumed to be in radians\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - rot_mat: sp.Matrix        shape: (3, 3)\r\n",
    "        The 3x3 rotation matrix for Pitch by angle_rad\r\n",
    "    \"\"\"\r\n",
    "    angle_rad = angle if not degrees else sp.rad(angle)\r\n",
    "    rot_mat = sp.Matrix([\r\n",
    "        [sp.cos(angle_rad), 0, sp.sin(angle_rad)],\r\n",
    "        [0, 1, 0],\r\n",
    "        [-sp.sin(angle_rad), 0, sp.cos(angle_rad)],\r\n",
    "    ])\r\n",
    "    return rot_mat\r\n",
    "\r\n",
    "# Rotate about Z Axis\r\n",
    "def RotZ(angle, degrees = False):\r\n",
    "    \"\"\"\r\n",
    "    Generates a Rotation matrice when the rotation is about Z axis\r\n",
    "    A general rotation about Z (Yaw) is given by\r\n",
    "\r\n",
    "                | cT   -sT   0 |\r\n",
    "    RotZ(T) =   | sT    cT   0 |\r\n",
    "                |  0     0   1 |\r\n",
    "\r\n",
    "    Where T is rotation angle in radians\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - angle: Symbol or float\r\n",
    "        The angle of rotation\r\n",
    "    - degrees: bool     default: False\r\n",
    "        If 'True', then angle parameter is assumed to be in degrees\r\n",
    "        else it is by default assumed to be in radians\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - rot_mat: sp.Matrix        shape: (3, 3)\r\n",
    "        The 3x3 rotation matrix for Yaw by angle_rad\r\n",
    "    \"\"\"\r\n",
    "    angle_rad = angle if not degrees else sp.rad(angle)\r\n",
    "    rot_mat = sp.Matrix([\r\n",
    "        [sp.cos(angle_rad), -sp.sin(angle_rad), 0],\r\n",
    "        [sp.sin(angle_rad), sp.cos(angle_rad), 0],\r\n",
    "        [0, 0, 1],\r\n",
    "    ])\r\n",
    "    return rot_mat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Some more function\r\n",
    "\r\n",
    "# Invert a homogeneous transformation matrix\r\n",
    "def inv_tf(htf):\r\n",
    "    \"\"\"\r\n",
    "    Inverts a passed homogeneous transformation matrix\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - htf: np.ndarray   shape: (4, 4)\r\n",
    "        The homogeneous transformaiton to invert\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    - htf_inv: np.ndarray   shape: (4, 4)\r\n",
    "        The inverse of 'htf' passed\r\n",
    "    \"\"\"\r\n",
    "    R: np.ndarray = htf[0:3, 0:3]\r\n",
    "    p: np.ndarray = htf[0:3, 3]\r\n",
    "    htf_inv = np.vstack((\r\n",
    "        np.hstack((R.T, -(R.T @ p).reshape(-1, 1))),\r\n",
    "        [0, 0, 0, 1]\r\n",
    "    ))\r\n",
    "    return htf_inv\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Frame transformations for all frames in the table above\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# To represent bld in bref\r\n",
    "tf_bref_bld = np.vstack((np.hstack((\r\n",
    "    np.eye(3), # Same alignment\r\n",
    "    np.array([0.5, 0, 0.5]).reshape(-1, 1)  # Offset in +X and +Z\r\n",
    ")), [0, 0, 0, 1]))\r\n",
    "# To represent bcam in bld\r\n",
    "tf_bld_bcam = np.vstack((np.hstack((\r\n",
    "    np.array(RotY(90, True) * RotZ(-90, True), dtype=float), # Rotation\r\n",
    "    np.array([0.1, 0, -0.05]).reshape(-1, 1)   # Offset in +X and -Z\r\n",
    ")), [0, 0, 0, 1]))\r\n",
    "# To represent bcam in bref\r\n",
    "tf_bref_bcam = tf_bref_bld @ tf_bld_bcam\r\n",
    "# Get the inverse of all transforms\r\n",
    "# To represent bref in bld\r\n",
    "tf_bld_bref = inv_tf(tf_bref_bld)\r\n",
    "# To represent bld in bcam\r\n",
    "tf_bcam_bld = inv_tf(tf_bld_bcam)\r\n",
    "# To represent bref in bcam\r\n",
    "tf_bcam_bref = inv_tf(tf_bref_bcam)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform each point in the point cloud to the camera frame\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "num_pts = len(pc_frames)    # pc_frames from LiDAR data\r\n",
    "# Point cloud in bcam frame\r\n",
    "pc_bcam = [ # Apply a frame-wise transformation\r\n",
    "    # Stack the points with reflectance\r\n",
    "    np.vstack((\r\n",
    "        # All points transformed as 3 x N\r\n",
    "        (\r\n",
    "            # Get point in bcam from bld\r\n",
    "            tf_bcam_bld @ np.vstack((\r\n",
    "                # Points as 4 x N - homogeneous coordinates\r\n",
    "                pcf[:,:3].T,\r\n",
    "                np.ones((1, pcf.shape[0]))\r\n",
    "            ))\r\n",
    "        )[:3, :],   # Last row is 1, remove it\r\n",
    "        # Reflectance values as 1 x N\r\n",
    "        pcf[:, 3].reshape(1, -1)\r\n",
    "    )).T \\\r\n",
    "    # For each frame\r\n",
    "    for pcf in pc_frames\r\n",
    "]   # Result is a list of np.ndarrays, each shape (N, 4)\r\n",
    "# 4 -> x, y, z, reflectance; N -> Num of pts in the frame"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Some sanity check that this actually works: take a random point and check tf\r\n",
    "rp_fnum = 63 # Frame to compare\r\n",
    "rp_fpt = 1878  # Point number in the particular frame\r\n",
    "rp_bld = pc_frames[rp_fnum][rp_fpt] # Random point in bld\r\n",
    "rp_bcam = pc_bcam[rp_fnum][rp_fpt]  # Random point in bcam\r\n",
    "# Project rp_bld in bcam using tf\r\n",
    "rp_bcam_proj = np.vstack((\\\r\n",
    "    # Point being projected from bld to bcam\r\n",
    "    (tf_bcam_bld @ np.vstack((rp_bld[0:3].reshape(3, 1), 1)))[:3],\r\n",
    "    # Reflectance\r\n",
    "    rp_bld[3]))\r\n",
    "if np.allclose(rp_bcam.flatten(), rp_bcam_proj.flatten()):\r\n",
    "    print(f\"Point in frame {rp_fnum}, point {rp_fpt} matches out\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Point in frame 63, point 1878 matches out\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer 2: Register all point clouds in reference frame and visualize\r\n",
    "\r\n",
    "Let us first bring all points (of all frames) to a single frame\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assuming that the odometry is for the camera frame, each point set / frame (in `pc_bcam`) has to be transformed first to `grbcp` (home frame of odometry) and then to `gref` (the **world frame**)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# All transformation (odometry)\r\n",
    "# All frames of odometry (bcam frames) in grbcam\r\n",
    "tfs_grbcp_bcam = odom_pose_matrices  # N x 4 x 4 poses\r\n",
    "# Transformation to express grbcp in gref (actual ground reference)\r\n",
    "tf_gref_grbcp = tf_bref_bcam"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Convert all frames in the ground reference\r\n",
    "pc_gref = [\r\n",
    "    # Apply a frame-wise transformation from bcam to gref\r\n",
    "    np.vstack(( # Stack points with reflectance\r\n",
    "        # All points as 3 x N\r\n",
    "        (\r\n",
    "            # Get point in frame i to grbcp, then to gref\r\n",
    "            tf_gref_grbcp @ tfs_grbcp_bcam[i] @ np.vstack((\r\n",
    "                # Points as 4 x N - homogeneous coordinates\r\n",
    "                pcf[:, :3].T,   # 3 x N - x, y, z in cols\r\n",
    "                np.ones((1, pcf.shape[0]))  # 1 x N - 1s\r\n",
    "            ))  # Result is 4 x N\r\n",
    "        )[:3, :],   # Remove the last row of 1s\r\n",
    "        # Reflectance - 1 x N\r\n",
    "        pcf[:, 3].reshape(1, -1)\r\n",
    "    )).T \\\r\n",
    "        # For each frame\r\n",
    "        for (i, pcf) in enumerate(pc_bcam)\r\n",
    "]   # Result is a list of np.ndarrays, each of shape (N, 4)\r\n",
    "# 4 -> x, y, z, reflectance; N-> Num of pts in the particular frame"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Visualize this in 03d\r\n",
    "o3d_pcds = [o3d.geometry.PointCloud(o3d.utility.Vector3dVector(points[:, :3]))\\\r\n",
    "    for points in pc_gref]  # All points as o3d point clouds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Call the visualization function\r\n",
    "viz_pcds_local_ss(o3d_pcds)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Get all points in one vector\r\n",
    "pcs_gref = np.vstack(pc_gref).astype(float).T  # All points as 4, N_total\r\n",
    "# All points (homogenized) in gref frame - shape 4 x N\r\n",
    "pcsh_gref = np.vstack((pcs_gref[:3, :], np.ones((1, pcs_gref.shape[1]))))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizing the point cloud\r\n",
    "\r\n",
    "We first convert to an Open3D PointCloud geometry and then use voxel down-sampling.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Convert to Open3D vector\r\n",
    "o3d_pcds = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pcsh_gref[:3, :].T))\r\n",
    "# Downsample these 9M+ points!\r\n",
    "o3d_pcds_comp = o3d_pcds.voxel_down_sample(0.25)\r\n",
    "n0 = len(o3d_pcds.points)\r\n",
    "n1 = len(o3d_pcds_comp.points)\r\n",
    "print(f\"Shrunk point cloud: {n0} -> {n1} points\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shrunk point cloud: 9413461 -> 577808 points\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "cf = o3d.geometry.TriangleMesh.create_coordinate_frame(size=10.0, origin=[0,0,0])\r\n",
    "# Visualize them all\r\n",
    "o3d.visualization.draw_geometries([o3d_pcds_comp, cf], window_name=\"Downsampled PC\",\r\n",
    "    width=1080, height=720)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Upon running the above cell and capturing images from different views, the following conclusions can be made\r\n",
    "\r\n",
    "1. Most of the points in the trajectory of the vehicle frame lie in the XY plane (with some constant offset that could be the height of the GPS/IMU). This is because the origin is above the point clouds, as seen in the image below\r\n",
    "\r\n",
    "    ![Origin and XZ plane above ground](./results/3/2/p1.jpg)\r\n",
    "\r\n",
    "2. It can also be inferred that the map was made by the vehicle taking a right turn and going forward. It is apparent that there has been a rotation about `-Z` and then straight path. Note that `+X` points in the heading direction of the vehicle. You can actually see the tire marks accumulated from future scans.\r\n",
    "\r\n",
    "    ![Vehicle heading](./results/3/2/p2.jpg)\r\n",
    "\r\n",
    "3. This is another view of the point clouds. Note that the color here is based on Z axis, which is along the height of the vehicle (red is above, blue is below).\r\n",
    "\r\n",
    "    ![Point clouds again](./results/3/2/p3.jpg)\r\n",
    "\r\n",
    "    There could be some noise in the data, giving points deeply underground\r\n",
    "\r\n",
    "    ![Points deeply underground](./results/3/2/p4.jpg)\r\n",
    "\r\n",
    "    You can filter these outliers through thresholding, or use the [colors property](http://www.open3d.org/docs/0.12.0/python_api/open3d.geometry.PointCloud.html#open3d.geometry.PointCloud.colors) and assign each point a color.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer 3: Transform Registered point cloud\r\n",
    "\r\n",
    "A function to transform the registered point cloud in `gref` to any point in the camera odometry sequence (sequence of `bcam` from odometry).\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Some variables for the function\r\n",
    "bcam_odom_poses = odom_pose_matrices    # N, 4, 4 - Sequence of bcam odometry\r\n",
    "tf_gref_osta = tf_gref_grbcp    # TF: osta in gref\r\n",
    "tf_osta_gref = inv_tf(tf_gref_osta) # TF: gref in osta\r\n",
    "pcmap_gref = pcsh_gref  # Map: Point cloud in gref (homogenized)\r\n",
    "# Function to transform world map (point clouds) in the ith camera frame\r\n",
    "def pcworld_in_bcam_odom(i):\r\n",
    "    \"\"\"\r\n",
    "    Uses the point cloud map 'pcmap_gref', and projects it into the frame\r\n",
    "    defined by 'bcam_odom_poses'['i']. The point cloud map is assumed to\r\n",
    "    be in the 'gref' frame, a fixed transform from 'gref' to 'osta' is\r\n",
    "    applied.\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - i: int    < len(bcam_odom_poses)\r\n",
    "        An index in odom poses\r\n",
    "    \"\"\"\r\n",
    "    # TF: Odometry frame 'i' in osta\r\n",
    "    tf_osta_ofi = bcam_odom_poses[i]\r\n",
    "    tf_ofi_osta = inv_tf(tf_osta_ofi)\r\n",
    "    pcmap_ofi = tf_ofi_osta @ tf_osta_gref @ pcmap_gref\r\n",
    "    return pcmap_ofi\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Get the point cloud in the ith camera frame\r\n",
    "i = 19  # Visualize the ith frame\r\n",
    "pcsh_bcami = pcworld_in_bcam_odom(i)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Convert to Open3D\r\n",
    "o3d_pcds = o3d.geometry.PointCloud(\r\n",
    "    o3d.utility.Vector3dVector(pcsh_bcami[:3, :].T))\r\n",
    "# Compress point cloud\r\n",
    "o3d_pcds_comp = o3d_pcds.voxel_down_sample(0.25)\r\n",
    "n0 = len(o3d_pcds.points)\r\n",
    "n1 = len(o3d_pcds_comp.points)\r\n",
    "print(f\"Shrunk point cloud: {n0} -> {n1} points\")\r\n",
    "# Coordinate frame (for the ith frame)\r\n",
    "cf = o3d.geometry.TriangleMesh.create_coordinate_frame(size=5, origin=[0,0,0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shrunk point cloud: 9413461 -> 577648 points\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Visualize the points in the origin of ith frame\r\n",
    "o3d.visualization.draw_geometries([o3d_pcds_comp, cf], \"Cam projection\",\r\n",
    "    width=1080, height=720)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It can be observed that the vehicle's camera frame `bcam` is indeed travelling through the world (registered point cloud). This observation can be proved because of the following screenshots\r\n",
    "\r\n",
    "1. `i = 0`: The vehicle can be seen in the starting pose\r\n",
    "\r\n",
    "    ![Pose at i = 0](./results/3/3/i1.jpg)\r\n",
    "\r\n",
    "2. `i = 10`: The vehicle can be seen making a right turn\r\n",
    "\r\n",
    "    ![Pose at i = 10](./results/3/3/i11.jpg)\r\n",
    "\r\n",
    "3. `i = 50`: The vehicle can be seen starting the straight segment\r\n",
    "\r\n",
    "    ![Pose at i = 50](./results/3/3/i51.jpg)\r\n",
    "\r\n",
    "4. `i = 76`: The vehicle can be seen at the last recorded pose\r\n",
    "\r\n",
    "    ![Pose at i = 76](./results/3/3/i77.jpg)\r\n",
    "\r\n",
    "> **Note**: The color of this is different because of the Z axis alignment of the camera frame. They may have to be colored, the object `o3d_pcds` inherently has no color."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Occupancy Map"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Occupancy grid maps are discrete fine grain grid maps. These maps can be either 2-D or 3-D. Each cell in the occupancy grid map contains information on the physical objects present in the corresponding space. Since these maps shed light on what parts of the environment are occupied, and what is not, they are really useful for path planning and navigation.\r\n",
    "\r\n",
    "Occupancy grid maps are probabilistic in nature due to noisy measurements. Each cell can have three states: Occupied, unoccupied, and unknown. For the purpose of this assignment, you can ignore the unknown and work in a binary setting where 1 is occupied and 0 is unoccupied."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. The task here is to create an occupancy map for each LiDAR scan. You do not need to apply bayesian update rules here, just keep it simple. \n",
    "\n",
    "2. Now, using the *registered* point cloud, generate occupancy maps for each frame. What difference do you expect to see between the two methods?\n",
    "\n",
    "You can mark a cell as occupied based on a threshold of how many different z values are there for a particular (x,y) cell."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer 1: Visualizing Occupancy Map for Each LiDAR scan\r\n",
    "\r\n",
    "Adjust the properties for the particular frame to be visualized\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Properties to be adjusted\r\n",
    "frame_num = 70  # Frame (or scan) number to visualize in image\r\n",
    "points_thresh = 10  # Number of points that mark a cell occupied\r\n",
    "grid_dx, grid_dy = 2.5, 2   # Grid sizes along X and Y axis\r\n",
    "gnd_lvl = -0.9  # Ground level (used for point thresholding in Z) (90 cm below bref)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Transformation of all points\r\n",
    "pc_fs_bld = pc_frames   # Point cloud in frames (list of ndarrays, N x 4)\r\n",
    "pc_hfs_bld = [   # A list of ndarrays, 4 x N - Homogeneous coordinates\r\n",
    "    np.vstack((\r\n",
    "        points[:, 0:3].T,\r\n",
    "        np.ones((1, points.shape[0]))\r\n",
    "    )) \\\r\n",
    "        for points in pc_fs_bld\r\n",
    "]\r\n",
    "# All points in the body reference frame\r\n",
    "pc_hfs_bref = [tf_bref_bld @ pts for pts in pc_hfs_bld]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Function to generate binary occupancy grid\r\n",
    "def bin_occ_grid_fm_pc(hpc, dx, dy, zthresh = 0.25):\r\n",
    "    \"\"\"\r\n",
    "    Generate occupancy grid for point clouds\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - hpc: np.ndarray      shape: 4, N\r\n",
    "        Points (in homogenized form) in point cloud\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    \"\"\"\r\n",
    "    xmin = np.amin(hpc[0, :])\r\n",
    "    xmax = np.amax(hpc[0, :])\r\n",
    "    ymin = np.amin(hpc[1, :])\r\n",
    "    ymax = np.amax(hpc[1, :])\r\n",
    "    x_lines = np.arange(xmin, xmax, dx)\r\n",
    "    y_lines = np.arange(ymin, ymax, dy)\r\n",
    "    nx = x_lines.shape[0] - 1\r\n",
    "    ny = y_lines.shape[0] - 1\r\n",
    "    occ_map = np.zeros((nx, ny))\r\n",
    "    for ix in range(nx):\r\n",
    "        for iy in range(ny):\r\n",
    "            occ_map[ix, iy] = np.sum(\r\n",
    "                (hpc[0] > x_lines[ix]) & (hpc[0] < x_lines[ix+1]) & \\\r\n",
    "                (hpc[1] > y_lines[iy]) & (hpc[1] < y_lines[iy+1]) & \\\r\n",
    "                (hpc[2] > zthresh)\r\n",
    "            )\r\n",
    "    return occ_map, x_lines, y_lines"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "o1, xv, yv = bin_occ_grid_fm_pc(pc_hfs_bref[frame_num], grid_dx, grid_dy, gnd_lvl)\r\n",
    "print(f\"Occupancy grid of shape (X, Y) = {o1.shape}\")\r\n",
    "zxi = np.argmax(xv > 0) - 1\r\n",
    "zyi = np.argmax(yv > 0) - 1\r\n",
    "print(f\"Zero in {zxi}, {zyi}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Occupancy grid of shape (X, Y) = (62, 48)\n",
      "Zero in 31, 23\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# white -> 1 (true) -> Free points; black -> 0 (false) -> Occupied points\r\n",
    "dimg = np.array((o1 < points_thresh) * 255, dtype=np.uint8)\r\n",
    "dimg = cv2.cvtColor(dimg, cv2.COLOR_GRAY2BGR)\r\n",
    "cv2.circle(dimg, (zyi, zxi), 1, (255, 0, 0), 1)\r\n",
    "print(\"255 is free and 0 is occupied\")\r\n",
    "plt.imshow(dimg, \r\n",
    "    extent=[yv[0], yv[-1], xv[-1], xv[0]], cmap=plt.cm.gray)\r\n",
    "plt.title(f\"Frame {frame_num}\")\r\n",
    "plt.colorbar()\r\n",
    "plt.xlabel(\"Y ->\")\r\n",
    "plt.ylabel(\"<- X\")\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "255 is free and 0 is occupied\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Show the point cloud using Open3D\r\n",
    "o3d_pcds = o3d.geometry.PointCloud(\r\n",
    "    o3d.utility.Vector3dVector(pc_hfs_bref[frame_num][:3, :].T))\r\n",
    "o3d.visualization.draw_geometries([o3d_pcds, cf])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference\r\n",
    "\r\n",
    "The following inference can be made by using different values for `frame_num` in the cells above (for this answer).\r\n",
    "\r\n",
    "1. The occupancy grid has different size / shape, because it's discretized based on cell size and LiDAR scans can have varying ranges (according to the scene they're in).\r\n",
    "\r\n",
    "Some observations made\r\n",
    "\r\n",
    "1. If we choose `frame_num = 2` (3rd frame in trajectory). We get the following figure\r\n",
    "\r\n",
    "    ![Frame 3](./results/4/1/f2.png)\r\n",
    "\r\n",
    "    The corresponding point cloud can be observed from the cell directly above. It appears that the only way for the vehicle (red circle) to go forward was when taking a right turn. It appears that there is an elevated surface immediately ahead (seen as elevated in the point cloud below)\r\n",
    "\r\n",
    "    ![Frame 3 in Point Cloud](./results/4/1/f2-pc.jpg)\r\n",
    "\r\n",
    "2. If we choose `frame_num = 70` (71st frame in trajectory). We get the following figure\r\n",
    "\r\n",
    "    ![Frame 71](./results/4/1/f70.png)\r\n",
    "\r\n",
    "    You can spot the cars (probably on the road running beside) and other obstacles. The corresponding point cloud is shown below\r\n",
    "\r\n",
    "    ![Frame 71 in Point Cloud](./results/4/1/f70-pc.jpg)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer 2: Registered Point Cloud in each LiDAR scan\r\n",
    "\r\n",
    "Adjust the properties for the particular frame to be visualized. Note that the entire map will be visualized here.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Properties to be adjusted\r\n",
    "frame_num = 70  # Frame (or scan) number to visualize in image\r\n",
    "points_thresh = 10  # Number of points that mark a cell occupied\r\n",
    "grid_dx, grid_dy = 2.5, 2   # Grid sizes along X and Y axis\r\n",
    "gnd_lvl = -0.9  # Ground level (used for point thresholding in Z) (90 cm below bref)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# All points in the map frame\r\n",
    "pc_map_gref = pcsh_gref   # Map (4 x N points), homogenized coordinates\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "pc_map_gref.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4, 9413461)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('mr-cs7-503': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "interpreter": {
   "hash": "833f805e531b09d5891922f3c95e86129d68dd31d00273e9af88a8ef7add9b8d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}