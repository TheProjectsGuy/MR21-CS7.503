{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment-1: Transformations and representations\r\n",
    "\r\n",
    "Personal solutions of Avneesh Mishra\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Instructions\n",
    "\n",
    "- Code must be written in Python in Jupyter Notebooks. We highly recommend using anaconda distribution or at the minimum, virtual environments for this assignment. See `Set Up` for detailed step-by-step instructions about the installation setup.\n",
    "- Save all your results in ```results/<question_number>/<sub_topic_number>/```\n",
    "- The **References** section provides you with important resources to solve the assignment.\n",
    "- For this assignment, you will be using Open3D extensively. Refer to [Open3D Documentation](http://www.open3d.org/docs/release/): you can use the in-built methods and **unless explicitly mentioned**, don't need to code from scratch for this assignment. \n",
    "- Make sure your code is modular since you may need to reuse parts for future assignments.\n",
    "- Answer the descriptive questions in your own words with context & clarity. Do not copy answers from online resources or lecture notes.\n",
    "- The **deadline** for this assignment is on 11/09/2021 at 11:55pm. Please note that there will be no extensions.\n",
    "- Plagiarism is **strictly prohibited**.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Submission Instructions\n",
    "\n",
    "1. Make sure your code runs without any errors after reinitializing the kernel and removing all saved variables.\n",
    "2. After completing your code and saving your results, zip the folder with name as ``Team_<team_name>_MR2021_Assignment_<assignment_number>.zip``"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set Up\n",
    "\n",
    "We highly recommend using anaconda distribution or at the minimum, virtual environments for this assignment. All assignments will be python based, hence familiarising yourself with Python is essential.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting up Anaconda environment (Recommended)\n",
    "\n",
    "1. Install Anaconda or Miniconda from [here](https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html) depending on your requirements.\n",
    "2. Now simply run `conda env create -f environment.yml` in the current folder to create an environment `mr_assignment1` (`environment.yml` can be found in `misc/`).\n",
    "3. Activate it using `conda activate mr_assignment1`.\n",
    "\n",
    "## Setting up Virtual environment using venv\n",
    "\n",
    "You can also set up a virtual environment using venv\n",
    "\n",
    "1. Run `sudo apt-get install python3-venv` from command line.\n",
    "2. `python3 -m venv ~/virtual_env/mr_assignment1`. (you can set the environment path to anything)\n",
    "3. `source ~/virtual_env/mr_assignment1/bin/activate`\n",
    "4. `pip3 install -r requirements.txt` from the current folder (`requirements.txt` can be found in `misc/`)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import open3d as o3d\r\n",
    "import numpy as np\r\n",
    "import copy"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Getting started with Open3D\r\n",
    "\r\n",
    "Open3D is an open-source library that deals with 3D data, such as point clouds, mesh. We'll be using Open3D frequently as we work with point clouds. Let's start with something simple:\r\n",
    "\r\n",
    "<img src=\"misc/bunny.jpg\" alt=\"drawing\" width=\"200\"/>\r\n",
    "\r\n",
    "1. Read the Stanford Bunny file (in `data/`) given to you and visualise it using Open3D.\r\n",
    "2. Convert the mesh to a point cloud and change the colour of points.\r\n",
    "3. Set a predefined viewing angle (using Open3D) for visualization and display the axes while plotting.\r\n",
    "4. Scale, Transform, and Rotate the rabbit (visualise after each step).\r\n",
    "5. Save the point cloud as bunny.pcd."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer 1: **Read and Visualize** Stanford bunny file\r\n",
    "\r\n",
    "Let's start with declaring the file name"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Read the mesh file\r\n",
    "file_name = \"./data/bunny.ply\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "\r\n",
    "- Read using [read_triangle_mesh](http://www.open3d.org/docs/release/tutorial/geometry/file_io.html#Mesh)\r\n",
    "- Visualize using [draw_geometries](http://www.open3d.org/docs/release/tutorial/visualization/visualization.html#Function-draw_geometries)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\r\n",
    "bunny_mesh = o3d.io.read_triangle_mesh(file_name)\r\n",
    "# Visualize the mesh\r\n",
    "o3d.visualization.draw_geometries([bunny_mesh], \"Bunny Mesh\", width=1080, height=720)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives the following result\r\n",
    "\r\n",
    "![Bunny mesh file](./results/1/1.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer 2: **Convert Mesh to Point Cloud** and **change color**\r\n",
    "\r\n",
    "Let's set sampling first"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "N = 2500"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "- Sample points from mesh to point cloud using [sample_points_uniformly](http://www.open3d.org/docs/release/tutorial/geometry/mesh.html#Sampling)\r\n",
    "- Paint point cloud using [paint_uniform_color](http://www.open3d.org/docs/release/tutorial/geometry/pointcloud.html#Paint-point-cloud)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Convert to point cloud with N points\r\n",
    "bunny_pc = bunny_mesh.sample_points_uniformly(N)\r\n",
    "# Show both the mesh and the point cloud version\r\n",
    "o3d.visualization.draw_geometries([bunny_mesh, bunny_pc], \"Bunny PC and Mesh\", width=1080, height=720)\r\n",
    "# Paint point cloud\r\n",
    "c = [252, 123, 3] # RGB 255 color\r\n",
    "bunny_pc.paint_uniform_color([c[0]/255, c[1]/255, c[2]/255])\r\n",
    "o3d.visualization.draw_geometries([bunny_pc], width=1080, height=720)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The output for drawing point cloud and mesh is as shown below\r\n",
    "\r\n",
    "![Point cloud and mesh](./results/1/2.1.jpg)\r\n",
    "\r\n",
    "The output after giving a custom color to the pointcloud is shown below\r\n",
    "\r\n",
    "![Colored point cloud](./results/1/2.2.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer 3: Set predefined **viewing angle** for visualization and display **axes** when plotting\r\n",
    "\r\n",
    "Let's define an axis first"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Create a coordinate frame handle using [create_coordinate_frame](http://www.open3d.org/docs/latest/python_api/open3d.geometry.TriangleMesh.html#open3d.geometry.TriangleMesh.create_coordinate_frame)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "cf = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.2, origin=[0, 0, 0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's create the function that'll do the visualization for us\r\n",
    "\r\n",
    "- Using Customized visualization as shown [here](http://www.open3d.org/docs/release/tutorial/visualization/customized_visualization.html)\r\n",
    "    - Get the [ViewControl](http://www.open3d.org/docs/0.12.0/python_api/open3d.visualization.ViewControl.html) object using [get_view_control](http://www.open3d.org/docs/0.12.0/python_api/open3d.visualization.Visualizer.html#open3d.visualization.Visualizer.get_view_control) function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def custom_draw_geometry(pcds, look_at=[0, 0.1, 0], cam_front=[-1, 0, 0.2], cam_up=[0, 1, 0], \\\r\n",
    "                         title=\"Custom View\", width=1080, height=720):\r\n",
    "    \"\"\"\r\n",
    "    Draws geometry with the specified camera parameters\r\n",
    "    \r\n",
    "    Parameters:\r\n",
    "    - pcds: [geometry]\r\n",
    "        A list of geometry objects\r\n",
    "    - look_at: (3,1)\r\n",
    "        A vector that will be at center of window\r\n",
    "    - cam_front: (3,1)\r\n",
    "        A vector where the camera front is located\r\n",
    "    - cam_up: (3, 1)\r\n",
    "        A vector that points upwards to the camera\r\n",
    "        for orientation information\r\n",
    "    - title: str    default: \"Custom View\"\r\n",
    "        The title of window\r\n",
    "    - width: int    default: 1080\r\n",
    "        Width of display window\r\n",
    "    - height: int    default: 720\r\n",
    "        Height of the display window\r\n",
    "    \"\"\"\r\n",
    "    vis = o3d.visualization.Visualizer()\r\n",
    "    vis.create_window(window_name=title, width=width, height=height)\r\n",
    "    for pcd in pcds:\r\n",
    "        vis.add_geometry(pcd)\r\n",
    "    ctr = vis.get_view_control()\r\n",
    "    ctr.set_lookat(look_at)\r\n",
    "    ctr.set_front(cam_front)\r\n",
    "    ctr.set_up(cam_up)\r\n",
    "    vis.run()\r\n",
    "    vis.destroy_window()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Display coordinate frame and bunny using this visualization\r\n",
    "custom_draw_geometry([bunny_pc, cf])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives a result like\r\n",
    "\r\n",
    "![Different view and frame](./results/1/3.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer 4: **Scale**, **Transform** and **Rotate** the point cloud\r\n",
    "\r\n",
    "Let's create a copy first"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "bunny_tfpc = copy.deepcopy(bunny_pc)\r\n",
    "c = [39, 242, 235]\r\n",
    "bunny_tfpc.paint_uniform_color([c[0]/255, c[1]/255, c[2]/255])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PointCloud with 2500 points."
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "\r\n",
    "[Transformation](http://www.open3d.org/docs/release/tutorial/geometry/transformation.html) module can be used, it has the following functions\r\n",
    "- [scale](http://www.open3d.org/docs/release/python_api/open3d.geometry.TriangleMesh.html#open3d.geometry.TriangleMesh.scale) to scale the point cloud about a point\r\n",
    "- [translate](http://www.open3d.org/docs/release/python_api/open3d.geometry.TriangleMesh.html#open3d.geometry.TriangleMesh.translate) to translate (move) the point cloud to another point (the given translation vector is added to every point)\r\n",
    "- [rotate](http://www.open3d.org/docs/release/python_api/open3d.geometry.TriangleMesh.html#open3d.geometry.TriangleMesh.rotate) to apply a rotation using a 3x3 rotation matrix\r\n",
    "    - It uses quaternion convention $\\left[ sin(\\frac{\\theta}{2}), \\hat{w_x} cos(\\frac{\\theta}{2}), \\hat{w_y} cos(\\frac{\\theta}{2}), \\hat{w_z} cos(\\frac{\\theta}{2}) \\right ]$ where $\\theta$ is the rotation angle (in radians) and $\\left[ \\hat{w_x} , \\hat{w_y}, \\hat{w_z}\\right]$ is the unit vector which is the axis of rotation. You can use [get_rotation_matrix_from_quaternion](http://www.open3d.org/docs/release/python_api/open3d.geometry.get_rotation_matrix_from_quaternion.html) to get a 3x3 rotation matrix from it\r\n",
    "- [transform](http://www.open3d.org/docs/latest/python_api/open3d.geometry.TriangleMesh.html#open3d.geometry.TriangleMesh.transform) to transform (apply a 4x4 homogeneous transformation matrix)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "bunny_tfpc = copy.deepcopy(bunny_pc)\r\n",
    "c = [39, 242, 235]\r\n",
    "bunny_tfpc.paint_uniform_color([c[0]/255, c[1]/255, c[2]/255])\r\n",
    "# Scale it\r\n",
    "bunny_tfpc.scale(0.5, center=bunny_tfpc.get_center())\r\n",
    "custom_draw_geometry([bunny_tfpc, bunny_pc, cf], title=\"Scaling\")\r\n",
    "# Translate it\r\n",
    "bunny_tfpc.translate([0, 0, 0.1])\r\n",
    "custom_draw_geometry([bunny_tfpc, bunny_pc, cf], title=\"Translation\")\r\n",
    "# Rotate it\r\n",
    "quat_axang = lambda axis, ang: [np.cos(ang/2), axis[0]*np.sin(ang/2), axis[1]*np.sin(ang/2), axis[2]*np.sin(ang/2)]\r\n",
    "rot_mat = o3d.geometry.get_rotation_matrix_from_quaternion(quat_axang([1, 0, 0], np.deg2rad(90)))\r\n",
    "bunny_tfpc.rotate(rot_mat, center=bunny_tfpc.get_center())\r\n",
    "custom_draw_geometry([bunny_tfpc, bunny_pc, cf], title=\"Rotation\")\r\n",
    "# Transform it\r\n",
    "tf_mat = np.eye(4)\r\n",
    "tf_mat[:3, :3] = o3d.geometry.get_rotation_matrix_from_quaternion(quat_axang([0, 0, 1], np.deg2rad(180)))\r\n",
    "tf_mat[:3, 3] = [0, 0.1, 0]\r\n",
    "bunny_tfpc.transform(tf_mat)\r\n",
    "custom_draw_geometry([bunny_tfpc, bunny_pc, cf], title=\"Transformation\", look_at=[0, 0, 0.1], cam_up=[0, 0, 1], \\\r\n",
    "                     cam_front=[1, 0.1, 0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following are the results\r\n",
    "\r\n",
    "![Scaling](./results/1/4.1.jpg)\r\n",
    "![Translation](./results/1/4.2.jpg)\r\n",
    "![Rotation](./results/1/4.3.jpg)\r\n",
    "![Transformation](./results/1/4.4.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer 5: **Save** the point cloud to a file\r\n",
    "\r\n",
    "Let's declare the file name to use"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "bunny_tfpc_fname = \"./results/1/bunny.pcd\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "\r\n",
    "- Use [write_point_cloud](http://www.open3d.org/docs/release/python_api/open3d.io.write_point_cloud.html#open3d.io.write_point_cloud) function to write a point cloud to a file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "\r\n",
    "o3d.io.write_point_cloud(bunny_tfpc_fname, bunny_tfpc)\r\n",
    "# Read it and see if it got saveed properly\r\n",
    "bunny_tfpcr = o3d.io.read_point_cloud(bunny_tfpc_fname)\r\n",
    "custom_draw_geometry([bunny_tfpcr, cf], title=\"Saved Bunny\", look_at=[0, 0, 0.1], cam_up=[0, 0, 1], \\\r\n",
    "                     cam_front=[1, 0.1, 0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives the following output\n",
    "\n",
    "- A file [bunny.pcd](./results/1/bunny.pcd) having the following point cloud\n",
    "\n",
    "    ![Saved bunny](./results/1/5.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Transformations and representations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## a) Euler angles\r\n",
    "1. Write a function that returns a rotation matrix given the angles $\\alpha$, $\\beta$, and $\\gamma$ in radians (X-Y-Z)\r\n",
    "\r\n",
    "2. Solve for angles using ```fsolve from scipy``` for three initializations of your choice and compare.\r\n",
    "$$M(\\alpha , \\beta ,\\gamma)=\\left[\\begin{array}{rrr}0.26200263 & -0.19674724 & 0.944799 \\\\0.21984631 & 0.96542533 & 0.14007684 \\\\\r\n",
    "    -0.93969262 & 0.17101007 & 0.29619813\\end{array}\\right] \r\n",
    "$$\r\n",
    "\r\n",
    "$$N(\\alpha , \\beta ,\\gamma)=\\left[\\begin{array}{rrr}0 & -0.173648178 &  0.984807753 \\\\0 & 0.984807753 & 0.173648178 \\\\\r\n",
    "    -1 & 0 & 0\\end{array}\\right] \r\n",
    "$$\r\n",
    "\r\n",
    "3. What is a Gimbal lock? \r\n",
    "\r\n",
    "4. Show an example where a Gimbal lock occurs and visualize the Gimbal lock on the given bunny point cloud. You have to show the above by **animation** (cube rotating along each axis one by one).\r\n",
    "    - *Hint: Use Open3D's non-blocking visualization and discretize the rotation to simulate the animation. For example, if you want to rotate by $30^{\\circ}$ around a particular axis, do in increments of $5^{\\circ}$ 6 times to make it look like an animation.*\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 1: Get Rotation Matrix (XYZ Rotation)\r\n",
    "Assuming rotation is in local frame\r\n",
    "\r\n",
    "Start by importing everything"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Import sympy for all symbolic computation\r\n",
    "import sympy as sp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions for rotation about **X**, **Y** and **Z** axis (for symbolic angles)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Rotate about X axis\r\n",
    "def RotX(angle, degrees = False):\r\n",
    "    \"\"\"\r\n",
    "    Generates a Rotation matrice when the rotation is about X axis\r\n",
    "    A general rotation about X (Roll) is given by\r\n",
    "\r\n",
    "                | 1    0    0 |\r\n",
    "    RotX(T) =   | 0   cT  -sT |\r\n",
    "                | 0   sT   cT |\r\n",
    "\r\n",
    "    Where T is rotation angle in radians\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - angle: Symbol or float\r\n",
    "        The angle of rotation\r\n",
    "    - degrees: bool     default: False\r\n",
    "        If 'True', then angle parameter is assumed to be in degrees\r\n",
    "        else it is by default assumed to be in radians\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - rot_mat: sp.Matrix        shape: (3, 3)\r\n",
    "        The 3x3 rotation matrix for Roll by angle_rad\r\n",
    "    \"\"\"\r\n",
    "    angle_rad = angle if not degrees else sp.rad(angle)\r\n",
    "    rot_mat = sp.Matrix([\r\n",
    "        [1, 0, 0],\r\n",
    "        [0, sp.cos(angle_rad), -sp.sin(angle_rad)],\r\n",
    "        [0, sp.sin(angle_rad), sp.cos(angle_rad)],\r\n",
    "    ])\r\n",
    "    return rot_mat\r\n",
    "\r\n",
    "# Rotate about Y Axis\r\n",
    "def RotY(angle, degrees = False):\r\n",
    "    \"\"\"\r\n",
    "    Generates a Rotation matrice when the rotation is about Y axis\r\n",
    "    A general rotation about Y (Pitch) is given by\r\n",
    "\r\n",
    "                |  cT   0   sT |\r\n",
    "    RotY(T) =   |   0   1    0 |\r\n",
    "                | -sT   0   cT |\r\n",
    "\r\n",
    "    Where T is rotation angle in radians\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - angle: Symbol or float\r\n",
    "        The angle of rotation\r\n",
    "    - degrees: bool     default: False\r\n",
    "        If 'True', then angle parameter is assumed to be in degrees\r\n",
    "        else it is by default assumed to be in radians\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - rot_mat: sp.Matrix        shape: (3, 3)\r\n",
    "        The 3x3 rotation matrix for Pitch by angle_rad\r\n",
    "    \"\"\"\r\n",
    "    angle_rad = angle if not degrees else sp.rad(angle)\r\n",
    "    rot_mat = sp.Matrix([\r\n",
    "        [sp.cos(angle_rad), 0, sp.sin(angle_rad)],\r\n",
    "        [0, 1, 0],\r\n",
    "        [-sp.sin(angle_rad), 0, sp.cos(angle_rad)],\r\n",
    "    ])\r\n",
    "    return rot_mat\r\n",
    "\r\n",
    "# Rotate about Z Axis\r\n",
    "def RotZ(angle, degrees = False):\r\n",
    "    \"\"\"\r\n",
    "    Generates a Rotation matrice when the rotation is about Z axis\r\n",
    "    A general rotation about Z (Yaw) is given by\r\n",
    "\r\n",
    "                | cT   -sT   0 |\r\n",
    "    RotZ(T) =   | sT    cT   0 |\r\n",
    "                |  0     0   1 |\r\n",
    "\r\n",
    "    Where T is rotation angle in radians\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - angle: Symbol or float\r\n",
    "        The angle of rotation\r\n",
    "    - degrees: bool     default: False\r\n",
    "        If 'True', then angle parameter is assumed to be in degrees\r\n",
    "        else it is by default assumed to be in radians\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - rot_mat: sp.Matrix        shape: (3, 3)\r\n",
    "        The 3x3 rotation matrix for Yaw by angle_rad\r\n",
    "    \"\"\"\r\n",
    "    angle_rad = angle if not degrees else sp.rad(angle)\r\n",
    "    rot_mat = sp.Matrix([\r\n",
    "        [sp.cos(angle_rad), -sp.sin(angle_rad), 0],\r\n",
    "        [sp.sin(angle_rad), sp.cos(angle_rad), 0],\r\n",
    "        [0, 0, 1],\r\n",
    "    ])\r\n",
    "    return rot_mat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use the above functions to create a symbolic equation. The output for variable `eu_xyz` should be\r\n",
    "\r\n",
    "$$ \\left[\\begin{matrix}\\cos{\\left(\\beta \\right)} \\cos{\\left(\\gamma \\right)} & - \\sin{\\left(\\gamma \\right)} \\cos{\\left(\\beta \\right)} & \\sin{\\left(\\beta \\right)}\\\\\\sin{\\left(\\alpha \\right)} \\sin{\\left(\\beta \\right)} \\cos{\\left(\\gamma \\right)} + \\sin{\\left(\\gamma \\right)} \\cos{\\left(\\alpha \\right)} & - \\sin{\\left(\\alpha \\right)} \\sin{\\left(\\beta \\right)} \\sin{\\left(\\gamma \\right)} + \\cos{\\left(\\alpha \\right)} \\cos{\\left(\\gamma \\right)} & - \\sin{\\left(\\alpha \\right)} \\cos{\\left(\\beta \\right)}\\\\\\sin{\\left(\\alpha \\right)} \\sin{\\left(\\gamma \\right)} - \\sin{\\left(\\beta \\right)} \\cos{\\left(\\alpha \\right)} \\cos{\\left(\\gamma \\right)} & \\sin{\\left(\\alpha \\right)} \\cos{\\left(\\gamma \\right)} + \\sin{\\left(\\beta \\right)} \\sin{\\left(\\gamma \\right)} \\cos{\\left(\\alpha \\right)} & \\cos{\\left(\\alpha \\right)} \\cos{\\left(\\beta \\right)}\\end{matrix}\\right] $$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Angle symbols\r\n",
    "al, be, ga = sp.symbols(r\"\\alpha, \\beta, \\gamma\")\r\n",
    "eu_xyz = RotX(al) * RotY(be) * RotZ(ga)\r\n",
    "eu_xyz"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}\\cos{\\left(\\beta \\right)} \\cos{\\left(\\gamma \\right)} & - \\sin{\\left(\\gamma \\right)} \\cos{\\left(\\beta \\right)} & \\sin{\\left(\\beta \\right)}\\\\\\sin{\\left(\\alpha \\right)} \\sin{\\left(\\beta \\right)} \\cos{\\left(\\gamma \\right)} + \\sin{\\left(\\gamma \\right)} \\cos{\\left(\\alpha \\right)} & - \\sin{\\left(\\alpha \\right)} \\sin{\\left(\\beta \\right)} \\sin{\\left(\\gamma \\right)} + \\cos{\\left(\\alpha \\right)} \\cos{\\left(\\gamma \\right)} & - \\sin{\\left(\\alpha \\right)} \\cos{\\left(\\beta \\right)}\\\\\\sin{\\left(\\alpha \\right)} \\sin{\\left(\\gamma \\right)} - \\sin{\\left(\\beta \\right)} \\cos{\\left(\\alpha \\right)} \\cos{\\left(\\gamma \\right)} & \\sin{\\left(\\alpha \\right)} \\cos{\\left(\\gamma \\right)} + \\sin{\\left(\\beta \\right)} \\sin{\\left(\\gamma \\right)} \\cos{\\left(\\alpha \\right)} & \\cos{\\left(\\alpha \\right)} \\cos{\\left(\\beta \\right)}\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[                                      cos(\\beta)*cos(\\gamma),                                       -sin(\\gamma)*cos(\\beta),              sin(\\beta)],\n",
       "[sin(\\alpha)*sin(\\beta)*cos(\\gamma) + sin(\\gamma)*cos(\\alpha), -sin(\\alpha)*sin(\\beta)*sin(\\gamma) + cos(\\alpha)*cos(\\gamma), -sin(\\alpha)*cos(\\beta)],\n",
       "[sin(\\alpha)*sin(\\gamma) - sin(\\beta)*cos(\\alpha)*cos(\\gamma),  sin(\\alpha)*cos(\\gamma) + sin(\\beta)*sin(\\gamma)*cos(\\alpha),  cos(\\alpha)*cos(\\beta)]])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 2: Solve for angles using **fsolve** from scipy\r\n",
    "\r\n",
    "Let's start by importing scipy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from scipy.optimize import fsolve"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Solving the rotation matrix\r\n",
    "\r\n",
    "- Use [scipy.optimize.fsolve](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fsolve.html)\r\n",
    "- You could also use [sympy.solvers.solve](https://docs.sympy.org/latest/modules/solvers/solvers.html), set `check=False` (argument) and manually check each solution using [np.allclose](https://numpy.org/doc/stable/reference/generated/numpy.allclose.html#numpy.allclose) (substitute the solution and compare with the real matrix, **M** or **N**)\r\n",
    "\r\n",
    "Using some analysis from the above equation, we can have the following formulas\r\n",
    "\r\n",
    "$$ \\alpha = \\textup{arctan2} \\left( -R_{23},R_{33} \\right ) $$\r\n",
    "$$ \\beta = \\textup{arctan2} \\left( R_{13}, \\sqrt{1-R_{13}^{2}} \\right ) $$\r\n",
    "$$ \\gamma = \\textup{arctan2} \\left( -R_{12}, R_{11} \\right ) $$\r\n",
    "\r\n",
    "Hopefully, we won't run into a case when $\\beta = 90 \\: \\textup{deg}$, because then $\\alpha$ and $\\beta$ cannot be resolved (the arguments to $\\textup{arctan2}$ will become $0$). We can use the above three equations to solve for angles."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Original Matrices\r\n",
    "M_abg = [\r\n",
    "    [ 0.26200263, -0.19674724,  0.944799],\r\n",
    "    [ 0.21984631,  0.96542533,  0.14007684],\r\n",
    "    [-0.93969262,  0.17101007,  0.29619813]\r\n",
    "]\r\n",
    "M_np = np.array(M_abg, dtype=float)\r\n",
    "M_sp = sp.Matrix(M_np)\r\n",
    "N_abg = [\r\n",
    "    [ 0.        , -0.17364818,  0.98480775],\r\n",
    "    [ 0.        ,  0.98480775,  0.17364818],\r\n",
    "    [-1.        ,  0.        ,  0.        ]\r\n",
    "]\r\n",
    "N_np = np.array(N_abg, dtype=float)\r\n",
    "N_sp = sp.Matrix(N_np)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Function of equations\r\n",
    "def func_solve_eu_m(eu_angs, mat):\r\n",
    "    ax = eu_angs[0]\r\n",
    "    ay = eu_angs[1]\r\n",
    "    az = eu_angs[2]\r\n",
    "    eqs = [\r\n",
    "        ax - np.arctan2(-mat[1,2], mat[2,2]),\r\n",
    "        ay - np.arctan2(mat[0,2], (1-mat[0,2]**2)**0.5),\r\n",
    "        az - np.arctan2(-mat[0,1], mat[0,0])\r\n",
    "    ]\r\n",
    "    return eqs\r\n",
    "# Solve for M\r\n",
    "init_vals_m = [ # Put all the initial guess values here (in radians)\r\n",
    "    [3, 2, 4],\r\n",
    "    [0.5, 0.5, 0.5],\r\n",
    "    [-1, -1, 2]\r\n",
    "]\r\n",
    "print(\"Roots for M\")\r\n",
    "for init_val in init_vals_m:\r\n",
    "    root = fsolve(func_solve_eu_m, init_val, M_np)\r\n",
    "    print(f\"\\tRoot with init value {init_val}\")\r\n",
    "    print(f\"\\t\\tRadians: {np.round(root, 3)}\")\r\n",
    "    print(f\"\\t\\tDegrees: {np.round(np.rad2deg(root), 3)}\")\r\n",
    "# Solve for N\r\n",
    "init_vals_n = [\r\n",
    "    [1.5, 2, 5],\r\n",
    "    [5, 1.5, 1.5],\r\n",
    "    [2, 4, 5]\r\n",
    "]\r\n",
    "print(\"Roots for N\")\r\n",
    "for init_val in init_vals_n:\r\n",
    "    root = fsolve(func_solve_eu_m, init_val, N_np)\r\n",
    "    print(f\"\\tRoot with init value {init_val}\")\r\n",
    "    print(f\"\\t\\tRadians: {np.round(root, 3)}\")\r\n",
    "    print(f\"\\t\\tDegrees: {np.round(np.rad2deg(root), 3)}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Roots for M\n",
      "\tRoot with init value [3, 2, 4]\n",
      "\t\tRadians: [-0.442  1.237  0.644]\n",
      "\t\tDegrees: [-25.31   70.874  36.904]\n",
      "\tRoot with init value [0.5, 0.5, 0.5]\n",
      "\t\tRadians: [-0.442  1.237  0.644]\n",
      "\t\tDegrees: [-25.31   70.874  36.904]\n",
      "\tRoot with init value [-1, -1, 2]\n",
      "\t\tRadians: [-0.442  1.237  0.644]\n",
      "\t\tDegrees: [-25.31   70.874  36.904]\n",
      "Roots for N\n",
      "\tRoot with init value [1.5, 2, 5]\n",
      "\t\tRadians: [-1.571  1.396  1.571]\n",
      "\t\tDegrees: [-90.  80.  90.]\n",
      "\tRoot with init value [5, 1.5, 1.5]\n",
      "\t\tRadians: [-1.571  1.396  1.571]\n",
      "\t\tDegrees: [-90.  80.  90.]\n",
      "\tRoot with init value [2, 4, 5]\n",
      "\t\tRadians: [-1.571  1.396  1.571]\n",
      "\t\tDegrees: [-90.  80.  90.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Solution using sympy.solve\r\n",
    "# -- For M --\r\n",
    "solutions = sp.solvers.solve(sp.Eq(eu_xyz, M_sp), al, be, ga, check=False)\r\n",
    "true_solutions = []\r\n",
    "for (ax, ay, az) in solutions:\r\n",
    "    lhs_mat = np.array(eu_xyz.subs({al: ax, be: ay, ga: az}), dtype=float)\r\n",
    "    if np.allclose(lhs_mat, M_np):\r\n",
    "        true_solutions.append([ax, ay, az])\r\n",
    "sol_m = np.array(copy.deepcopy(true_solutions), dtype=float)   # Solutions for M\r\n",
    "print(\"M can be solved using (XYZ)\")\r\n",
    "for (i, sol) in enumerate(sol_m):\r\n",
    "    print(f\"\\tSolution {i+1}\")\r\n",
    "    print(f\"\\t\\t(radians): {np.round(sol, 3)}\")\r\n",
    "    print(f\"\\t\\t(degrees): {np.round(np.rad2deg(sol), 3)}\")\r\n",
    "# -- For N --\r\n",
    "solutions = sp.solvers.solve(sp.Eq(eu_xyz, N_sp), al, be, ga, check=False)\r\n",
    "true_solutions = []\r\n",
    "for (ax, ay, az) in solutions:\r\n",
    "    lhs_mat = np.array(eu_xyz.subs({al: ax, be: ay, ga: az}), dtype=float)\r\n",
    "    if np.allclose(lhs_mat, N_np):\r\n",
    "        true_solutions.append([ax, ay, az])\r\n",
    "sol_n = np.array(copy.deepcopy(true_solutions), dtype=float)   # Solutions for N\r\n",
    "print(\"N can be solved using (XYZ)\")\r\n",
    "for (i, sol) in enumerate(sol_n):\r\n",
    "    print(f\"\\tSolution {i+1}\")\r\n",
    "    print(f\"\\t\\t(radians): {np.round(sol, 3)}\")\r\n",
    "    print(f\"\\t\\t(degrees): {np.round(np.rad2deg(sol), 3)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "M can be solved using (XYZ)\n",
      "\tSolution 1\n",
      "\t\t(radians): [-0.442  1.237  0.644]\n",
      "\t\t(degrees): [-25.31   70.874  36.904]\n",
      "\tSolution 2\n",
      "\t\t(radians): [2.7   1.905 3.786]\n",
      "\t\t(degrees): [154.69  109.126 216.904]\n",
      "N can be solved using (XYZ)\n",
      "\tSolution 1\n",
      "\t\t(radians): [1.571 1.745 4.712]\n",
      "\t\t(degrees): [ 90. 100. 270.]\n",
      "\tSolution 2\n",
      "\t\t(radians): [4.712 1.396 1.571]\n",
      "\t\t(degrees): [270.  80.  90.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following values will satisfy for **M** (all angles in degrees)\r\n",
    "\r\n",
    "| **Alpha** | **Beta** | **Gamma** |\r\n",
    "| :--- | :--- | :---- |\r\n",
    "| -25.31 | 70.874  | 36.904  |\r\n",
    "| 154.69 | 109.126 | 216.904 |\r\n",
    "\r\n",
    "The following values will satisfy for **N** (all angles in degrees)\r\n",
    "\r\n",
    "| **Alpha** | **Beta** | **Gamma** |\r\n",
    "| :--- | :--- | :---- |\r\n",
    "| 90.  | 100. | 270. |\r\n",
    "| 270. | 80.  | 90.  |\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 3: Gimbal Lock\r\n",
    "\r\n",
    "Mathematical definition and explanation through code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "\r\n",
    "Mathematically, it's when resolving orientations from the rotation matrix is not feasible. For instance, the **Euler XYZ** rotation matrix (as derived earlier) is given by\r\n",
    "\r\n",
    "$$ \\left[\\begin{matrix}\\cos{\\left(\\beta \\right)} \\cos{\\left(\\gamma \\right)} & - \\sin{\\left(\\gamma \\right)} \\cos{\\left(\\beta \\right)} & \\sin{\\left(\\beta \\right)}\\\\\\sin{\\left(\\alpha \\right)} \\sin{\\left(\\beta \\right)} \\cos{\\left(\\gamma \\right)} + \\sin{\\left(\\gamma \\right)} \\cos{\\left(\\alpha \\right)} & - \\sin{\\left(\\alpha \\right)} \\sin{\\left(\\beta \\right)} \\sin{\\left(\\gamma \\right)} + \\cos{\\left(\\alpha \\right)} \\cos{\\left(\\gamma \\right)} & - \\sin{\\left(\\alpha \\right)} \\cos{\\left(\\beta \\right)}\\\\\\sin{\\left(\\alpha \\right)} \\sin{\\left(\\gamma \\right)} - \\sin{\\left(\\beta \\right)} \\cos{\\left(\\alpha \\right)} \\cos{\\left(\\gamma \\right)} & \\sin{\\left(\\alpha \\right)} \\cos{\\left(\\gamma \\right)} + \\sin{\\left(\\beta \\right)} \\sin{\\left(\\gamma \\right)} \\cos{\\left(\\alpha \\right)} & \\cos{\\left(\\alpha \\right)} \\cos{\\left(\\beta \\right)}\\end{matrix}\\right] $$\r\n",
    "\r\n",
    "Which is also the same as **Fixed ZYX**. Substituting $\\beta = \\frac{\\pi}{2}$, we get\r\n",
    "\r\n",
    "$$ \\left[\\begin{matrix}0 & 0 & 1\\\\\\sin{\\left(\\alpha \\right)} \\cos{\\left(\\gamma \\right)} + \\sin{\\left(\\gamma \\right)} \\cos{\\left(\\alpha \\right)} & - \\sin{\\left(\\alpha \\right)} \\sin{\\left(\\gamma \\right)} + \\cos{\\left(\\alpha \\right)} \\cos{\\left(\\gamma \\right)} & 0\\\\\\sin{\\left(\\alpha \\right)} \\sin{\\left(\\gamma \\right)} - \\cos{\\left(\\alpha \\right)} \\cos{\\left(\\gamma \\right)} & \\sin{\\left(\\alpha \\right)} \\cos{\\left(\\gamma \\right)} + \\sin{\\left(\\gamma \\right)} \\cos{\\left(\\alpha \\right)} & 0\\end{matrix}\\right] $$\r\n",
    "\r\n",
    "Resolving $\\alpha$ and $\\gamma$ is now impossible, because the above matrix is essentially\r\n",
    "\r\n",
    "$$ \\left[\\begin{matrix}0 & 0 & 1\\\\\\sin{\\left(\\alpha + \\gamma \\right)} & \\cos{\\left(\\alpha + \\gamma \\right)} & 0\\\\- \\cos{\\left(\\alpha + \\gamma \\right)} & \\sin{\\left(\\alpha + \\gamma \\right)} & 0\\end{matrix}\\right] $$\r\n",
    "\r\n",
    "This should be verified by the code block below"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Substitute beta as pi/2 and simplify result\r\n",
    "sp.simplify(eu_xyz.subs({be:sp.pi/2}))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}0 & 0 & 1\\\\\\sin{\\left(\\alpha + \\gamma \\right)} & \\cos{\\left(\\alpha + \\gamma \\right)} & 0\\\\- \\cos{\\left(\\alpha + \\gamma \\right)} & \\sin{\\left(\\alpha + \\gamma \\right)} & 0\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[                    0,                    0, 1],\n",
       "[ sin(\\alpha + \\gamma), cos(\\alpha + \\gamma), 0],\n",
       "[-cos(\\alpha + \\gamma), sin(\\alpha + \\gamma), 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can therefore only find $\\alpha +\\gamma$ (not the individual angles). This also means that their _individual information_ is lost (singularity!), only the $\\alpha + \\gamma$ value decides the final orientation. \r\n",
    "\r\n",
    "Consider the below cases:\r\n",
    "1. We first rotate by `10` degrees about X, then cause a singularity by rotating `90` degrees about Y, then rotate by `30` degrees about Z (all axis rotations are in local frame).\r\n",
    "2. We first rotate by `0` degrees about X (no movement), then cause a singularity by rotating `90` degrees about Y, then rotate by `40` degrees about Z (all axis rotations are in local frame).\r\n",
    "3. We first rotate by `30` degrees about X, then cause a singularity by rotating `90` degrees about Y, then rotate by `10` degrees about Z (all axis rotations are in local frame).\r\n",
    "4. We first rotate by `40` degrees about X, then cause a singularity by rotating `90` degrees about Y, then rotate by `0` degrees (no movement) about Z (all axis rotations are in local frame).\r\n",
    "\r\n",
    "**All** the above cases have the **exact same** outcome, which when given to a system, cannot be distinguished. This can be verified by running the cell below\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "eu_xyz_d = RotX(al, True) * RotY(be, True) * RotZ(ga, True)\r\n",
    "r_case1 = np.array(eu_xyz_d.subs({al:10, be:90, ga:30}), dtype=float)\r\n",
    "r_case2 = np.array(eu_xyz_d.subs({al:0, be:90, ga:40}), dtype=float)\r\n",
    "r_case3 = np.array(eu_xyz_d.subs({al:30, be:90, ga:10}), dtype=float)\r\n",
    "r_case4 = np.array(eu_xyz_d.subs({al:40, be:90, ga:0}), dtype=float)\r\n",
    "if np.allclose(r_case1, r_case2) and np.allclose(r_case2, r_case3) \\\r\n",
    "    and np.allclose(r_case3, r_case4):\r\n",
    "    print(\"All cases yield the same rotation matrix!\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All cases yield the same rotation matrix!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A similar problem happens when we substitute $\\beta = -\\frac{\\pi}{2}$ and with **every** three angle representation of rotations. This is the problem with **explicit parameterization** of rotations. To preserve the essence of rotation (to know what actually happened), we use **implicit parameterization**, like quaternions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 4: Visualizing Gimbal Lock through Bunny\r\n",
    "\r\n",
    "Let's start by importing the original bunny file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Read the mesh file\r\n",
    "file_name = \"./data/bunny.ply\"\r\n",
    "bunny_mesh = o3d.io.read_triangle_mesh(file_name)\r\n",
    "# Convert mesh to point cloud\r\n",
    "N = 2500\r\n",
    "c = [252, 123, 3]   # Color of point cloud\r\n",
    "bunny_pc = bunny_mesh.sample_points_uniformly(N)\r\n",
    "bunny_pc.paint_uniform_color([c[0]/255, c[1]/255, c[2]/255])\r\n",
    "# A frame (for reference)\r\n",
    "ref_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.2, origin=[0,0,0])\r\n",
    "custom_draw_geometry([bunny_pc, ref_frame])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The **XYZ Euler** angles are the same as **ZYX Fixed** rotation angles, that is, instead of rotating about X, then Y, then Z local axis; we rotate about Z, then Y, and then X global / fixed axis. The result is the same (both have the same rotation matrix for $\\alpha$, $\\beta$ and $\\gamma$ being angles for X,Y and Z respectively).\r\n",
    "\r\n",
    "We compare the following two cases in animation\r\n",
    "1. Rotate about global (fixed) Z by `30` degrees, then global Y by `90` degrees and then global X by `10` degrees\r\n",
    "2. Rotate about global (fixed) Z by `10` degrees, then global Y by `90` degrees and then global X by `30` degrees\r\n",
    "\r\n",
    "We should observe that the final pose of both the above cases is the same. Therefore showing that individual rotations (about global Z and X) cannot be resolved because of the singularity"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Fixed rotations (Case 1)\r\n",
    "bunny_case1 = copy.deepcopy(bunny_pc)\r\n",
    "c = [63, 207, 50]   # Color of point cloud (case 1)\r\n",
    "bunny_case1.paint_uniform_color([c[0]/255, c[1]/255, c[2]/255])\r\n",
    "bunny_case1.rotate(np.array(RotZ(30, True), dtype=float), [0, 0, 0])\r\n",
    "bunny_case1.rotate(np.array(RotY(sp.pi/2), dtype=float), [0, 0, 0])\r\n",
    "bunny_case1.rotate(np.array(RotX(10, True), dtype=float), [0, 0, 0])\r\n",
    "# Fixed rotations (Case 2)\r\n",
    "bunny_case2 = copy.deepcopy(bunny_pc)\r\n",
    "c = [46, 60, 219]   # Color of point cloud (case 2)\r\n",
    "bunny_case2.paint_uniform_color([c[0]/255, c[1]/255, c[2]/255])\r\n",
    "bunny_case2.rotate(np.array(RotZ(10, True), dtype=float), [0, 0, 0])\r\n",
    "bunny_case2.rotate(np.array(RotY(sp.pi/2), dtype=float), [0, 0, 0])\r\n",
    "bunny_case2.rotate(np.array(RotX(30, True), dtype=float), [0, 0, 0])\r\n",
    "# Both are the same\r\n",
    "if np.allclose(np.array(bunny_case1.points, float), \\\r\n",
    "    np.array(bunny_case2.points, float)):\r\n",
    "    print(\"Both point clouds are same (result may be superimposed)\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Both point clouds are same (result may be superimposed)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's visualize the transformations\r\n",
    "- Use the [non-blocking](http://www.open3d.org/docs/release/tutorial/visualization/non_blocking_visualization.html) visualization features of Open3D"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def visualize_pc_ZYX_rot(pc: o3d.geometry.PointCloud, az: float, ay: float, \\\r\n",
    "    ax: float, deg = False, static_gs = None, **kwargs):\r\n",
    "    \"\"\"\r\n",
    "    Visualizes the point cloud rotation through ZYX fixed rotations (same result \r\n",
    "    as XYZ Euler angles). Creates an animation window that shows the animation.\r\n",
    "    This function captures the execution till the animation is over. A few notes\r\n",
    "    about the animation:\r\n",
    "    - All rotations happen w.r.t. center as [0, 0, 0]\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - pc: o3d.geometry.PointCloud\r\n",
    "        The point cloud which will be visualized. It is copied (transformations\r\n",
    "        are not applied to the point cloud passed). All properties are deeply\r\n",
    "        copied.\r\n",
    "    - az: float\r\n",
    "        Angle of rotation about the Z axis.\r\n",
    "    - ay: float\r\n",
    "        Angle of rotation about the Y axis.\r\n",
    "    - ax: float\r\n",
    "        Angle of rotation about the X axis.\r\n",
    "    - deg: bool     default: False\r\n",
    "        Interpret the angles passed as if they're in degrees (not radians). If \r\n",
    "        'ax', 'ay' and 'az' passed to the function are in radians, then this\r\n",
    "        must be 'False', else if they're in degres, then this must be 'True'.\r\n",
    "    - static_gs: list of o3d.geometry.Geometry objects  default = None\r\n",
    "        A list of Geometry objects that can be displayed in the visualization\r\n",
    "        window. You can pass coordinate frames, other point clouds, etc.\r\n",
    "    - **kwargs: unwrapped dictionary (keyword arguments)\r\n",
    "        - look_at: list (len=3)     default: [0.1, 0.1, 0]\r\n",
    "            Set camera look_at for visualization\r\n",
    "        - cam_front: list (len=3)   default: [0, 0, 1]\r\n",
    "            Set camera front vector\r\n",
    "        - cam_up: list (len=3)      default: [0, 1, 0]\r\n",
    "            Set camera up vector\r\n",
    "        - viz_title: str        default: \"Animation\"\r\n",
    "            The title of animation window\r\n",
    "        - sz: float     default: 5.0\r\n",
    "            Default step size for Z rotation (in degrees)\r\n",
    "        - sy: float     default: 5.0\r\n",
    "            Default step size for Y rotation (in degrees)\r\n",
    "        - sx: float     default: 5.0\r\n",
    "            Default step size for Z rotation (in degrees)\r\n",
    "        - save_imgs: bool   default: False\r\n",
    "            If True, it saves images in 'save_path' variable. Directories\r\n",
    "            have to be existing beforehand (they're not created)\r\n",
    "        - save_path: bool   default: \"./results/\"\r\n",
    "            The path / folder where the images are saved\r\n",
    "\r\n",
    "    Returns:\r\n",
    "    - final_pc: o3d.geometry.PointCloud\r\n",
    "        The final point cloud after all rotations are applied to it\r\n",
    "    \"\"\"\r\n",
    "    # Animation objects\r\n",
    "    pctf: o3d.geometry.PointCloud = copy.deepcopy(pc)   # Point Cloud to be transformed\r\n",
    "    # Some properties of animation\r\n",
    "    sz = 5.0 if \"sz\" not in kwargs else kwargs[\"sz\"]\r\n",
    "    step_size_z = float(np.deg2rad(sz))   # Step size (increment angle) in radians\r\n",
    "    del_time_z = 0.25  # Delay time in seconds\r\n",
    "    sy = 5.0 if \"sy\" not in kwargs else kwargs[\"sy\"]\r\n",
    "    step_size_y = float(np.deg2rad(sy))  # Step size for Rot Y animation\r\n",
    "    del_time_y = 0.25   # Delay time for Y animation\r\n",
    "    sx = 5.0 if \"sx\" not in kwargs else kwargs[\"sx\"]\r\n",
    "    step_size_x = float(np.deg2rad(sx))  # Step size for Rot X animation\r\n",
    "    del_time_x = 0.25   # Delay time for X animation\r\n",
    "    end_wait_time = 5  # Wait time in the end (before destroying window) in sec\r\n",
    "    save_path = \"./results/\" if \"save_path\" not in kwargs else kwargs[\"save_path\"]\r\n",
    "    save_imgs = False if \"save_imgs\" not in kwargs else kwargs[\"save_imgs\"]\r\n",
    "    # Some properties of visualization window\r\n",
    "    viz_title = \"Animation\" if \"viz_title\" not in kwargs else kwargs[\"viz_title\"]\r\n",
    "    viz_width = 1080\r\n",
    "    viz_height = 720\r\n",
    "    look_at = [0.1, 0.1, 0] if \"look_at\" not in kwargs else kwargs[\"look_at\"]\r\n",
    "    cam_front = [0, 0, 1] if \"cam_front\" not in kwargs else kwargs[\"cam_front\"]\r\n",
    "    cam_up = [0, 1, 0] if \"cam_up\" not in kwargs else kwargs[\"cam_up\"]\r\n",
    "    # Some variables to not calculate every loop\r\n",
    "    rot_z = np.array(RotZ(step_size_z), dtype=float)\r\n",
    "    rot_y = np.array(RotY(step_size_y), dtype=float)\r\n",
    "    rot_x = np.array(RotX(step_size_x), dtype=float)\r\n",
    "    # -- Start non-blocking visualization --\r\n",
    "    vis = o3d.visualization.Visualizer()\r\n",
    "    vis.create_window(viz_title, viz_width, viz_height)\r\n",
    "    vis.add_geometry(pctf)\r\n",
    "    # Add all static geometries\r\n",
    "    if static_gs is not None:\r\n",
    "        for static_geo in static_gs:\r\n",
    "            vis.add_geometry(static_geo)\r\n",
    "    # Set view\r\n",
    "    ctr = vis.get_view_control()\r\n",
    "    ctr.set_lookat(look_at)\r\n",
    "    ctr.set_front(cam_front)\r\n",
    "    ctr.set_up(cam_up)\r\n",
    "    vis.poll_events()\r\n",
    "    vis.update_renderer()\r\n",
    "    if save_imgs:\r\n",
    "        vis.capture_screen_image(f\"{save_path}/{viz_title}_start.jpg\")\r\n",
    "    # Rotate about Z axis\r\n",
    "    ar_z = float(np.deg2rad(az)) if deg else float(az)\r\n",
    "    steps_z = int(np.around(ar_z/step_size_z))\r\n",
    "    for i in range(steps_z):\r\n",
    "        # Rotate by step\r\n",
    "        pctf.rotate(rot_z, center=[0, 0, 0])\r\n",
    "        # Render\r\n",
    "        vis.update_geometry(pctf)\r\n",
    "        st_time = time.time()\r\n",
    "        while (time.time() - st_time < del_time_z):\r\n",
    "            vis.poll_events()\r\n",
    "            vis.update_renderer()\r\n",
    "        if save_imgs:\r\n",
    "            vis.capture_screen_image(f\"{save_path}/{viz_title}_rz_{i}.jpg\")\r\n",
    "    # Rotate about Y axis\r\n",
    "    ar_y = float(np.deg2rad(ay)) if deg else float(ay)\r\n",
    "    steps_y = int(np.around(ar_y/step_size_y))\r\n",
    "    for i in range(steps_y):\r\n",
    "        # Rotate by step\r\n",
    "        pctf.rotate(rot_y, center=[0, 0, 0])\r\n",
    "        # Render\r\n",
    "        vis.update_geometry(pctf)\r\n",
    "        st_time = time.time()\r\n",
    "        while (time.time() - st_time < del_time_y):\r\n",
    "            vis.poll_events()\r\n",
    "            vis.update_renderer()\r\n",
    "        if save_imgs:\r\n",
    "            vis.capture_screen_image(f\"{save_path}/{viz_title}_ry_{i}.jpg\")\r\n",
    "    # Rotate about X axis\r\n",
    "    ar_x = float(np.deg2rad(ax)) if deg else float(ax)\r\n",
    "    steps_x = int(np.around(ar_x/step_size_x))\r\n",
    "    for i in range(steps_x):\r\n",
    "        # Rotate by step\r\n",
    "        pctf.rotate(rot_x, center=[0, 0, 0])\r\n",
    "        # Render\r\n",
    "        vis.update_geometry(pctf)\r\n",
    "        st_time = time.time()\r\n",
    "        while (time.time() - st_time < del_time_x):\r\n",
    "            vis.poll_events()\r\n",
    "            vis.update_renderer()\r\n",
    "        if save_imgs:\r\n",
    "            vis.capture_screen_image(f\"{save_path}/{viz_title}_rx_{i}.jpg\")\r\n",
    "    # Destroy everything\r\n",
    "    st_time = time.time()\r\n",
    "    while (time.time() - st_time < end_wait_time):\r\n",
    "        vis.poll_events()\r\n",
    "        vis.update_renderer()\r\n",
    "    if save_imgs:\r\n",
    "        vis.capture_screen_image(f\"{save_path}/{viz_title}_end.jpg\")\r\n",
    "    vis.destroy_window()\r\n",
    "    # Return things\r\n",
    "    return pctf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Animations for case 1 (ZYX = 30, 90, 10)\r\n",
    "bunny_case1 = copy.deepcopy(bunny_pc)\r\n",
    "c = [63, 207, 50]   # Color of point cloud (case 1)\r\n",
    "bunny_case1.paint_uniform_color([c[0]/255, c[1]/255, c[2]/255])\r\n",
    "bunny_case1 = visualize_pc_ZYX_rot(bunny_case1, 30, 90, 10, True, \\\r\n",
    "    static_gs=[ref_frame], \\\r\n",
    "    look_at=[0, 0.05, 0.05], cam_front=[0.9, 0.3, 0.3], \\\r\n",
    "    viz_title=\"Case1\", save_imgs=False, save_path=\"./results/2/imgs\")\r\n",
    "\r\n",
    "# Animations for case 2 (ZYX = 10, 90, 30)\r\n",
    "bunny_case2 = copy.deepcopy(bunny_pc)\r\n",
    "c = [46, 60, 219]   # Color of point cloud (case 2)\r\n",
    "bunny_case2.paint_uniform_color([c[0]/255, c[1]/255, c[2]/255])\r\n",
    "bunny_case2 = visualize_pc_ZYX_rot(bunny_case2, 10, 90, 30, True, \\\r\n",
    "    static_gs=[ref_frame], \\\r\n",
    "    look_at=[0, 0.05, 0.05], cam_front=[0.9, 0.3, 0.3], \\\r\n",
    "    viz_title=\"Case2\", save_imgs=False, save_path=\"./results/2/imgs\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparing different outputs\r\n",
    "\r\n",
    "To save the images, set `save_imgs=True` in the function calls above.\r\n",
    "\r\n",
    "The **Case 1** output looks like\r\n",
    "\r\n",
    "![A](./results/2/Case1.gif)\r\n",
    "\r\n",
    "The **Case 2** output looks like\r\n",
    "\r\n",
    "![B](./results/2/Case2.gif)\r\n",
    "\r\n",
    "GIF made using [this app on Windows 10](https://www.microsoft.com/en-us/p/gif-maker-gif-editor/9pkc9pxzxg9r?activetab=pivot:overviewtab)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Both are the same finally\r\n",
    "if np.allclose(np.array(bunny_case1.points, float), \\\r\n",
    "    np.array(bunny_case2.points, float)):\r\n",
    "    print(\"Both point clouds are same\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Both point clouds are same\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## b) Quaternions\r\n",
    "\r\n",
    "1. What makes Quaternions popular in graphics? \r\n",
    "2. Convert a rotation matrix to quaternion and vice versa. Do not use inbuilt libraries for this question.\r\n",
    "3. Perform matrix multiplication of two $\\mathcal{R}_{3 \\times 3}$ rotation matrices and perform the same transformation in the quaternion space. Verify if the final transformation obtained in both the cases are the same.\r\n",
    "4. Try to interpolate any 3D model (cube / bunny / not sphere obviously!!) between two rotation matrices and visualize!\r\n",
    "\r\n",
    "The above questions require you to **code your own functions** and **only verify** using inbuilt functions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 1: Quaternions in Graphics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Intuition\r\n",
    "\r\n",
    "The concept of quaternions comes from complex numbers. Complex number multiplication can be thought of as rotation of a vector in a 2D plane. Consider the complex number multiplication below\r\n",
    "\r\n",
    "$$ ( a + \\mathbf{i} b ) ( c + \\mathbf{i} d ) = (ac-bd) + \\mathbf{i} (bc+ad) $$\r\n",
    "\r\n",
    "This can be visualized as a matrix multiplication\r\n",
    "\r\n",
    "$$ ( a + \\mathbf{i} b ) ( c + \\mathbf{i} d ) = \\begin{bmatrix}\r\n",
    "a & -b \\\\\r\n",
    "b & a\r\n",
    "\\end{bmatrix} \\begin{bmatrix} \r\n",
    "c \\\\\r\n",
    "d\r\n",
    "\\end{bmatrix} $$\r\n",
    "\r\n",
    "If $(a+\\mathbf{i}b) = \\cos (\\theta) + \\mathbf{i} \\sin (\\theta)$ the above matrix becomes a rotation matrix (note that the complex number still has two numbers, but one constraint)\r\n",
    "\r\n",
    "$$ \\mathbf{R} = \\begin{bmatrix}\r\n",
    "\\cos (\\theta) & -\\sin (\\theta) \\\\\r\n",
    "\\sin (\\theta) & \\cos (\\theta)\r\n",
    "\\end{bmatrix} \\begin{bmatrix}\r\n",
    "c \\\\\r\n",
    "d\r\n",
    "\\end{bmatrix} $$\r\n",
    "\r\n",
    "Quaternions extend this logic to rotations in three dimensions. As observed earlier, euler angles (which are explicit parameters) run into singularity issues. This makes interpolation and resolving difficult. Quaternions allow representation of rotations using four numbers, with one constraint. Say there is a rotation about the unit vector $\\vec{u} = u_x \\mathbf{i} + u_y \\mathbf{j} + u_z \\mathbf{k}$ by angle of $\\theta$, the quaternion representation is given by\r\n",
    "\r\n",
    "$$ \\mathbf{q} = e^{\\frac{\\theta}{2} \\left( u_x \\mathbf{i} + u_y \\mathbf{j} + u_z \\mathbf{k} \\right) } = \\cos \\frac{\\theta}{2} + \\left( u_x \\mathbf{i} + u_y \\mathbf{j} + u_z \\mathbf{k} \\right) \\sin \\frac{\\theta}{2} $$\r\n",
    "\r\n",
    "The multiplication rules are $\\mathbf{i}^2 = \\mathbf{j}^2 = \\mathbf{k}^2 = \\mathbf{i} \\mathbf{j} \\mathbf{k} = -1$ and $\\mathbf{i} \\mathbf{j} = \\mathbf{k}$, $\\mathbf{j} \\mathbf{k} = \\mathbf{i}$, $\\mathbf{k} \\mathbf{i} = \\mathbf{j}$. This makes programming their multiplication simpler (than even matrix multiplication). This, along with the fact that they don't have singularity problems, makes them a good tool to express orientations (and therefore a popular tool in graphics). However, most of the times, they're internally abstracted."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reference\r\n",
    "\r\n",
    "- [eater.net/quaternions](https://eater.net/quaternions)\r\n",
    "- 3Blue1Brown YouTube videos\r\n",
    "    - [Visualizing quaternions as a projection](https://www.youtube.com/watch?v=d4EgbgTm0Bg)\r\n",
    "    - [Rotations using quaternions](https://www.youtube.com/watch?v=zjMuIxRvygQ&t=4s)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 2: Matrix and Quaternion conversions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Convert quaternion to rotation matrix**\r\n",
    "\r\n",
    "Using Rodrigues' rotations formula, the rotation matrix when a rotation about unit vector $\\mathbf{k}$ by angle $\\theta$ (using right hand thumb rule) is given by\r\n",
    "\r\n",
    "$$ \\mathbf{R} = \\mathbf{I} + (\\sin \\theta) \\mathbf{[k]} + (1-\\cos \\theta) \\mathbf{[k]}^2 $$\r\n",
    "\r\n",
    "Where \r\n",
    "$$ \r\n",
    "\\mathbf{[k]} = \\begin{bmatrix}\r\n",
    "0 & -k_z & k_y \\\\\r\n",
    "k_z & 0 & -k_x \\\\\r\n",
    "-k_y & k_x & 0 \r\n",
    "\\end{bmatrix} \r\n",
    "\\;\\; \\textup{and} \\;\\;\r\n",
    "\\mathbf{[k]}^2 = \\begin{bmatrix}\r\n",
    "-k_y^2-k_z^2 & k_x k_y & k_x k_z \\\\\r\n",
    "k_y k_x & -k_x^2-k_z^2 & k_y k_z \\\\\r\n",
    "k_z k_x & k_z k_y & -k_x^2-k_y^2\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "Using a quaternion notation $ \\mathbf{q} = \\left[ k_x \\sin \\left( \\frac{\\theta}{2} \\right ), \\; k_y \\sin \\left( \\frac{\\theta}{2} \\right ), \\; k_z \\sin \\left( \\frac{\\theta}{2} \\right ), \\; \\cos \\left( \\frac{\\theta}{2} \\right ) \\right ] = [q_1, q_2, q_3, q_4] $ the above matrix $\\mathbf{R}$ can be reduced. We use $(1-\\cos \\theta) = 2 \\sin^2 \\frac{\\theta}{2}$ and $\\sin \\theta = 2 \\sin \\left( \\frac{\\theta}{2} \\right ) \\cos \\left( \\frac{\\theta}{2} \\right )$. We get the following result\r\n",
    "\r\n",
    "$$\r\n",
    "\\mathbf{R} = \\begin{bmatrix}\r\n",
    "1-2q_2^2-2q_3^2 & 2 (q_1 q_2 - q_3 q_4) & 2 (q_1 q_3 + q_2 q_4) \\\\\r\n",
    "2 (q_2 q_1 + q_3 q_4) & 1-2q_1^2-2q_3^2 & 2 (q_2 q_3 - q_1 q_4) \\\\\r\n",
    "2 (q_3 q_1 - q_2 q_4) & 2 (q_2 q_3 + q_1 q_4) & 1-2q_1^2-2q_2^2\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "This can be programmed and tested"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Function\r\n",
    "def quat_to_rm(qx, qy, qz, qw):\r\n",
    "    \"\"\"\r\n",
    "    Convert a quaternion to a 3x3 rotation matrix.The convention\r\n",
    "    used to represent quaternions is\r\n",
    "        [ux*sin(th/2), uy*sin(th/2), uz*sin(th/2), cos(th/2)]\r\n",
    "\r\n",
    "    Paraemters:\r\n",
    "    - qx: float\r\n",
    "        Quaternion k_x * sin(th/2)\r\n",
    "    - qy: float\r\n",
    "        Quaternion k_y * sin(th/2)\r\n",
    "    - qz: float\r\n",
    "        Quaternion k_z * sin(th/2)\r\n",
    "    - qw: float\r\n",
    "        Quaternion cos(th/2)\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - rot_m: np.ndarray     shape: (3, 3)   dtype: float\r\n",
    "        Rotation matrix constructed using the quaternions\r\n",
    "    \"\"\"\r\n",
    "    q1 = float(qx)\r\n",
    "    q2 = float(qy)\r\n",
    "    q3 = float(qz)\r\n",
    "    q4 = float(qw)\r\n",
    "    rot_m = np.array([\r\n",
    "        [1-2*(q2**2)-2*(q3**2), 2*(q1*q2-q3*q4), 2*(q1*q3+q2*q4)],\r\n",
    "        [2*(q2*q1+q3*q4), 1-2*(q1**2)-2*(q3**2), 2*(q2*q3-q1*q4)],\r\n",
    "        [2*(q3*q1-q2*q4), 2*(q2*q3+q1*q4), (1-2*(q1)**2-2*(q2)**2)]\r\n",
    "    ], dtype=float)\r\n",
    "    return rot_m"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Testing quaternion to rotation matrix\r\n",
    "r_actual = np.array(RotX(sp.pi/3), dtype=float)\r\n",
    "r = quat_to_rm(1*np.sin(0.5*np.pi/3), 0, 0, np.cos(0.5*np.pi/3))\r\n",
    "if np.allclose(r, r_actual):\r\n",
    "    print(\"Works for RotX\")\r\n",
    "r_actual = np.array(RotY(sp.pi/2), dtype=float)\r\n",
    "r = quat_to_rm(0, 1*np.sin(0.5*np.pi/2), 0, np.cos(0.5*np.pi/2))\r\n",
    "if np.allclose(r, r_actual):\r\n",
    "    print(\"Works for RotY\")\r\n",
    "r_actual = np.array(RotZ(sp.pi/6), dtype=float)\r\n",
    "r = quat_to_rm(0, 0, 1*np.sin(0.5*np.pi/6), np.cos(0.5*np.pi/6))\r\n",
    "if np.allclose(r, r_actual):\r\n",
    "    print(\"Works for RotZ\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Works for RotX\n",
      "Works for RotY\n",
      "Works for RotZ\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Convert rotation matrix to quaternion**\r\n",
    "\r\n",
    "Consider\r\n",
    "\r\n",
    "$$\r\n",
    "\\mathbf{R} = \\begin{bmatrix}\r\n",
    "r_{11} & r_{12} & r_{13} \\\\\r\n",
    "r_{21} & r_{22} & r_{23} \\\\\r\n",
    "r_{31} & r_{32} & r_{33}\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "We need to get quaternion $ \\mathbf{q} = \\left[ k_x \\sin \\left( \\frac{\\theta}{2} \\right ), \\; k_y \\sin \\left( \\frac{\\theta}{2} \\right ), \\; k_z \\sin \\left( \\frac{\\theta}{2} \\right ), \\; \\cos \\left( \\frac{\\theta}{2} \\right ) \\right ] = [q_1, q_2, q_3, q_4] $ from the above matrix. To do that, follow the following steps\r\n",
    "\r\n",
    "1. Calculate $\\mathbf{v}$ using the formula below\r\n",
    "\r\n",
    "    $$ \r\n",
    "    \\mathbf{v} = \\begin{bmatrix}\r\n",
    "    v_1 \\\\ v_2 \\\\ v_3 \\\\ v_4\r\n",
    "    \\end{bmatrix} = \\begin{bmatrix}\r\n",
    "    \\frac{1}{2} \\sqrt{1+r_{11}-r_{22}-r_{33}} \\\\\r\n",
    "    \\frac{1}{2} \\sqrt{1-r_{11}+r_{22}-r_{33}} \\\\\r\n",
    "    \\frac{1}{2} \\sqrt{1-r_{11}-r_{22}+r_{33}} \\\\\r\n",
    "    \\frac{1}{2} \\sqrt{1+r_{11}+r_{22}+r_{33}}\r\n",
    "    \\end{bmatrix}\r\n",
    "    $$\r\n",
    "\r\n",
    "    For the next step, get the maximum value among $v_1, v_2, v_3, v_4$ (all values of $\\mathbf{v}$).\r\n",
    "\r\n",
    "2. If $v_1$ is largest in $\\mathbf{v}$, calculate the rest using $q_1 = v_1$. The quaternions are given by\r\n",
    "\r\n",
    "    $$\r\n",
    "    \\mathbf{q} = \\begin{bmatrix}\r\n",
    "    q_1 \\\\ q_2 \\\\ q_3 \\\\ q_4\r\n",
    "    \\end{bmatrix} = \\begin{bmatrix}\r\n",
    "    v_1 \\\\\r\n",
    "    \\frac{r_{12} + r_{21}}{4q_1} \\\\\r\n",
    "    \\frac{r_{13} + r_{31}}{4q_1} \\\\\r\n",
    "    \\frac{r_{32} - r_{23}}{4q_1}\r\n",
    "    \\end{bmatrix}\r\n",
    "    $$\r\n",
    "\r\n",
    "    This follows that\r\n",
    "\r\n",
    "    $$ q_1 = v_1 = \\frac{1}{2} \\sqrt{1+r_{11}-r_{22}-r_{33}} $$\r\n",
    "\r\n",
    "3. If $v_2$ is largest in $\\mathbf{v}$, calculate the rest using $q_2 = v_2$. The quaternions are given by\r\n",
    "\r\n",
    "    $$\r\n",
    "    \\mathbf{q} = \\begin{bmatrix}\r\n",
    "    q_1 \\\\ q_2 \\\\ q_3 \\\\ q_4\r\n",
    "    \\end{bmatrix} = \\begin{bmatrix}\r\n",
    "    \\frac{r_{12}+r_{21}}{4q_2} \\\\\r\n",
    "    v_2 \\\\\r\n",
    "    \\frac{r_{23}+r_{32}}{4q_2} \\\\\r\n",
    "    \\frac{r_{13}-r_{31}}{4q_2}\r\n",
    "    \\end{bmatrix}\r\n",
    "    $$\r\n",
    "\r\n",
    "    This follows that\r\n",
    "\r\n",
    "    $$ q_2 = v_2 = \\frac{1}{2} \\sqrt{1-r_{11}+r_{22}-r_{33}} $$\r\n",
    "\r\n",
    "4. If $v_3$ is largest in $\\mathbf{v}$, calculate the rest using $q_3 = v_3$. The quaternions are given by\r\n",
    "\r\n",
    "    $$\r\n",
    "    \\mathbf{q} = \\begin{bmatrix}\r\n",
    "    q_1 \\\\ q_2 \\\\ q_3 \\\\ q_4\r\n",
    "    \\end{bmatrix} = \\begin{bmatrix}\r\n",
    "    \\frac{r_{13}+r_{31}}{4q_3} \\\\\r\n",
    "    \\frac{r_{23}+r_{32}}{4q_3} \\\\\r\n",
    "    v_3 \\\\\r\n",
    "    \\frac{r_{21}-r_{12}}{4q_3}\r\n",
    "    \\end{bmatrix}\r\n",
    "    $$\r\n",
    "\r\n",
    "    This follows that\r\n",
    "\r\n",
    "    $$ q_3 = v_3 = \\frac{1}{2} \\sqrt{1-r_{11}-r_{22}+r_{33}} $$\r\n",
    "\r\n",
    "5. If $v_4$ is largest in $\\mathbf{v}$, calculate the rest using $q_4 = v_4$. The quaternions are given by\r\n",
    "\r\n",
    "    $$\r\n",
    "    \\mathbf{q} = \\begin{bmatrix}\r\n",
    "    q_1 \\\\ q_2 \\\\ q_3 \\\\ q_4\r\n",
    "    \\end{bmatrix} = \\begin{bmatrix}\r\n",
    "    \\frac{r_{32}-r_{23}}{4q_4} \\\\\r\n",
    "    \\frac{r_{13}-r_{31}}{4q_4} \\\\\r\n",
    "    \\frac{r_{21}-r_{12}}{4q_4} \\\\\r\n",
    "    v_4 \\\\\r\n",
    "    \\end{bmatrix}\r\n",
    "    $$\r\n",
    "\r\n",
    "    This follows that\r\n",
    "\r\n",
    "    $$ q_4 = v_4 = \\frac{1}{2} \\sqrt{1+r_{11}+r_{22}+r_{33}} $$\r\n",
    "\r\n",
    "This has to be programmed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Function\r\n",
    "def rm_to_quat(rot_m):\r\n",
    "    \"\"\"\r\n",
    "    Convert a rotation matrix to quaternions. The convention\r\n",
    "    used to represent quaternions is\r\n",
    "        [ux*sin(th/2), uy*sin(th/2), uz*sin(th/2), cos(th/2)]\r\n",
    "    \r\n",
    "    Parameters:\r\n",
    "    - rot_m: np.ndarray     shape: (3,3)\r\n",
    "        A 3x3 rotation matrix\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - qx: float\r\n",
    "        Quaternion ux*sin(th/2)\r\n",
    "    - qy: float\r\n",
    "        Quaternion uy*sin(th/2)\r\n",
    "    - qz: float\r\n",
    "        Quaternion uz*sin(th/2)\r\n",
    "    - qw: float\r\n",
    "        Quaternion cos(th/2)\r\n",
    "    \"\"\"\r\n",
    "    # Parse all elements\r\n",
    "    [r11, r12, r13] = rot_m[0, :]\r\n",
    "    [r21, r22, r23] = rot_m[1, :]\r\n",
    "    [r31, r32, r33] = rot_m[2, :]\r\n",
    "    # Get 'v' vector\r\n",
    "    v = np.array([\r\n",
    "        0.5*((1+r11-r22-r33)**0.5), # v1\r\n",
    "        0.5*((1-r11+r22-r33)**0.5), # v2\r\n",
    "        0.5*((1-r11-r22+r33)**0.5), # v3\r\n",
    "        0.5*((1+r11+r22+r33)**0.5)  # v4\r\n",
    "    ])\r\n",
    "    mvi = np.argmax(v)  # Maximum value quaternion\r\n",
    "    # Returning vector\r\n",
    "    qx = 0.0\r\n",
    "    qy = 0.0\r\n",
    "    qz = 0.0\r\n",
    "    qw = 1.0\r\n",
    "    if mvi == 0:    # v1\r\n",
    "        qx = v[0]\r\n",
    "        qy = (r12 + r21)/(4*v[0])\r\n",
    "        qz = (r13 + r31)/(4*v[0])\r\n",
    "        qw = (r32 - r23)/(4*v[0])\r\n",
    "    elif mvi == 1:  # v2\r\n",
    "        qx = (r12 + r21)/(4*v[1])\r\n",
    "        qy = v[1]\r\n",
    "        qz = (r23 + r32)/(4*v[1])\r\n",
    "        qw = (r13 - r31)/(4*v[1])\r\n",
    "    elif mvi == 2:  # v3\r\n",
    "        qx = (r13 + r31)/(4*v[2])\r\n",
    "        qy = (r23 + r32)/(4*v[2])\r\n",
    "        qz = v[2]\r\n",
    "        qw = (r21 - r12)/(4*v[2])\r\n",
    "    elif mvi == 3:  # v4\r\n",
    "        qx = (r32 - r23)/(4*v[3])\r\n",
    "        qy = (r13 - r31)/(4*v[3])\r\n",
    "        qz = (r21 - r12)/(4*v[3])\r\n",
    "        qw = v[3]\r\n",
    "    return [qx, qy, qz, qw]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use [scipy.spatial.transform.Rotation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.html#scipy.spatial.transform.Rotation) for verification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Let's verify it this works\r\n",
    "from scipy.spatial.transform import Rotation\r\n",
    "rot_mat = np.array(RotX(25, True) * RotY(30, True) * RotZ(30, True), dtype=float)\r\n",
    "qvals = np.array(rm_to_quat(rot_mat))\r\n",
    "qvals_actual = Rotation.from_matrix(rot_mat).as_quat()\r\n",
    "if np.allclose(qvals, qvals_actual):\r\n",
    "    print(\"Quaternion logic appears correct\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Quaternion logic appears correct\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 3: Transformations using Quaternions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform quaternion multiplication using standard rules of quaternion multiplication. The multiplication rules are $\\mathbf{i}^2 = \\mathbf{j}^2 = \\mathbf{k}^2 = \\mathbf{i} \\mathbf{j} \\mathbf{k} = -1$ and $\\mathbf{i} \\mathbf{j} = \\mathbf{k}$, $\\mathbf{j} \\mathbf{k} = \\mathbf{i}$, $\\mathbf{k} \\mathbf{i} = \\mathbf{j}$. Refer to the image below for graph representation\r\n",
    "\r\n",
    "[![Cayley Q8 quaternion multiplication graph.svg](https://upload.wikimedia.org/wikipedia/commons/0/04/Cayley_Q8_quaternion_multiplication_graph.svg)](https://en.wikipedia.org/wiki/File:Cayley_Q8_quaternion_multiplication_graph.svg)\r\n",
    "\r\n",
    "The result is the [Hamilton product](https://en.wikipedia.org/wiki/Quaternion#Hamilton_product) of quaternions, but using our convention"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Function to multiply two quaternions\r\n",
    "def quat_mul(qu1, qu2):\r\n",
    "    \"\"\"\r\n",
    "    Perform quaternion multiplication and return the result. The\r\n",
    "    multiplication result is qu1 * qu2. The convention used to \r\n",
    "    represent quaternions is\r\n",
    "        [ux*sin(th/2), uy*sin(th/2), uz*sin(th/2), cos(th/2)]\r\n",
    "    The first three elements are [i,j,k] components and the last\r\n",
    "    one is the real component\r\n",
    "\r\n",
    "    Paraemters:\r\n",
    "    - qu1: list or np.ndarray   shape: (4,)\r\n",
    "        First quaternion\r\n",
    "    - qu2: list or np.ndarray   shape: (4,)\r\n",
    "        Second quaternion\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - qu_res: list      len: 4\r\n",
    "        Resultant quaternion which is obtained by qu1 * qu2 after\r\n",
    "        applying the rules of quaternion multiplication. Note\r\n",
    "        that the result is [qx, qy, qz, qw].\r\n",
    "    \"\"\"\r\n",
    "    [q11, q12, q13, q14] = qu1\r\n",
    "    [q21, q22, q23, q24] = qu2\r\n",
    "    qu_res = [\r\n",
    "        q11*q24 + q12*q23 - q13*q22 + q14*q21,  # qx\r\n",
    "        -q11*q23 + q12*q24 + q13*q21 + q14*q22, # qy\r\n",
    "        q11*q22 - q12*q21 + q13*q24 + q14*q23,  # qz\r\n",
    "        q14*q24 - q11*q21 - q12*q22 - q13*q23   # qw\r\n",
    "    ]\r\n",
    "    return qu_res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Compare multiplication of rot1 and rot2\r\n",
    "rot1 = np.array(RotX(30, True) * RotY(45, True), dtype=float)\r\n",
    "qu1 = rm_to_quat(rot1)\r\n",
    "rot2 = np.array(RotY(45, True) * RotZ(10, True), dtype=float)\r\n",
    "qu2 = rm_to_quat(rot2)\r\n",
    "# Rotation matrix multiplication\r\n",
    "rot_res = rot1 @ rot2\r\n",
    "quatr_res = rm_to_quat(rot_res)\r\n",
    "# Quaternion multiplication\r\n",
    "qu_res = quat_mul(qu1, qu2)\r\n",
    "rotq_res = quat_to_rm(*qu_res)\r\n",
    "# Check if close\r\n",
    "if np.allclose(rot_res, rotq_res):\r\n",
    "    print(\"Quaternion and rotation matrix multiplication give the same rotation matrices\")\r\n",
    "if np.allclose(quatr_res, qu_res):\r\n",
    "    print(\"Quaternion and rotation matrix multiplication give the same quaternions\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Quaternion and rotation matrix multiplication give the same rotation matrices\n",
      "Quaternion and rotation matrix multiplication give the same quaternions\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Inverting quaternions**\r\n",
    "\r\n",
    "This can be done using the [conjugate of the quaternion](https://en.wikipedia.org/wiki/Quaternion#Unit_quaternion)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Quaternion inverse\r\n",
    "def quat_inv(qu):\r\n",
    "    \"\"\"\r\n",
    "    Constructs an inverse of quaternion passed. The convention used\r\n",
    "    to represent quaternions is\r\n",
    "        [ux*sin(th/2), uy*sin(th/2), uz*sin(th/2), cos(th/2)]\r\n",
    "    Quaternion has to be of unit length, as the function actually\r\n",
    "    returns the conjugate\r\n",
    "    \r\n",
    "    Paraemters:\r\n",
    "    - qu: list or np.ndarray   shape: (4,)\r\n",
    "        Quaternion that has to be inverted\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - qu_inv: list or np.ndarray   shape: (4,)\r\n",
    "        Inverted quaternion. Multiplication of this qith 'qu' should\r\n",
    "        give the unit quaternion [0, 0, 0, 1]\r\n",
    "    \"\"\"\r\n",
    "    [q1, q2, q3, q4] = qu\r\n",
    "    qu_inv = [-q1, -q2, -q3, q4]    # Inverse quaternion\r\n",
    "    return qu_inv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# Check if inversion works fine\r\n",
    "qu1_inv = quat_inv(qu1)\r\n",
    "qu_identity = quat_mul(qu1, qu1_inv)\r\n",
    "qu_identity2 = quat_mul(qu1_inv, qu1)\r\n",
    "if np.allclose(qu_identity, qu_identity2):\r\n",
    "    print(\"Quaternion inversion works fine\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Quaternion inversion works fine\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 4: Interpolation using Quaternions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quaternion interpolation requires conservation of the length of quaternions (they must all be unit lengths). The **SLERP** algorithm performs _Spherical Linear Interpolation_ and has the following formula\r\n",
    "\r\n",
    "$$ Slerp \\left( t; \\mathbf{q}_{i}, \\mathbf{q}_{f} \\right ) = \\frac{\\textup{Sin} \\left( (1-t) \\theta \\right )}{\\textup{Sin} (\\theta)} \\mathbf{q}_{i} \\: + \\: \\frac{\\textup{Sin} \\left( t \\theta \\right )}{\\textup{Sin} (\\theta)} \\mathbf{q}_{f} $$\r\n",
    "\r\n",
    "Where $ \\theta = \\textup{cos}^{-1} \\left( \\mathbf{q}_i \\: \\cdot \\: \\mathbf{q}_f \\right ) $\r\n",
    "\r\n",
    "**Reference**\r\n",
    "\r\n",
    "- [Geometric Slerp on Wikipedia](https://en.wikipedia.org/wiki/Slerp#Geometric_Slerp)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Return intermediate quaternions\r\n",
    "def gen_intermediate_quats(quat_init, quat_final, N=10):\r\n",
    "    \"\"\"\r\n",
    "    Generate intermediate quaternions from an initial to final\r\n",
    "    quaternion rotation pose. The convention used to represent \r\n",
    "    quaternions is\r\n",
    "        [ux*sin(th/2), uy*sin(th/2), uz*sin(th/2), cos(th/2)]\r\n",
    "\r\n",
    "    The function uses SLERP (Spherical Linear Interpolation)\r\n",
    "    to interpolate intermediate points\r\n",
    "    \r\n",
    "    Parameters:\r\n",
    "    - quat_init: list or np.ndarray     shape: (4,)\r\n",
    "        Initial quaternion. All values must be normalized and\r\n",
    "        floating point (they're case to float)\r\n",
    "    - quat_final: list or np.ndarray     shape: (4,)\r\n",
    "        Final quaternion. All values must be normalized and\r\n",
    "        floating point (they're case to float)\r\n",
    "    - N: int    default: 10\r\n",
    "        The number of intermediate steps. This is NOT time\r\n",
    "        sampled. Assume a time range from 0 to 1, broken into\r\n",
    "        N stages\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - qu_n_vals: np.ndarray     shape: (N, 4)\r\n",
    "        The sequence of quaternions\r\n",
    "    \"\"\"\r\n",
    "    # Initial and final quaternions\r\n",
    "    qu_i = np.array(quat_init, dtype=float)\r\n",
    "    qu_f = np.array(quat_final, dtype=float)\r\n",
    "    # Theta values\r\n",
    "    theta = np.arccos(np.dot(qu_i, qu_f))\r\n",
    "    # Interpolation timestamps\r\n",
    "    t = np.linspace(0, 1, N)\r\n",
    "    coeffs_init = np.sin((1-t)*theta)/np.sin(theta)\r\n",
    "    coeffs_final = np.sin(t*theta)/np.sin(theta)\r\n",
    "    # All values\r\n",
    "    qu_n_vals = coeffs_init.reshape(-1, 1) * qu_i + coeffs_final.reshape(-1, 1) * qu_f\r\n",
    "    return qu_n_vals"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Animation of point cloud between orientations\r\n",
    "def visualize_pc_rots(pc: o3d.geometry.PointCloud, qu_i, qu_f, N = 10, static_gs = None, \\\r\n",
    "    color_init = [46,60,219], color_final = [63,207,50], color_anim = [240,165,53], \\\r\n",
    "    ):\r\n",
    "    \"\"\"\r\n",
    "    Visualizes a point cloud rotating between two given orientations\r\n",
    "    as quaternions. The point cloud convention used is as follows\r\n",
    "        [ux*sin(th/2), uy*sin(th/2), uz*sin(th/2), cos(th/2)]\r\n",
    "    The point cloud of initial and final stages is also displayed\r\n",
    "\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - pc: o3d.geometry.PointCloud\r\n",
    "        The point cloud which will be visualized. This is not altered\r\n",
    "        and a deepcopy is always used.\r\n",
    "    - qu_i: list or np.ndarray      shape: (4,)     dtype: float\r\n",
    "        Initial orientation as a quaternion (normalized)\r\n",
    "    - qu_f: list or np.ndarray      shape: (4,)     dtype: float\r\n",
    "        Final orientation as a quaternion (normalized)\r\n",
    "    - N: int\r\n",
    "        Number of intermediate orientations to show\r\n",
    "    - static_gs: list of o3d.geometry.Geometry objects  default = None\r\n",
    "        A list of Geometry objects that can be displayed in the \r\n",
    "        visualization window. You can pass coordinate frames, other \r\n",
    "        point clouds, etc.\r\n",
    "    - color_init: list      len: 3  default: [46,60,219]\r\n",
    "        The color of initial point cloud\r\n",
    "    - color_final: list     len: 3  default: [63,207,50]\r\n",
    "        The color of final point cloud\r\n",
    "    - color_anim: list      len: 3  default: [240,165,53]\r\n",
    "        The color of point cloud when in animation (intermediate stages)\r\n",
    "    \r\n",
    "    \"\"\"\r\n",
    "    # Animation objects and variables\r\n",
    "    pc_main = copy.deepcopy(pc)\r\n",
    "    pc_init = copy.deepcopy(pc_main)\r\n",
    "    pc_final = copy.deepcopy(pc_main)\r\n",
    "    pc_inter = copy.deepcopy(pc_main)\r\n",
    "    end_wait_time = 1\r\n",
    "    step_time = 0.25\r\n",
    "    look_at = [0, 0.05, 0.05]\r\n",
    "    cam_front = [-1, 0.2, 0.2]\r\n",
    "    cam_up = [0, 1, 0]\r\n",
    "    # Some variables to be used during animation\r\n",
    "    rot_init = quat_to_rm(qu_i[0], qu_i[1], qu_i[2], qu_i[3])\r\n",
    "    pc_init.rotate(rot_init, [0, 0, 0])\r\n",
    "    rot_final = quat_to_rm(qu_f[0], qu_f[1], qu_f[2], qu_f[3])\r\n",
    "    pc_final.rotate(rot_final, [0, 0, 0])\r\n",
    "    quat_vals = gen_intermediate_quats(qu_i, qu_f, N)\r\n",
    "    # Some properties of visualization window\r\n",
    "    viz_title = \"Animation\"\r\n",
    "    viz_width = 1080\r\n",
    "    viz_height = 720\r\n",
    "    # Some alterations to animation objects\r\n",
    "    c = color_init\r\n",
    "    pc_init.paint_uniform_color([c[0]/255, c[1]/255, c[2]/255])\r\n",
    "    c = color_final\r\n",
    "    pc_final.paint_uniform_color([c[0]/255, c[1]/255, c[2]/255])\r\n",
    "    c = color_anim\r\n",
    "    pc_inter.paint_uniform_color([c[0]/255, c[1]/255, c[2]/255])\r\n",
    "    # -- Start non-blocking visualization --\r\n",
    "    vis = o3d.visualization.Visualizer()\r\n",
    "    vis.create_window(viz_title, viz_width, viz_height)\r\n",
    "    if static_gs is not None:\r\n",
    "        for static_geo in static_gs:\r\n",
    "            vis.add_geometry(static_geo)\r\n",
    "    vis.add_geometry(pc_init)\r\n",
    "    vis.add_geometry(pc_final)\r\n",
    "    vis.add_geometry(pc_inter)  # Intermediate point cloud\r\n",
    "    # Set view\r\n",
    "    ctr = vis.get_view_control()\r\n",
    "    ctr.set_lookat(look_at)\r\n",
    "    ctr.set_front(cam_front)\r\n",
    "    ctr.set_up(cam_up)\r\n",
    "    vis.poll_events()\r\n",
    "    vis.update_renderer()\r\n",
    "    # Animate through every step\r\n",
    "    for i in range(N):\r\n",
    "        curr_quat = quat_vals[i, :]\r\n",
    "        rot_m = quat_to_rm(curr_quat[0], curr_quat[1], curr_quat[2], curr_quat[3])\r\n",
    "        pc_main.rotate(rot_m, [0, 0, 0])\r\n",
    "        # Transfer points\r\n",
    "        pc_inter.points = pc_main.points\r\n",
    "        # Update visualization\r\n",
    "        vis.update_geometry(pc_inter)\r\n",
    "        pc_main = copy.deepcopy(pc) # Make the copy again\r\n",
    "        st_time = time.time()\r\n",
    "        while (time.time() - st_time < step_time):\r\n",
    "            vis.poll_events()\r\n",
    "            vis.update_renderer()\r\n",
    "    # Destroy everything\r\n",
    "    st_time = time.time()\r\n",
    "    while (time.time() - st_time < end_wait_time):\r\n",
    "        vis.poll_events()\r\n",
    "        vis.update_renderer()\r\n",
    "    vis.destroy_window()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Rotation that has happened\r\n",
    "rot = np.array(RotX(30, True) * RotY(90, True) * RotZ(10, True), dtype=float)\r\n",
    "qu_i = np.array([0, 0, 0, 1])\r\n",
    "qu_f = np.array(rm_to_quat(rot))\r\n",
    "# Create a copy of point cloud\r\n",
    "bunny_points = copy.deepcopy(bunny_pc)\r\n",
    "ref_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.2, origin=[0,0,0])\r\n",
    "# Show the visualization\r\n",
    "visualize_pc_rots(bunny_points, qu_i, qu_f, static_gs=[ref_frame], N=20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The animation below was achieved with the following python code (for initial and final quaternion values)\r\n",
    "\r\n",
    "```py\r\n",
    "rot = np.array(RotX(30, True) * RotY(90, True) * RotZ(10, True), dtype=float)\r\n",
    "qu_i = np.array([0, 0, 0, 1])\r\n",
    "qu_f = np.array(rm_to_quat(rot))\r\n",
    "```\r\n",
    "\r\n",
    "And the individual images were captured using [capture_screen_image](http://www.open3d.org/docs/release/python_api/open3d.visualization.Visualizer.html#open3d.visualization.Visualizer.capture_screen_image) function\r\n",
    "\r\n",
    "![Animation of quaternion interpolation](./results/2/Quat_animation.gif)\r\n",
    "\r\n",
    "GIF made using [this app on Windows 10](https://www.microsoft.com/en-us/p/gif-maker-gif-editor/9pkc9pxzxg9r?activetab=pivot:overviewtab)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## c) Exponential maps (Bonus)\r\n",
    "\r\n",
    "1. What is the idea behind exponential map representation of rotation matrices?\r\n",
    "2. Perform matrix exponentiation and obtain the rotation matrix to rotate a vector $P$ around $\\omega$ for $\\theta$ seconds.\r\n",
    "$$\r\n",
    "\\omega = \\begin{bmatrix}2 \\\\ 1 \\\\ 15 \\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "$$\r\n",
    "\\theta = 4.1364\r\n",
    "$$\r\n",
    "\r\n",
    "3. Compute the logarithmic map (SO(3) to so(3)) of the rotation matrix to obtain the rotation vector and the angle of rotation\r\n",
    "$$\r\n",
    "\\begin{bmatrix}\r\n",
    "0.1 &  -0.9487 & 0.3 \\\\\r\n",
    "0.9487 & 0.  & -0.3162 \\\\\r\n",
    "0.3   &  0.3162  & 0.9 \r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "You can use inbuilt libraries **only to verify** your results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 1: Why Axis-Angle\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exponential maps or **Angle-Axis convention** provide an intuitive understanding of rotations that we can visualize, and that still adhere to the norms of rotational matrices (representing successive operations as multiplication). Since they're an implicit representation, they're not prone to singularities (like how euler angles are, as they're an explicit representation).\r\n",
    "\r\n",
    "The idea is to represent every rotation operation as a single rotation by an angle $\\theta$ about a unit vector $\\omega$ (using the right hand convention). This is easier to visualize, as vectors can be represented in 3D space and a rotation by $\\theta$ can also be visualized intuitively (curl your right hand along the vector, with thumb pointing towards the head, the rotational sense of your right hand fingers show the rotation direction). This gives them a representational advantage over other intrinsic representations like quaternions (that are harder to visualize)\r\n",
    "\r\n",
    "References:\r\n",
    "- [Wikipedia](https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation#Exponential_map_from_%7F'%22%60UNIQ--postMath-00000006-QINU%60%22'%7F(3)_to_SO(3))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 2: Rotation matrix from Axis-angle\r\n",
    "\r\n",
    "Assuming that angle of rotation is $\\theta$, given in radians"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using Rodrigues' rotations formula, the rotation matrix when a rotation about unit vector $\\mathbf{k}$ by angle $\\theta$ (using right hand thumb rule) is given by\r\n",
    "\r\n",
    "$$ \\mathbf{R} = \\mathbf{I} + (\\sin \\theta) \\mathbf{[k]} + (1-\\cos \\theta) \\mathbf{[k]}^2 $$\r\n",
    "\r\n",
    "Where \r\n",
    "$$ \r\n",
    "\\mathbf{[k]} = \\begin{bmatrix}\r\n",
    "0 & -k_z & k_y \\\\\r\n",
    "k_z & 0 & -k_x \\\\\r\n",
    "-k_y & k_x & 0 \r\n",
    "\\end{bmatrix} \r\n",
    "\\;\\; \\textup{and} \\;\\;\r\n",
    "\\mathbf{[k]}^2 = \\begin{bmatrix}\r\n",
    "-k_y^2-k_z^2 & k_x k_y & k_x k_z \\\\\r\n",
    "k_y k_x & -k_x^2-k_z^2 & k_y k_z \\\\\r\n",
    "k_z k_x & k_z k_y & -k_x^2-k_y^2\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "We get\r\n",
    "\r\n",
    "$$\r\n",
    "\\mathbf{R} = \\begin{bmatrix}\r\n",
    "1+(1-\\cos\\theta)(k_x^2-1) & -k_z\\sin\\theta+(1-\\cos\\theta)k_xk_y & k_y\\sin\\theta+(1-\\cos\\theta)k_xk_z \\\\\r\n",
    "k_z\\sin\\theta+(1-\\cos\\theta)k_yk_x & 1+(1-\\cos\\theta)(k_y^2-1) & -k_x\\sin\\theta+(1-\\cos\\theta)k_yk_z \\\\\r\n",
    "-k_y\\sin\\theta+(1-\\cos\\theta)k_zk_x & k_x\\sin\\theta+(1-\\cos\\theta)k_zk_y & 1+(1-\\cos\\theta)(k_z^2-1) \\\\\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "You can accomplish this using scipy\r\n",
    "- Use [Rotation.from_rotvec](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.from_rotvec.html) to construct Rotation object using rotation vector. Note that this takes only three numbers, as the axis is expected to be normalized (so multiply the angle and axis).\r\n",
    "- Use [Rotation.as_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.as_matrix.html) to get the rotation matrix back"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Angle axis to rotation matrix\r\n",
    "def axang_to_rm(ax, ang, degrees = False):\r\n",
    "    \"\"\"\r\n",
    "    Convert axis-angle representation to rotation matrix\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - ax: list or np.ndarray    shape: (3,)\r\n",
    "        The axis of rotation where ax[0] is X coordinate, ax[1] is Y\r\n",
    "        coordinate and ax[2] is Z coordinate\r\n",
    "    - ang: float\r\n",
    "        The angle of rotation\r\n",
    "    - degrees: bool     default: False\r\n",
    "        If 'True', the 'ang' angle is assumed to be in degrees and is\r\n",
    "        subsequently converted to radians. Else if 'False', the 'ang'\r\n",
    "        value is assumed to already be in radians\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - rot_m: np.ndarray     shape: (3, 3)\r\n",
    "        A 3x3 rotation matrix (direction cosines)\r\n",
    "    \"\"\"\r\n",
    "    th_rad = np.deg2rad(ang) if degrees else ang\r\n",
    "    [kx, ky, kz] = ax[0], ax[1], ax[2]\r\n",
    "    k_cross = sp.Matrix([\r\n",
    "        [0, -kz, ky],\r\n",
    "        [kz, 0, -kx],\r\n",
    "        [-ky, kx, 0]\r\n",
    "    ])\r\n",
    "    k_cross_sq = k_cross * k_cross\r\n",
    "    rot_m = np.eye(3) + sp.sin(th_rad) * k_cross + (1-sp.cos(th_rad)) * k_cross_sq\r\n",
    "    return rot_m"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "w_axis = np.array([2, 1, 15])\r\n",
    "w_axis = w_axis / np.linalg.norm(w_axis)\r\n",
    "ang_th = 4.1364\r\n",
    "px, py, pz = sp.symbols('P_x, P_y, P_z')\r\n",
    "P_vect = sp.Matrix([[px], [py], [pz]])\r\n",
    "rot_m = axang_to_rm(w_axis, ang_th)\r\n",
    "# Use scipy to verify\r\n",
    "rm = Rotation.from_rotvec(w_axis * ang_th)\r\n",
    "# Rotation matrix is\r\n",
    "if np.allclose(rm.as_matrix(), np.array(rot_m, dtype=float)):\r\n",
    "    print(\"Rotation matrix is identical through Scipy\")\r\n",
    "    print(np.array(rot_m, dtype=float))\r\n",
    "# Transformation of P\r\n",
    "print(\"The vector P = [Px, Py, Pz] will become\")\r\n",
    "rot_m * P_vect"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Rotation matrix is identical through Scipy\n",
      "[[-0.51780074  0.84292002  0.14617876]\n",
      " [-0.81605629 -0.53794854  0.21133741]\n",
      " [ 0.25677718 -0.00985943  0.96642034]]\n",
      "The vector P = [Px, Py, Pz] will become\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}- 0.517800739415721 P_{x} + 0.842920021873521 P_{y} + 0.146178763797195 P_{z}\\\\- 0.816056291972358 P_{x} - 0.537948536841593 P_{y} + 0.211337408052421 P_{z}\\\\0.256777184720253 P_{x} - 0.00985943379369655 P_{y} + 0.966420337623546 P_{z}\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[ -0.517800739415721*P_x + 0.842920021873521*P_y + 0.146178763797195*P_z],\n",
       "[ -0.816056291972358*P_x - 0.537948536841593*P_y + 0.211337408052421*P_z],\n",
       "[0.256777184720253*P_x - 0.00985943379369655*P_y + 0.966420337623546*P_z]])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 3: Axis-angle from Rotation matrix\r\n",
    "\r\n",
    "The angle and axis can be derived from the rotation matrix by doing the following\r\n",
    "\r\n",
    "$$\r\n",
    "\\mathbf{R} = \\begin{bmatrix}\r\n",
    "r_{11} & r_{12} & r_{13} \\\\\r\n",
    "r_{21} & r_{22} & r_{23} \\\\\r\n",
    "r_{31} & r_{32} & r_{33}\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "The angle is given by\r\n",
    "\r\n",
    "$$ \\theta = \\arccos \\left( \\frac{r_{11}+r_{22}+r_{33}-1}{2} \\right ) $$\r\n",
    "\r\n",
    "The axis is then retrieved using\r\n",
    "\r\n",
    "$$\r\n",
    "\\mathbf{k} = \\frac{1}{2 \\sin\\theta} \\begin{bmatrix}\r\n",
    "r_{32} - r_{23} \\\\\r\n",
    "r_{13} - r_{31} \\\\\r\n",
    "r_{21} - r_{12}\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "\r\n",
    "Use the following scipy functions for verification\r\n",
    "- Use [Rotation.from_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.from_matrix.html) to construct a Rotation object from rotation matrix\r\n",
    "- Use [Rotation.as_rotvec](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.as_rotvec.html) to get the rotation vector and angle. The angle is the norm (magnitude) and the axis has to be normalized."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Rotation matrix to angle axis\r\n",
    "def rm_to_axang(rot_m, degrees = False):\r\n",
    "    \"\"\"\r\n",
    "    Convert rotation matrix to angle-axis representation\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "    - rot_m: np.ndarray     shape: (3, 3)\r\n",
    "        Rotation Matrix\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - ax: np.ndarray    shape: (3,1)\r\n",
    "        The axis\r\n",
    "    - ang: float\r\n",
    "        The angle. If 'degrees' is False, then in radians. Else\r\n",
    "        if 'degrees' is True, then in degrees.\r\n",
    "    \"\"\"\r\n",
    "    # Parse elements\r\n",
    "    r11 = rot_m[0][0]\r\n",
    "    r12 = rot_m[0][1]\r\n",
    "    r13 = rot_m[0][2]\r\n",
    "    r21 = rot_m[1][0]\r\n",
    "    r22 = rot_m[1][1]\r\n",
    "    r23 = rot_m[1][2]\r\n",
    "    r31 = rot_m[2][0]\r\n",
    "    r32 = rot_m[2][1]\r\n",
    "    r33 = rot_m[2][2]\r\n",
    "    # Angle\r\n",
    "    ang_rad = np.arccos((r11+r22+r33-1)/2)\r\n",
    "    ang = np.rad2deg(ang_rad) if degrees else ang_rad\r\n",
    "    # Axis\r\n",
    "    ax = (1/(2*np.sin(ang_rad))) * np.array([\r\n",
    "        [r32-r23],\r\n",
    "        [r13-r31],\r\n",
    "        [r21-r12]\r\n",
    "    ])\r\n",
    "    return ax, ang"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Rotation matrix\r\n",
    "rot_m = np.array([\r\n",
    "    [0.1, -0.9487, 0.3],\r\n",
    "    [0.9487, 0.0, -0.3162],\r\n",
    "    [0.3, 0.3162, 0.9]\r\n",
    "])\r\n",
    "# Get axis and angle\r\n",
    "ax, ang = rm_to_axang(rot_m)\r\n",
    "print(f\"Axis is \\n{ax}\")\r\n",
    "print(f\"Angle is {ang:.4f} (which is {np.rad2deg(ang):.3f} degrees)\")\r\n",
    "# Testing with scipy\r\n",
    "axang_sp = Rotation.from_matrix(rot_m).as_rotvec()\r\n",
    "ang_sp = np.linalg.norm(axang_sp)\r\n",
    "ax_sp = axang_sp / ang_sp\r\n",
    "if np.allclose(ax_sp, ax.flatten()) and np.allclose(ang_sp, ang):\r\n",
    "    print(\"Scipy returns the same axis and angle\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Axis is \n",
      "[[0.3162]\n",
      " [0.    ]\n",
      " [0.9487]]\n",
      "Angle is 1.5708 (which is 90.000 degrees)\n",
      "Scipy returns the same axis and angle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Data representations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## a) Octomaps\r\n",
    "\r\n",
    "1. Why is an Octomap memory efficient?\r\n",
    "2. When do we update an Octomap and why?\r\n",
    "3. When would you likely use an octomap instead of a point cloud?\r\n",
    " "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 1: Octomap memory\r\n",
    "\r\n",
    "An octomap stores environmental data (usually obtained through a point cloud) in a tree like data structure. Each node is a cube called a voxel which can be further divided into 8 sub-cubes (sub-voxels). Some of the reasons why octomaps are memory efficient are as follows\r\n",
    "- The information about the coordinates of each node (center location of each cube) need not be stored (it can be inferred on traversal), only the probabilistic estimate of its occupancy is stored. \r\n",
    "- The depth of the tree is bounded by the maximum resolution of the data. Additionally, segmenting the tree to a particular depth level (less than the leaf nodes) yields a map with coarser resolution. So this allows storing artifact information and retrievals of multiple resolutions.\r\n",
    "- If all children of a node have the same state (occupied or free) they can be pruned, to save memory. Such pruning is also possible when constructing or modifying the tree. \r\n",
    "- Using maximum likelihood probabilities before tree pruning leads to even greater compression and lesser memory requirements.\r\n",
    "\r\n",
    "Additionally, you can store extra information for every voxel (like temperature or color of the region)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 2: Updating Octomaps\r\n",
    "\r\n",
    "Note that occupancy values are updated as **log-odds** values as shown below (it's essentially accumulating previous log-odds estimates and thresholding them)\r\n",
    "\r\n",
    "$$ \\textup{L} (n|z_{1:t}) = \\textup{max} \\left( \\textup{min} \\left( \\textup{L} (n|z_{1:t-1}) + \\textup{L}(n|z_{t}), l_{\\textup{max}} \\right ), l_{\\textup{min}} \\right ) $$\r\n",
    "\r\n",
    "Where $\\textup{L}(n) = \\textup{log} \\left[ \\frac{P(n)}{1-P(n)} \\right ]$ (log, odds). In a static environment, all voxels will converge to a stable state ($l_{\\textup{min}}$ for free and $l_{\\textup{max}}$ for occupied). However, when readings come that change a node / voxel from stable to _unstable_ (new _measurements that contradict_ the state of corresponding node), then its children (which were pruned earlier when the voxel became stable) will have to be **regenerated** and **updated** (resampled and added to the tree) accordingly. The bounds in the above equation are so that the map can adapt to changes in the environment quickly, and to promote compression among stable nodes. Say we didn't have them, we would need as many observations contradicting the current voxel state as many were taken to affirm that state earlier, this would slow the updating process of the map significantly.\r\n",
    "\r\n",
    "Basically, we update the map when contradicting readings are achieved and, because we do not want to loose the sub-voxel data, we update children nodes in the octree as well. We do this to maintain the map's correctness."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 3: Octomaps Vs. Point Clouds\r\n",
    "\r\n",
    "While point clouds are simpler to visualize, they have serious memory constraints (over a large area that needs to be mapped) and cannot easily be stored in a hierarchical manner. Precisely, you could use octomaps instead of point clouds in the following cases\r\n",
    "\r\n",
    "- Storage and transmission of spatial data in terms of occupancy. Point clouds would take significantly more information (sampled points of 3D space) compared to octrees (using which the octomap is made)\r\n",
    "- Hierarchical models where some objects (maybe foreground objects of prominence) could have higher resolution separate octrees compared to less important objects (maybe background objects). Hierarchical octrees allow subtrees to be created, which are very useful in environment recognition. Doing the same through point clouds is difficult.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## b) Signed Distance Functions\n",
    "\n",
    "1. How do we determine object surfaces using SDF?\n",
    "2. How do we aggregate views from multiple cameras? (just a general overview is fine)\n",
    "3. Which preserves details better? Voxels or SDF? Why?\n",
    "4. Whats an advantage of SDF over a point cloud?\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 1: Object Surfaces using SDF\r\n",
    "\r\n",
    "A Signed Distance Function is applied to individually sampled points in space. Their value is associated to the distance to the nearest surface and the position relative to the surface. Usually, if a point is in the surface (surface comes first in sensor measurement / ray from sensor), then, it is given a positive value. If a point is outside the surface (point comes first in ray from sensor), then, it is given a negative value. So it is high inside surface / object, decreases towards 0 as we move to surface, then further decreases (goes negative) as we move outwards the object surface.\r\n",
    "\r\n",
    "Therefore, an object surface can be extracted from the sign distance function by **sampling the points whose value is 0** (points on the surface).\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 2: Aggregating multiple camera views\r\n",
    "\r\n",
    "A camera essentially projects a 3D scene to a surface. During this process, the depth of the scene is lost. By capturing the scene from multiple views, we can extract several depth features of the scene back from the multiple images. A scene can be reconstructed by aggregating multiple pictures from the same camera, taken from different poses or multiple cameras can be used to do this process live / on-the-fly.\r\n",
    "\r\n",
    "Say we have two cameras that have captured images (say one image from each) of the same scene and we have to find the depth information of the scene. We would roughly follow the following steps\r\n",
    "\r\n",
    "1. Find the **camera parameters**: This stereo setup has several parameters that are divided into two main categories: _intrinsic_ and _extrinsic_ parameters. \r\n",
    "\r\n",
    "    Let's briefly describe these\r\n",
    "\r\n",
    "    - Intrinsic parameters are parameters of the camera, things like focal length. These parameters allow efficient projection lines in 3D space. That is, given a pixel in the image, project it's ray in 3D space (a set of points where that pixel could be in 3D space) that could have made that pixel land where it is in the image. These parameters are particular to the camera. This basically gives the mapping from 3D world coordinates to 2D image coordinates.\r\n",
    "    - Extrinsic parameters are parameters of the stereo setup that give us the transformation between the two cameras. This is basically to understand where one camera is with respect to another in the 3D world.\r\n",
    "\r\n",
    "    Several applications allow us to estimate these parameters, usually after running an experiment with a checkboard (whose dimensions are well known in advance). MATLAB's [Stereo Camera Calibrator App](https://in.mathworks.com/help/vision/ug/stereo-camera-calibrator-app.html) allows identification and exporting of the camera parameters. \r\n",
    "    \r\n",
    "    Usually, once these parameters are identified, the stereo setup is frozen, that is, no changes to the camera or their relative pose is made. This is done so that we do not have to run this step every time; just run once, calibrate and done.\r\n",
    "\r\n",
    "2. Run **stereo rectification** and **feature extraction**: This is two steps in actual, but squashed into one for describing purposes. The end result is to have features identified that belong to both the images. Only when we have correctly identified these features, can they be projected and the relevant depth information be retrieved. To understand why distinguishable features are needed consider this though experiment. Say we have two pictures taken of a plane wall (no features); what information can be projected? There is nothing that can be extracted from the plane image.\r\n",
    "\r\n",
    "    1. Feature extraction: Finding features of significance. Usually corner detection algorithms work well. Algorithms like [SIFT](https://en.wikipedia.org/wiki/Scale-invariant_feature_transform) are also commonly used.\r\n",
    "    2. Stereo Rectification: This means horizontally aligning the images, so that feature matching stage becomes less computationally intensive. We don't just have to find features in the two images, we also have to match them (find their corresponding equivalent in the other image).\r\n",
    "\r\n",
    "    Usually, this can be done on the images after having the camera parameters. This is basically removing the distortion (using intrinsic parameters) from the images and horizontally aligning the two images so that individual features on each line can be matched using a linear search approach (which is less computationally intensive than having to consider pairwise features and neighborhoods).\r\n",
    "\r\n",
    "3. Generate a **disparity map**: This basically shows the individual pixel displacement. Pixels closer to the camera have high disparity (greater deviation in the two images) than pixels that are farther from the camera in the scene. This map is useful in estimating / converting the two images into a scene description format like point cloud. Note that this can only be done on rectified images, as horizontal displacement of features are used. This is usually where the common steps end. The following steps are specific to the kind of data we want to retrieve. Usually, [Epipolar geometry](https://en.wikipedia.org/wiki/Epipolar_geometry) is heavily used in this stage and the next stages.\r\n",
    "\r\n",
    "4. Use the disparity map and camera stereo parameters to construct the point cloud. The disparity map has already given some estimate of depth, we use the camera parameters to get the exact location of these features in the scene. Some approaches can even use apply neighborhood methods to the regions near the features in the images and virtually project every pixel into the point cloud.\r\n",
    "\r\n",
    "This is how you could _reconstruct_ a scene as point cloud using stereo-imaging from two cameras.\r\n",
    "\r\n",
    "**References**\r\n",
    "\r\n",
    "- YouTube\r\n",
    "    - [Stereo Vision by MATLAB](https://www.youtube.com/watch?v=GpU1Vx-b3VA)\r\n",
    "- Slides\r\n",
    "    - [Vision Research Lab, University of Minnesota](http://vision.psych.umn.edu/users/schrater/schrater_lab/courses/CompVis07/Papers/Stereo.pdf)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 3: Voxels or SDF\r\n",
    "\r\n",
    "- Usually, SFDs have voxel information embedded in them, as they're functions that essentially take point / coordinates and return proximity to surface (which can be later used as an estimate of occupancy for that coordinate). Voxels on the other hand, are an extension of occupancy maps in 3D. They explicitly discretize (divide) the 3D space into cubical volumes and store occupancy values.\r\n",
    "- When it comes to **preserving surface details of the scene**, SDFs can do a better job because they have that embedded in them (value = 0 is the surface). Voxels on the other hand have to run some surface detection algorithm (usually done using surface normals). This compute load is over the very heavy memory load used by Voxels. Usually, SDFs can do such tasks better than Voxel representations that use lesser memory like Octrees (which still require some processing to get surface contours of objects). Therefore, given the same memory requirement and the objective being preserving the scene objects, SDFs can do a better job.\r\n",
    "- SDFs can be used to estimate Voxel occupancy too. This makes them a robust tool for navigation purposes. If sliced along a surface, they can be used as potential functions (that allow us to traverse a path while avoiding or repelling from obstacles)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer 4: SDF Vs. Point Clouds\r\n",
    "\r\n",
    "We might want to use SDFs when estimating occupancy in 3D space\r\n",
    "\r\n",
    "- A point cloud has no proximity information associated with it. It is simply a collection of 3D points. To infer anything from them, some transformations need to be applied to them. To retrieve occupancy of a voxel (a cube in 3D space), points within it have to be estimated, which requires repetitive sampling of the clouds (for every query).\r\n",
    "- SDFs on the other hand, store this information within them. For any given point in space, they return the distance from the nearest surface. This can be used as a measurement to proximity and an estimate of occupancy.\r\n",
    "\r\n",
    "We might want to use SDFs when the objects in the scene are very important\r\n",
    "\r\n",
    "- Since SDFs are functions (yielding the surface of obstacles / objects when equated to 0), they can be stored while containing high details about objects in the scene.\r\n",
    "- SDFs also allow us to dilate (or contract) objects. We can simply offset the function to re-scale the object, and such scaling is very uniform. An example of this can be found [here](https://www.cineversity.com/vidplaylist/372083_default_playlist/volumetric_workflow_what_are_signed_distance_fields_sdf). Doing the same using point clouds is difficult (you have to estimate the center of scaling first, then apply transformation)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# References and Resources\n",
    "\n",
    "1. Gimbal locks and quaternions: https://youtu.be/YF5ZUlKxSgE\n",
    "2. Exponential map: \n",
    "    1. 3 Blue 1 Brown: https://youtu.be/O85OWBJ2ayo\n",
    "    2. Northwestern Robotics: https://youtu.be/v_KBHaG0mas\n",
    "3. Bunny ply is taken from: http://graphics.im.ntu.edu.tw/~robin/courses/cg03/model/"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "833f805e531b09d5891922f3c95e86129d68dd31d00273e9af88a8ef7add9b8d"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('mr-cs7-503': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}